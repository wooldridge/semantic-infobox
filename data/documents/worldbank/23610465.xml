<?xml version="1.0" encoding="UTF-8"?><ml:doc-envelope xmlns:ml="http://marklogic.com/poolparty/worldbank"><ml:original-txt>                                93621&#13;
&#13;
&#13;
&#13;
&#13;
Monitor&#13;
      ingand&#13;
Evau&#13;
   lati&#13;
      on Ss&#13;
          ytem:&#13;
TheCaseofChie&#13;
            l&#13;
1990â&#128;&#147;2014&#13;
&#13;
&#13;
No.29|Jul&#13;
        y 2014&#13;
&#13;
&#13;
&#13;
&#13;
MarceaG&#13;
     l  uzmÃ¡ n,g&#13;
               InacoI&#13;
                   i a&#13;
                     rrr&#13;
                       Ã¡zava,&#13;
                            l&#13;
andBors&#13;
      i delosR o&#13;
               Ã­s&#13;
&amp;#12;ECD Working Paper Series No. 29&#13;
&#13;
&#13;
&#13;
&#13;
        Monitoring and Evaluation System:&#13;
                The Case of Chile&#13;
                   1990â&#128;&#147;2014&#13;
        By Marcela GuzmÃ¡n, Ignacio IrarrÃ¡zaval, and Boris de los RÃ­os&#13;
&#13;
&#13;
&#13;
&#13;
www.worldbank.org/ieg/ecd&#13;
&amp;#12;Â© 2014 Independent Evaluation Group, The World Bank Group&#13;
1818 H St., NW&#13;
Washington, DC 20433&#13;
http://ieg.worldbankgroup.org&#13;
&#13;
&#13;
&#13;
      IEG: Improving the World Bank Groupâ&#128;&#153;s Development Results Through Excellence in Evaluation&#13;
&#13;
&#13;
&#13;
The Independent Evaluation Group is an independent unit within the World Bank Group; it reports directly&#13;
to the Bankâ&#128;&#153;s Board of Executive Directors. IEG assesses what works, and what does not; how a borrower&#13;
plans to run and maintain a project; and the lasting contribution of the Bank to a countryâ&#128;&#153;s overall&#13;
development. The goals of evaluation are to learn from experience, to provide an objective basis for&#13;
assessing the results of the Bankâ&#128;&#153;s work, and to provide accountability in the achievement of its objectives. It&#13;
also improves Bank work by identifying and disseminating the lessons learned from experience and by&#13;
framing recommendations drawn from evaluation findings.&#13;
&#13;
IEGâ&#128;&#153;s Evaluation Capacity Development Working Papers are an informal series to disseminate the findings of&#13;
work in progress to encourage the exchange of ideas about development effectiveness through evaluation.&#13;
&#13;
The findings, interpretations, and conclusions expressed here are those of the author(s) and do not&#13;
necessarily reflect the views of the Board of Executive Directors of the World Bank or the governments they&#13;
represent, or IEG management.&#13;
&#13;
IEG cannot guarantee the accuracy of the data included in this work. The boundaries, colors, denominations,&#13;
and other information shown on any map in this work do not imply on the part of the World Bank any&#13;
judgment of the legal status of any territory or the endorsement or acceptance of such boundaries.&#13;
&#13;
ISBN-13: 978-1-60244-246-7&#13;
ISBN-10: 1-60244-246-0&#13;
&#13;
&#13;
&#13;
Contact: IEG Communication, Learning, and Strategies&#13;
e-mail: ieg@worldbank.org&#13;
Telephone: 202-458-4497&#13;
Facsimile: 202-522-3125&#13;
http://ieg.worldbankgroup.org&#13;
&amp;#12;Acknowledgements&#13;
&#13;
The authors thank the Independent Evaluation Group of the World Bank Group for its support of&#13;
this work.&#13;
&#13;
This paper was originally written as two different papers; the first draft covered the case of the&#13;
monitoring and evaluation in Chile from 1990 to 2010 and was written by Marcela Guzman. The&#13;
second draft was authored by Ignacio IrarrÃ¡zaval and Boris de los Rios covering the 2010-14&#13;
period. The present version of the paper merges the original drafts in a single document.&#13;
&#13;
Marcela Guzman is currently an international consultant and was formerly Head of the&#13;
Management Control Division at the Budget Office in the Ministry of Finance in Chile. Ignacio&#13;
IrarrÃ¡zaval is the Director of the Center for Public Policies at the Catholic University of Chile. Boris&#13;
de los RÃ­os is the Coordinator for Public Administration of the Center for Public Policies at the&#13;
Catholic University of Chile.&#13;
&#13;
This paper benefitted from review and comments by Paula Darville (Head of the Management&#13;
Control Division, Budget Office, Ministry of Finance, Chile), Nidhi Khattri (Lead Evaluation Officer,&#13;
IEG), Patrick Grasso, and Arianne Wessal (consultants, IEG) and edits from Heather Dittbrenner&#13;
(IEG). The task managers for this work were Manuel Fernando Castro and Ximena Fernandez&#13;
Ordonez (Evaluation Officer, IEG).&#13;
&#13;
None of the views expressed herein by the authors should be construed to represent the policies&#13;
or positions of the Catholic University of Chile, the government of Chile, or the World Bank Group.&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                           3&#13;
&amp;#12;ACRONYMS&#13;
&#13;
BIPS       Integrated Social Programs Bank&#13;
&#13;
DIPRES     Budget Directorate, Ministry of Finance&#13;
&#13;
MDS        Ministry of Social Development&#13;
&#13;
M&amp;E        Monitoring and Evaluation&#13;
&#13;
OECD       Organisation for Economic Co-operation and Development&#13;
&#13;
SEGPRES    Ministry of the Presidency&#13;
&#13;
&#13;
&#13;
&#13;
                                                                    4&#13;
&amp;#12;Table of Contents&#13;
Background ......................................................................................................................................... 7&#13;
&#13;
1       Monitoring and Evaluation System: 1990-2010 ......................................................................... 8&#13;
&#13;
    1.1       Introduction ......................................................................................................................... 8&#13;
&#13;
        1.1.1         Origins of the System .................................................................................................. 8&#13;
&#13;
        1.1.2         Elements of Context .................................................................................................... 9&#13;
&#13;
        1.1.3         Gradual Development and Stages ............................................................................... 9&#13;
&#13;
    1.2       Institutional Arrangements and System Operations ......................................................... 10&#13;
&#13;
        1.2.1         Primary Characteristics of Responsible Organizational Unit..................................... 10&#13;
&#13;
        1.2.2         Roles of the National Auditing Office and Civil Society ............................................. 11&#13;
&#13;
        1.2.3         Integration of Information into Decision-Making Processes .................................... 12&#13;
&#13;
    1.3       M&amp;E Components.............................................................................................................. 12&#13;
&#13;
        1.3.1         Indicators ................................................................................................................... 12&#13;
&#13;
        1.3.2         Evaluation .................................................................................................................. 16&#13;
&#13;
    1.4       Use of M&amp;E Information .................................................................................................... 22&#13;
&#13;
        1.4.1         Indicators ................................................................................................................... 22&#13;
&#13;
        1.4.2         Evaluations ................................................................................................................ 23&#13;
&#13;
2       Monitoring and Evaluation System: 2010-14 ........................................................................... 25&#13;
&#13;
    2.1       Introduction ....................................................................................................................... 25&#13;
&#13;
    2.2       Institutional Arrangements and System Operations ......................................................... 26&#13;
&#13;
    2.3       M&amp;E Components and Instruments .................................................................................. 29&#13;
&#13;
        2.3.1         Monitoring................................................................................................................. 29&#13;
&#13;
        2.3.2         Evaluation .................................................................................................................. 32&#13;
&#13;
    2.4       Use of M&amp;E Information .................................................................................................... 33&#13;
&#13;
        2.4.1         Indicators ................................................................................................................... 33&#13;
&#13;
        2.4.2         Evaluation .................................................................................................................. 34&#13;
&#13;
                                                                                                                                                    5&#13;
&amp;#12;3       Success Factors and Obstacles ................................................................................................. 36&#13;
&#13;
        3.1.1         Success Factors.......................................................................................................... 36&#13;
&#13;
        3.1.2         Obstacles ................................................................................................................... 38&#13;
&#13;
4       Challenges................................................................................................................................. 40&#13;
&#13;
5       Lessons for Other Countries ..................................................................................................... 42&#13;
&#13;
    5.1       M&amp;E Systems Are Dynamic................................................................................................ 42&#13;
&#13;
    5.2       Strategic Roles ................................................................................................................... 43&#13;
&#13;
    5.3       Institutional Arrangements ................................................................................................ 43&#13;
&#13;
    5.4       Components of the M&amp;E System....................................................................................... 44&#13;
&#13;
    5.5       Availability of Information ................................................................................................. 45&#13;
&#13;
    5.6       Work Teams ....................................................................................................................... 46&#13;
&#13;
    5.7       Integration with the Decision-Making Process .................................................................. 46&#13;
&#13;
References......................................................................................................................................... 47&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                   6&#13;
&amp;#12;Background&#13;
&#13;
Chile is a unitary and presidential country in which the initiative for proposing legislative bills&#13;
associated with financial or budget administration is granted exclusively to the President. This&#13;
means that the Executive Branch is responsible for the administration and management of public&#13;
finances, with responsibilities concentrated in the Ministry of Finance.&#13;
&#13;
The basis for the current Chilean M&amp;E system dates back to the 1990s. The main actor behind the&#13;
set of tools and methodologies that constitute the system was the Budget Office, DirecciÃ³n de&#13;
Presupuestos 1 within the Ministry of Finance; and since 2000, the Public Management Control&#13;
Division of this office. Because of this, the Chilean monitoring and evaluation (M&amp;E) system has&#13;
been structured mainly around the budgetary cycle through the creation of certain tools focused&#13;
on the Chilean stateÂ´s programs and institutions. During the development of the M&amp;E system,&#13;
two periods can be identified. The first period has, in turn, two stages. The first stage, from 1990&#13;
to 2000, was marked by the creation of M&amp;E tools and the beginning of their implementation.&#13;
The second stage, from 2000 to 2010, was characterized by the processes of expansion,&#13;
institutionalization, and consolidation of the system by the Public Management Control Division.&#13;
The second period, from 2010 until now, started with the change of the ruling coalition in the&#13;
country. During this period, new actors were added to the system, thus modifying its emphasis.&#13;
However, many of the tools created during the first period are still being implemented.&#13;
&#13;
Prior to the current M&amp;E system, there were already precedents of evaluation tools. In the 1970s,&#13;
the first steps toward systematic evaluations were brought about by the incorporation of the ex-&#13;
ante evaluation of public investments, constituting what is the present day Sistema Nacional de&#13;
Inversiones â&#128;&#147; National Investment System. This system and its related institutions are also part of&#13;
current M&amp;E system in the country.&#13;
&#13;
The objective of this document is to give a broad view of the M&amp;E systems in Chile, distinguishing&#13;
these three stages and providing lessons for other countries that are developing their own&#13;
systems. The first section focuses on the first period and its two stages: 1990-2000 and 2000-&#13;
2010. These stages concentrate mainly on the role played by the Budget Office. The second&#13;
period covers 2010-13, in which light is shed on both the new systemÂ´s actors and the emphasis&#13;
adopted by the authorities in charge, but at the same time the authorities largely continue and&#13;
strengthen the existing tools from the M&amp;E system of the previous period. The third section of&#13;
the paper summarizes success factors and obstacles to success in the two periods. Section 4&#13;
states general conclusions regarding the main systemÂ´s challenges, and Section 5 includes lessons&#13;
for other countries.&#13;
&#13;
&#13;
&#13;
&#13;
1&#13;
    Created in 2000.&#13;
&#13;
&#13;
                                                                                                      7&#13;
&amp;#12;1    Monitoring and Evaluation System: 1990-2010&#13;
&#13;
1.1 Introduction&#13;
From its creation in the 1990s, the Chilean monitoring and evaluation (M&amp;E) system has&#13;
represented a substantial part of the effort to improve the use of Chileâ&#128;&#153;s public resources within a&#13;
broader context of multiple initiatives designed to modernize and improve public management in&#13;
many areas.&#13;
&#13;
This close relationship with the budget has determined the primary characteristics of the M&amp;E&#13;
system, in both its design and operations. For this reason, special attention is paid to (1) the role&#13;
played by M&amp;E within the Ministry of Finance in the Budget office (DirecciÃ³n de Presupuestosâ&#128;&#148;&#13;
DIPRES), and the National Congress; (2) the coordination of the different components and&#13;
instruments around the cycle of budget formulation, discussion, and approval; and (3) the use of&#13;
M&amp;E information in decision-making processes.&#13;
&#13;
1.1.1   Origins of the System&#13;
&#13;
Chileâ&#128;&#153;s M&amp;E system is one of the components in its Management Control System. Efforts to&#13;
develop this system began in the early 1990s. Institutionally, it operates within the Ministry of&#13;
Finance, specifically in the Budget Office, DIPRES. 2 The M&amp;E systemâ&#128;&#153;s architecture includes&#13;
performance indicators and evaluations that operate in a complementary manner, with various&#13;
methodologies used for conducting evaluations. 3&#13;
&#13;
The M&amp;E systemâ&#128;&#153;s institutional coverage includes all the organizations in the Executive Branch of&#13;
the central government and those included in the Budget Law for the Public Sector. The system is&#13;
focused on performance from two perspectives:&#13;
&#13;
â&#128;¢   Delivery areas in the results chain, called â&#128;&#156;value chainâ&#128;&#157; in the Chilean model (Ã&#129;reas de Control&#13;
    and Cadena de Valor, respectively): processes, outputs, and intermediate and final results&#13;
&#13;
â&#128;¢   Performance dimensions: efficiency, effectiveness, economy, and quality.&#13;
&#13;
2&#13;
 The Chilean process includes ex ante evaluation of public spending projects conducted through the&#13;
National Investment System, under the responsibility of the Ministry of Planning. Spending projects must&#13;
have a favorable economic technical recommendation prior to their incorporation into public budgets.&#13;
3&#13;
  Indicators are mathematical algorithms or formulas for measurement that present a quantitative&#13;
assessment of performance. They may cover both quantitative and qualitative aspects, but they do not, on&#13;
their own, explain the performance levels attained. They may be used for making commitments to targets&#13;
or simply to conduct follow-up. Evaluations are studies, examinations, or reviews that use information that&#13;
is organized according to a methodological framework. Their purpose is to generate assessments--and to&#13;
seek explanatory factors for these assessments or evaluation-based judgments--with respect to individual&#13;
programs, sets of programs with the same policy aim, or organizations. These definitions come from&#13;
DIPRES.&#13;
&#13;
&#13;
                                                                                                           8&#13;
&amp;#12;1.1.2   Elements of Context&#13;
&#13;
Chileâ&#128;&#153;s fiscal policy indicators were positive in the early 1990s; consequently, it cannot be said&#13;
that the M&amp;E system is a result of restrictions on spending. Rather, it developed as a search for&#13;
better results from the use of public funds and the need for greater transparency, based on the&#13;
underlying results chain. 4&#13;
&#13;
During the period in which the system was initiated, developed, and consolidated, a set of fiscal&#13;
reforms was introduced into the administration of public finances. These included&#13;
macroeconomic budget formulation, management of financial assets and liabilities, the budget&#13;
process, resource allocation, accounting, and programmatic classifications.&#13;
&#13;
The initial implementation of the M&amp;E system was accompanied by other initiatives for improving&#13;
public managementâ&#128;&#148;a development that has continued over the past two decades. Such&#13;
initiatives originated with DIPRES as well as from other executive bodies, particularly the Ministry&#13;
of the Secretariat of the Presidency. Especially worth mentioning among these developments&#13;
were exercises in strategic management, the introduction of information and communication&#13;
technologies, the installation of information and complaints offices, new procedures for&#13;
personnel training, mechanisms for salary-based performance incentives, the simplification of&#13;
procedural steps, the creation of a High-Level Public Management System (Alta DirecciÃ³n PÃºblica),&#13;
and standards on transparency and integrity. 5 All these initiatives created a positive environment&#13;
for the development of the M&amp;E system.&#13;
&#13;
1.1.3   Gradual Development and Stages&#13;
&#13;
The M&amp;E system was built gradually. First, a set of performance indicators was developed. In&#13;
many ways, this became the foundation for the system. Only later were evaluations introduced.&#13;
The information generated by the M&amp;E system was also integrated into decision making&#13;
gradually, beginning only in 2000, about seven years after the work with performance indicators&#13;
had begun and three years after the first type of evaluations had been initiated.&#13;
&#13;
During the first period, the two main phases of development were (1) the creation of M&amp;E tools&#13;
and the beginning of their implementation, from 1993 to early 2000; and (2) the processes of&#13;
perfecting, expanding, institutionalizing, and consolidating the system, from 2000 to 2010. The&#13;
changes introduced on the system during the period 2010-13 are detailed in the next chapter, and&#13;
as mentioned previously, those changes involve the introduction of new actors and the&#13;
strengthening of the previous consolidated M&amp;E tools.&#13;
&#13;
&#13;
&#13;
4&#13;
 For more background on the administration of public finances and the fiscal situation, see Marcel (1993,&#13;
pp. 55-69); DIPRES (2001b, pp. 13-17); OECD (2004); GuzmÃ¡n and Marcel (2008, pp. 312â&#128;&#147;314).&#13;
5&#13;
 For more background see ComitÃ© Interministerial de la ModernizaciÃ³n de la GestiÃ³n PÃºblica (2000) and&#13;
Ministerio Secretaria General de la Presidencia (2006).&#13;
&#13;
&#13;
                                                                                                            9&#13;
&amp;#12;The first stage was experimental, in both technical-operational and institutional terms. Adequate&#13;
support was not yet in place, and there was a lack of continuity in implementation, but at least&#13;
there were no major political obstacles. This stage was characterized by the first steps in the&#13;
development of performance indicators in 1993 and the introduction of the first program&#13;
evaluations in 1997. The indicators tool was established through the work initiated in 1993, in the&#13;
form of a pilot implementation in five agencies, called â&#128;&#156;Public Servicesâ&#128;&#157; in Chile, and referred to as&#13;
the Pilot Plan for Modernizing Public Service Management (DIPRES 1993, 1995). 6 Despite its&#13;
limitations, this stage generated the first set of lessons to be used in implementing the actual&#13;
system.&#13;
&#13;
The second stage ranged from 2000 to 2010. It included perfecting, expanding, and coordinating&#13;
methodologies and instruments to shape the M&amp;E system. Most importantly, in this stage,&#13;
performance information generated by the system was integrated into analysis and decision-&#13;
making processes, a scenario that continues until 2014, with different mechanisms implemented&#13;
by each government. Additionally, during 2003-05 the M&amp;E system was expanded in terms of the&#13;
number of agencies constructing indicators, the number of indicators per agency, and the number&#13;
of evaluations conducted. From 2006 to 2010, the process of consolidating and institutionalizing&#13;
the M&amp;E system continued, while more innovations in the types of evaluations were introduced.&#13;
&#13;
1.2 Institutional Arrangements and System Operations&#13;
&#13;
1.2.1    Primary Characteristics of Responsible Organizational Unit 7&#13;
&#13;
In 2000 the Ministry of Financeâ&#128;&#153;s Management Control Division had two units operating the M&amp;E&#13;
system: the Management and Evaluation Departments. The Management Control Division was&#13;
initially composed of a total of 11 professionals including the department heads. The&#13;
Management Department had four professionals and the Evaluation Department had six, all&#13;
dedicated to administering the evaluations and related activities (see Figure 1).&#13;
&#13;
&#13;
&#13;
&#13;
6&#13;
 Junta de Auxilia Escolar y Becas (Board of School Assistance and Scholarships); Servicio Nacional de&#13;
CapacitaciÃ³n y Empleo (National Training and Employment Service); Servicio AgrÃ­cola y Ganadero&#13;
(Agricultural and Livestock Service); DirecciÃ³n de Bibliotecas, Archivos y Museos (Libraries, Archives and&#13;
Museums Office), and DirecciÃ³n General de Deportes y RecreaciÃ³n (Sports and Recreation Office).&#13;
7&#13;
 The author appreciates the background information on the work team sent by DIPRES, particularly by the&#13;
authorities in the Management Control Division.&#13;
&#13;
&#13;
                                                                                                             10&#13;
&amp;#12;Figure 1: DIPRES Organizational Structure&#13;
&#13;
&#13;
                                                       Budget Director&#13;
&#13;
&#13;
&#13;
&#13;
                              Division of                                        Assistant Director&#13;
                                                            Assistant Director&#13;
                             Management                                          of Rationalization&#13;
                                                              of the Budget&#13;
                               Control                                           and Public Service&#13;
&#13;
&#13;
&#13;
&#13;
                  Department of        Department of&#13;
                                                           Budgetary Sectors&#13;
                    Evaluation         Management&#13;
&#13;
&#13;
&#13;
As part of the diversification of the systemâ&#128;&#153;s tools, capacities were enhanced throughout the&#13;
decade. By the end of 2005, the team was composed of 16 professionals, including department&#13;
heads, and it was benefiting from institutional support from outside the division in the areas of&#13;
design and administration of information systems and application of information technologies. By&#13;
2010 the number of professionals in the same departments more than doubled, to 23; plus there&#13;
were 4 additional professionals in the new Technical Assistance Department, which was also&#13;
responsible for the evaluations of new programs.&#13;
By 2010, 19 of the 27 professionals responsible for the M&amp;E system were DIPRES functionaries&#13;
(full-time, regular employees) and the remaining 8 received professional fees, through contracts,&#13;
for their work. As for their backgrounds, 14 were commercial engineers and 5 were industrial&#13;
engineers. Twenty had studied at the graduate level, mostly in economics, public policy, and&#13;
public management, and six had taken professional courses beyond their university degrees in&#13;
areas complementing their work, with support from DIPRES.&#13;
In addition to their formal studies and work experience, the professionals have been provided&#13;
with various internal learning activities and have attended workshops and talks with Public&#13;
Services. In addition, department heads have participated in relevant international conferences&#13;
on M&amp;E systems with the opportunity to exchange experiences with other experts.&#13;
&#13;
1.2.2   Roles of the National Auditing Office and Civil Society&#13;
&#13;
The Comptroller Generalâ&#128;&#153;s Office carries out external audits. These are exclusively financial&#13;
audits, as this entity does not conduct performance or cost-effectiveness audits.&#13;
Civil society organizations are passively involved in the M&amp;E system, connected only through&#13;
access to public information. With regard to beneficiaries, such as citizens directly linked with the&#13;
various program areas of government, the evaluation methodologies focus on evaluating the&#13;
quality of goods and/or services delivered. Therefore, the evaluation process reviews the&#13;
availability of information in these aspects and also reports on the perceptions of&#13;
citizens/beneficiaries in relation to the services delivered.&#13;
&#13;
                                                                                                      11&#13;
&amp;#12;1.2.3      Integration of Information into Decision-Making Processes&#13;
&#13;
The objective of Chileâ&#128;&#153;s M&amp;E system is to integrate information into analytical processes and to&#13;
use that information, together with other financial background information and policy priorities,&#13;
to support decision-making. This acknowledges the difficulties in ascertaining the impact of public&#13;
actions and therefore the caution that must be taken in the use of information.&#13;
&#13;
Information from evaluations has been useful in reporting to the executive and in decision-making&#13;
processes at that level. The various forms of evaluation systematize performance information,&#13;
explain its causes, and present recommendations for actions to be taken. At the same time,&#13;
information on performance indicators, their targets, and the extent to which those targets are&#13;
met has been less useful in decision-making.&#13;
&#13;
1.3 M&amp;E Components&#13;
The Chilean M&amp;E system was founded on two components: indicators and evaluations. The&#13;
primary functions of DIPRES with regard to indicators include: technical support to Public Services.&#13;
in their development; their review, with assistance from DIPRESâ&#128;&#153;s specialists on sector-based&#13;
budgets; their presentation in the budget preparation stage; the technical construction of targets&#13;
and their requirement levels; the evaluation of target compliance; the preparation of documents&#13;
to report and disseminate indicators, their targets, and their compliance; and the incorporation of&#13;
improvements into the tool and its implementation processes.&#13;
Evaluations are conducted by external professionals who are selected through public bidding&#13;
processes. DIPRES is responsible for assuring the quality and use of evaluations, especially serving&#13;
as a counterpart for the technical and operational processes in conducting evaluations, from the&#13;
preparation of terms of reference for evaluators to the final approval of reports.&#13;
In addition to the evaluation methodologies presented in the current sections, in 2001 the ex ante&#13;
evaluation was introduced. This type of evaluation consists on the design review for new and&#13;
modified programs presented each year to the budget. This kind of evaluation has evolved over&#13;
the years and its current mechanisms are presented in the next chapter, for the period 2010-&#13;
2014.&#13;
&#13;
1.3.1      Indicators&#13;
&#13;
1.3.1.1 Dimensions and Delivery Levels 8&#13;
&#13;
The monitoring system is implemented through a set of institutional arrangements that establish&#13;
the roles and functions of the different stakeholders. The conceptualization and taxonomy of&#13;
indicators uses two conceptsâ&#128;&#148;performance dimensions and â&#128;&#156;delivery levelsâ&#128;&#157;â&#128;&#148;defined by the&#13;
steps in the â&#128;&#156;value chainâ&#128;&#157; (see Figure 2).&#13;
&#13;
&#13;
8&#13;
    For more background, see GuzmÃ¡n (2005); Arenas and Berner (2010).&#13;
&#13;
&#13;
                                                                                                  12&#13;
&amp;#12; The performance indicators and targets constitute annexes accompanying the presentation of the&#13;
 Draft Budget Law to the National Congress. The development of indicators, unlike evaluations, is&#13;
 carried out only on the basis of administrative instructions. A legal framework has not been&#13;
 required, and an Inter-ministerial Committee has not been established, as in the case of&#13;
 evaluations. This committee is described in section 1.3.2.2.&#13;
&#13;
 Figure 2: Delivery Areas: The Steps in the â&#128;&#156;Value Chainâ&#128;&#157;&#13;
&#13;
&#13;
&#13;
&#13;
                                            Intermediate                Final Result/&#13;
     Process            Product&#13;
                                                Result                    Impact&#13;
&#13;
&#13;
&#13;
&#13;
 Monitoring is organized around performance dimensions and steps in the delivery areas of the&#13;
 value chain. The objective is to examine the performance dimensions of efficiency, effectiveness,&#13;
 economy, and quality, depending on which of these is most relevant to each step, as illustrated in&#13;
 Table 1.&#13;
&#13;
 Table 1: Performance Dimensions and Delivery Areas&#13;
&#13;
                                                   Delivery areas&#13;
Performance&#13;
                                                                            Results&#13;
dimension&#13;
                        Process        Product (Output)&#13;
                                                             Intermediate               Final&#13;
&#13;
Efficiency                 X                   X&#13;
&#13;
Effectiveness                                  X                    X                    X&#13;
&#13;
Economy                    X&#13;
&#13;
Quality                                        X&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                 13&#13;
&amp;#12;1.3.1.2 Overview of Stakeholders and Functions&#13;
&#13;
There are three stakeholders involved with the indicatorsâ&#128;&#153; tool: the agencies or Public Services,&#13;
DIPRES, and the National Congress. Each performs different functions, as described below:&#13;
&#13;
    â&#128;¢ Public Services: Participate directly in formulating performance indicators and targets.&#13;
    Each Public Service must present these elements, together with its budget proposal, to&#13;
    DIPRES, and they carry out the final analysis and selection of the indicators jointly. Each public&#13;
    service must report on their compliance with established targets at the end of each year and&#13;
    when requested must present background information on the means used to verify what has&#13;
    been reported.&#13;
&#13;
    â&#128;¢ DIPRES: Analyzes proposals for indicators, taking technical requirements into&#13;
    consideration and examining the degree of consistency between proposed targets and&#13;
    allocated resources; makes comments that are discussed with the Public Services and&#13;
    incorporated into a proposal; prepares reports to be presented to Congress; implements&#13;
    changes; registers the changes occurring during the year due to external factors; follows up&#13;
    on compliance with targets; and prepares reports on its work to send to authorities in&#13;
    ministries and Public Services, the National Congress and the general public through its&#13;
    website.&#13;
&#13;
    â&#128;¢ Congress: Through the Special Joint Budget Committee (ComisiÃ³n Especial Mixta de&#13;
    Presupuestos) and Budget Subcommittees (Subcomisiones de Presupuesto) receives reports&#13;
    on the formulation of indicators and targets and is informed of compliance with targets at&#13;
    yearâ&#128;&#153;s end.&#13;
&#13;
1.3.1.3 Selection Process and Formulation of Indicators for Monitoring&#13;
Every year during the budget formulation process, each public service presents a set of indicators&#13;
in line with technical guidelines that have been presented by DIPRES (DIPRES 2009a, Formulario&#13;
H). For most agencies, these indicators come from their management information systems&#13;
(Sistemas de InformaciÃ³n de GestiÃ³n). 9&#13;
&#13;
DIPRES, particularly the Management Control Division, reviews the presentations of indicators&#13;
and makes comments primarily on technical aspects â&#128;&#147; referring to the construction of indicators â&#128;&#147;&#13;
and relevance aspects â&#128;&#147; considering the strategic outputs to which the indicators are linked and&#13;
the performance dimensions to be measured. Also in this review, new indicators are suggested or&#13;
required.&#13;
&#13;
9&#13;
 The management information systems are part of the management improvement programs instrument in&#13;
each public service (see DIPRES 2009b, p. 40). Most of the public services. included in the Budget Law must&#13;
prepare an improvement program. Exceptions are the superintendentsâ&#128;&#153; offices, the Comptroller Generalâ&#128;&#153;s&#13;
Office (ContralorÃ­a General de la RepÃºblica), Congress, Defense Services, and Health Services. Some of these&#13;
are covered by other incentive mechanisms.&#13;
&#13;
&#13;
                                                                                                         14&#13;
&amp;#12;The presentation of each indicator is accompanied by target proposals, or performance&#13;
commitments. After indicators have been selected, the corresponding targets are reviewed in&#13;
light of the budget resources allocated for the corresponding area. The purpose of this review is&#13;
to ensure consistency between targets and resources. Prior to presenting the draft law to&#13;
Congress, the Management Control Division consults with specialists in the various budget sectors&#13;
within DIPRES to align resources with targets for the indicators selected and to ensure that targets&#13;
are ambitious but feasible.&#13;
&#13;
Reviews and observations sometimes require clarifications that are worked out through&#13;
interactions between the technical teams in Public Services and in DIPRES. If differences persist&#13;
between these technical teams, they are resolved among the authorities of the respective&#13;
organizations; however, as of 2014, this has only rarely been necessary.&#13;
&#13;
The process continues with the presentation of the indicators and targets that accompany the&#13;
draft Budget Law. Members of the Special Joint Budget Committee and Budget Subcommittees&#13;
may request changes to the indicators presented, or the indicators and their targets may be&#13;
modified in line with changes in budget allocations. After budget allocations have been&#13;
established in the Budget Law, DIPRES reviews and adjusts targets in accordance with the final&#13;
resources allocated.&#13;
&#13;
If during the fiscal year there are factors external to the management of Public Services that&#13;
prevent compliance with the particular targets defined, this situation is reported to DIPRES, and if&#13;
they are verified, DIPRES eliminates them from the evaluation of compliance. 10&#13;
&#13;
1.3.1.3 Scope of Indicators&#13;
The number of agencies participating in the presentation of indicators increased from 2001 to&#13;
2010, from 72 to 150. The average number of indicators per agency grew from 3.8 in 2001 to 12.8&#13;
in 2004 and then decreased to an average of 8.6 indicators in the 2010 budget. This decrease was&#13;
a result of efforts to seek a balance between quantity and quality (see Table 2).&#13;
Table 2: Agencies and Average Indicators per Agency, 2001-10&#13;
&#13;
        Year        Indicators         Number of agencies                Average per agency&#13;
&#13;
        2001           275                     72                                3.8&#13;
&#13;
        2002           537                     109                               4.9&#13;
&#13;
        2003          1039                     111                               9.4&#13;
&#13;
        2004          1684                     132                              12.8&#13;
&#13;
        2005          1588                     133                              11.9&#13;
&#13;
&#13;
&#13;
10&#13;
  In 2010, the number of changes required was the highest since the indicators work began, because of the&#13;
effects of the February 2010 earthquake, which significantly altered government priorities.&#13;
&#13;
&#13;
                                                                                                      15&#13;
&amp;#12;           Year       Indicators         Number of agencies                   Average per agency&#13;
&#13;
           2006          1552                     136                                 11.4&#13;
&#13;
           2007          1445                     139                                 10.4&#13;
&#13;
           2008          1443                     142                                 10.2&#13;
&#13;
           2009          1504                     150                                 10.0&#13;
&#13;
           2010          1274                     150                                  8.6&#13;
&#13;
           Source: DIPRES.&#13;
&#13;
1.3.2      Evaluation&#13;
&#13;
1.3.1.2 Methodology&#13;
&#13;
Since 1997 the government has implemented different types of program and institutional&#13;
evaluations. Among the ex post types of evaluation, the Evaluation of Government Programs&#13;
(EvaluaciÃ³n de Programas Gubernamentales) was inaugurated in 1997, using rapid or desk&#13;
evaluations. In 2001 Impact Evaluations (EvaluaciÃ³n de Impacto) were incorporated, and the&#13;
following year, Institutional Evaluations (Evaluaciones Institutcionales) and Comprehensive&#13;
Spending Review (EvaluaciÃ³n Comprehensiva del Gasto), were introduced. Finally, in 2009 the&#13;
Evaluation of New Programs (EvaluaciÃ³n de Programas Nuevos) was added.&#13;
&#13;
       (a) Rapid or Desk Evaluations of Government Programs (Based on Logic Frameworks)&#13;
&#13;
Evaluations of government programs are based on the basic concepts of the Logical Framework&#13;
Matrix (Matriz de Marco LÃ³gico), 11 complemented by the review of a set of program-specific&#13;
topics. These evaluations mostly use available information 12 or background information that may&#13;
be systematized in the short term, as well as interviews with key stakeholders. In some cases the&#13;
application of other qualitative mechanisms, primarily group interviews and simple surveys, are&#13;
also used.&#13;
&#13;
The evaluation begins with the development of a logical framework matrix that includes different&#13;
levels of program objectives, specifying the goals, purposes, components, primary activities and&#13;
the corresponding performance indicators.&#13;
&#13;
After the matrix has been constructed, the evaluation focuses on obtaining information on the&#13;
following topics:&#13;
&#13;
â&#128;¢      Justification. An analysis of the diagnostic assessment or the problem that gave rise to the&#13;
       program and that the program intends to resolve (or contribute to resolving).&#13;
&#13;
11&#13;
     The matrix was adapted to meet the needs for conceptual unity and presentation across programs.&#13;
12&#13;
  Legal information, official documents, administrative instructions, prior studies, indicators, financial&#13;
information, statistics, and other data.&#13;
&#13;
&#13;
                                                                                                             16&#13;
&amp;#12;â&#128;¢    Design. An analysis of the sequence and consistency of the programâ&#128;&#153;s components and&#13;
     activities, considering its goals and purposes. An analysis of the matrixâ&#128;&#153;s vertical logic is used&#13;
     in this process.&#13;
&#13;
â&#128;¢    Organization and management. An assessment of the main institutional aspects through&#13;
     which the program operates, 13 as well as the main work processes, coordination within the&#13;
     agency and among agencies, when applicable, and the available instruments for carrying out&#13;
     activities.&#13;
&#13;
â&#128;¢    Performance. An evaluation of the effectiveness, efficiency, and economy of the program, and&#13;
     its processes, products (outputs), and intermediate and final results. The evaluation is carried&#13;
     out by applying the horizontal logic of the matrix.&#13;
&#13;
â&#128;¢    Sustainability/continuity. An assessment of judgments on the programâ&#128;&#153;s sustainability in&#13;
     terms of institutional capacities and the need (or lack of need) for its continuity, in line with&#13;
     its evolution.&#13;
&#13;
â&#128;¢    Conclusions and recommendations. An identification of the weaknesses and deficiencies&#13;
     affecting program performance and suggests actions for improving the program, in&#13;
     institutional-organizational, design, and/or management (operational) aspects.&#13;
&#13;
     (b) Impact Evaluations&#13;
&#13;
The objective of ex post impact evaluations is to measure a programâ&#128;&#153;s net effects on its&#13;
beneficiaries. It looks at differences with respect to baselines (initial diagnostic assessments) and&#13;
compares these differences to those of comparators to isolate any external effects from the&#13;
results.&#13;
&#13;
Although the main focus in impact evaluations has been to measure the final effects of programs,&#13;
during the first period this was expanded in Chile to include the review and evaluation of specific,&#13;
complementary topics, to examine other categories of information that assist in understanding&#13;
the observed results. Depending on the need for information by specific agencies, the areas&#13;
reviewed were similar to those described in the previous section.&#13;
&#13;
     (c) Comprehensive Spending Reviews&#13;
&#13;
&#13;
&#13;
&#13;
13&#13;
  Evaluation covers the characteristics of the organizational unit responsible for the program, considering&#13;
primarily its functions, where it is positioned within the organizational structure, its own structure of&#13;
subunits and the responsibilities designated for each of them, and the corresponding personnel.&#13;
&#13;
&#13;
                                                                                                          17&#13;
&amp;#12;A comprehensive spending review is an evaluation of the entirety of an organization or agency,&#13;
primarily using available information 14 or background information, as well as interviews with key&#13;
stakeholders, and the application of simple qualitative studies.&#13;
&#13;
The objective of this type of evaluation is to evaluate the set of programs and procedures&#13;
administered by the organization, organized within the following topics or categories of&#13;
information:&#13;
&#13;
     â&#128;¢ Institutional design. Covers the consistency between government priorities, mission,&#13;
     strategic objectives, outputs, and beneficiaries. On the basis of these elements, the rationality&#13;
     of the institutionâ&#128;&#153;s structure and the distribution of functions among the various work units&#13;
     making up the entity or the public service are evaluated.&#13;
&#13;
     â&#128;¢ Institutional management. Includes institutional capacity (professional, technological,&#13;
     organizational, and so forth) and management mechanisms or procedures that are applicable&#13;
     and relevant for the organization, such as mechanisms for coordination and designation of&#13;
     responsibilities, for allocation and transfer of funds and payment modalities, and for auditing&#13;
     and transparency in use of funds; M&amp;E instruments; and criteria for selecting beneficiaries.&#13;
&#13;
     â&#128;¢ Results and use of funds. Covers the results of strategic outputs and sub-outputs and&#13;
     linking these results to funds allocated for providing these benefits.&#13;
&#13;
     â&#128;¢ Conclusions and recommendations. As in other types of evaluation, it is important to&#13;
     present conclusions and recommendations for future actions.&#13;
&#13;
     (d) Evaluations of New Programs&#13;
&#13;
Evaluations of new programs use sophisticated methods and processes and are therefore very&#13;
strict in terms of technical abilities and process management. This type of evaluation is focused on&#13;
programs in an early implementation stage. Its purpose is to strengthen program design and to&#13;
develop the design of an ex post impact evaluation. It identifies the relevant baseline for the&#13;
program and establishes control or comparison groups, in line with the characteristics of the&#13;
particular situation. It also constructs rigorous information systems for collecting the required&#13;
data.&#13;
&#13;
&#13;
&#13;
&#13;
14&#13;
  Legal information, strategic and programmatic definitions, institutional minutes and reports, prior&#13;
studies, official documents, financial information, indicators, and other data.&#13;
&#13;
&#13;
                                                                                                        18&#13;
&amp;#12;1.3.2.2 Overview of Stakeholders and Functions&#13;
Since the various evaluation initiatives were created, they have been part of the agreement&#13;
protocols signed between the National Congress and the Ministry of Finance when the Budget&#13;
Law is approved each year. In addition, since in 2004, the Ministry of Finance has been required&#13;
by law to conduct evaluations of the programs that receive funds from public service budgets. 15&#13;
There are five main stakeholders involved in evaluation: an Interministerial Committee, DIPRES,&#13;
evaluators, the Public Services, and the National Congress. Each of these stakeholders performs&#13;
different functions.&#13;
&#13;
     â&#128;¢   Interministerial Committee. The purpose of the Committee is to assure that evaluations&#13;
         are conducted in a way that is consistent with government policies, that the conclusions&#13;
         from this process are made known to the agencies involved, and that the necessary&#13;
         technical support and coordination are available in order for evaluations to take place&#13;
         smoothly. This committee is made up of one representative from the Ministry of the&#13;
         Secretariat of the Presidency, one representative from the Ministry of Planning&#13;
         (MIDEPLAN), and one representative from the Ministry of Finance, through DIPRES, with&#13;
         the last presiding over the committee.&#13;
&#13;
     â&#128;¢   DIPRES. DIPRES is responsible for conducting all types of evaluations. Its other&#13;
         responsibilities include defining methodological and operational designs; providing&#13;
         resources; managing evaluation operations; analyzing and approving progress and final&#13;
         reports; receiving and sending evaluation reports to the respective entities (Executive&#13;
         Branch and National Congress); preparing comprehensive reports; integrating the results&#13;
         into the budget cycle; and monitoring institutional commitments made on the basis of the&#13;
         conclusions and recommendations of the evaluations.&#13;
&#13;
     â&#128;¢   Evaluators. External evaluators, who may be individual consultants, firms, or universities,&#13;
         are responsible for conducting technical evaluations in accordance with the procedures&#13;
         defined by DIPRES.&#13;
&#13;
     â&#128;¢   Agencies or Public Services evaluated. The agencies responsible for the programs&#13;
         evaluated or that are being evaluated are in a process through which they:&#13;
&#13;
          o      Participate in activities to transmit and disseminate information on&#13;
                 methodological aspects of the evaluations.&#13;
&#13;
          o      Prepare information from the program or agency to be presented to the&#13;
                 evaluating team.&#13;
&#13;
&#13;
&#13;
&#13;
15&#13;
  Law No. 19.896 of 2003, which amends the Financial Administration Act of the State and its Regulations&#13;
(Decree 1175 of December 2003).&#13;
&#13;
&#13;
                                                                                                       19&#13;
&amp;#12;          o     In the case of rapid or desk evaluations of government programs, develop the&#13;
                preliminary logical framework matrix to be presented to the evaluating panel as&#13;
                initial information. In the case of Comprehensive Spending Reviews, develop the&#13;
                preliminary evaluation matrix.&#13;
&#13;
          o     Participate in all meetings requested by the evaluators and DIPRES to analyze any&#13;
                matters arising during the evaluation process.&#13;
&#13;
          o     Analyze and issue comments on the intermediate and final evaluation reports.&#13;
&#13;
          o     Prepare a response to each final evaluation report.&#13;
&#13;
          o     Establish agency commitments to improve programs on the basis of evaluation&#13;
                recommendations.&#13;
&#13;
          o     Report on compliance with institutional commitments in follow-up processes.&#13;
&#13;
    â&#128;¢   National Congress. The Special Joint Budget Committee and Budget Subcommittees&#13;
        receive the evaluation reports for their information and use.&#13;
&#13;
1.3.2.3 Selection of Programs and Agencies to Be Evaluated&#13;
The selection of programs and agencies to be evaluated each year is determined using different&#13;
types of data and qualitative judgments based on:&#13;
&#13;
â&#128;¢ Background information on performance that DIPRES has access to, as a result of its budget&#13;
  and management control functions.&#13;
&#13;
â&#128;¢ Whether a program or agency has already been evaluatedâ&#128;&#148;in the framework of the&#13;
  evaluation program operated by DIPRES or other evaluation processesâ&#128;&#148;and the year in which&#13;
  such evaluation was conducted.&#13;
&#13;
â&#128;¢ Other background information on performance, such as financial indicators.&#13;
&#13;
â&#128;¢ For existing programs, prospects for program implementation and priorities.&#13;
&#13;
â&#128;¢ For new programs, their political-programmatic importance and the resources involved.&#13;
&#13;
â&#128;¢   Recommendations from the Ministry of the Secretariat of the Presidency and Ministry of&#13;
    Planning, both members of the Inter-ministerial Evaluation Committee.&#13;
&#13;
â&#128;¢    Recommendations from the Special Joint Budget Committee and Budget Subcommittees from&#13;
    the proceedings on the draft budget law in Congress.&#13;
&#13;
Taking into consideration the aspects and elements described, DIPRES jointly prepares a proposal&#13;
for programs and agencies to be evaluated. This proposal is analyzed jointly with members of the&#13;
&#13;
&#13;
&#13;
                                                                                                 20&#13;
&amp;#12;Special Joint Budget Committee of the National Congress in the context of preparing an&#13;
Agreement Protocol each year.&#13;
&#13;
All evaluations are conducted by non-public entities, selected through public bidding processes.&#13;
For Evaluations of Government Programs, the work is carried out with evaluation panels&#13;
comprised of three professionals: an expert in evaluation, an expert in the sector or program area&#13;
to be evaluated, and an expert in management and administration of public programs. In the&#13;
cases of Impact Evaluations and Comprehensive Spending Reviews, the work is carried out with&#13;
universities or private consulting firms, as such evaluations are more complex. Evaluations of New&#13;
Programs are conducted by universities, with methodological advice from a panel of international&#13;
experts. Evaluations of Government Programs take approximately six months, and the cost is&#13;
approximately $35.0000. Impact Evaluations required onsite work and were thus more expensive,&#13;
at $80,000-100,000. Comprehensive Spending Reviews are conducted over 9-12 months, and the&#13;
cost varies, depending on the amount of spending and complexity of each agency evaluated.&#13;
&#13;
After DIPRES approves the final evaluation reports, they are sent to the National Congress for use&#13;
by the budget committees. The reports also are made public on the DIPRES website.&#13;
&#13;
1.3.2.4 Scope of Evaluations&#13;
There also was an increase in the annual number of evaluations, particularly in 2006â&#128;&#147;10. In 2010&#13;
there were 18 evaluations of government programs in process, increasing the total number of&#13;
programs evaluated during 1997-2010 to 255. In the same year, 14 impact evaluations were&#13;
initiated; consequently, a total of 85 programs were evaluated using this methodology in 2001-10.&#13;
In addition, four Comprehensive Spending Reviews were being initiated in 2010, bringing the total&#13;
number of agencies evaluated in this category to 44 in 2002-10. Finally, nine programs were being&#13;
evaluated with the Evaluation of New Programs methodology (see Table 4). In terms of public&#13;
spending, the evaluations of programs and agencies conducted in 2006-10 represent, on average,&#13;
9 percent of the national budget for each year. 16&#13;
Table 4: Variation in Number of Evaluations, 1997-2010&#13;
&#13;
        Type of         1997-                                  2003-     2006-&#13;
                                  2000      2001      2002                          2009   2010   Total&#13;
       evaluation       1999                                   2005      2008&#13;
 Evaluation of&#13;
 government               80        18       19        15        42        43       20     18     255&#13;
 programs&#13;
 Impact&#13;
                                              2         4        24        33        8     14      85&#13;
 evaluation&#13;
 Evaluation of&#13;
                                                                                     5      4      9&#13;
 new programs&#13;
&#13;
&#13;
16&#13;
     Figure calculated by author on the basis of Arenas and Berner (2010, p. 46).&#13;
&#13;
&#13;
                                                                                                        21&#13;
&amp;#12;      Type of        1997-                                 2003-    2006-&#13;
                              2000       2001     2002                        2009      2010     Total&#13;
     evaluation      1999                                  2005     2008&#13;
 Comprehensive&#13;
 spending                                           8       11        13        5         7        44&#13;
 review&#13;
 Total             80      18       21      27       77      89                 38       43       393&#13;
 Annual&#13;
                   27      18       21      27      25.6    28.6                38       43        28&#13;
 average&#13;
       Source: Developed by author based on DIPRES information.&#13;
&#13;
1.4 Use of M&amp;E Information&#13;
&#13;
1.4.1   Indicators&#13;
&#13;
1.4.1.1 Reporting Commitments and Compliance&#13;
&#13;
The purpose of the information derived from indicators and their targets is to be used to report&#13;
agency/program performance commitments during the fiscal year with regard to a significant&#13;
number of goods and services provided; at yearâ&#128;&#153;s end there is a report on the level of compliance&#13;
achieved. This reporting is made to authorities directly responsible for performance&#13;
commitments, budget authorities, Congress, and other stakeholders who access the documents.&#13;
&#13;
1.4.1.2 Links with Performance Bonuses&#13;
&#13;
The Management Improvement Programs (Programas de Mejoramiento de GestiÃ³n), particularly&#13;
the Management Planning and Control system component, link compliance with indicator targets&#13;
included in the budget to performance bonuses for central government employees. This system,&#13;
together with nine 13 other systems, is used in the programâ&#128;&#153;s total assessment. The â&#128;&#156;indicators&#13;
target scoreâ&#128;&#157; accounts for a minimum of 5 percent and a maximum of 55 percent of the total&#13;
score of the Management Improvement Program for the agency or program. 17&#13;
&#13;
1.4.1.3 Use in Relation to Evaluations&#13;
&#13;
Indicators also have been used in the processes of evaluating programs and agencies. In the&#13;
framework of applied methodologies, indicators are part of the available information and provide&#13;
information on performance in some areas, helping guide the evaluation process. Additionally,&#13;
because programs and agencies are not evaluated every year, indicators are the only performance&#13;
&#13;
&#13;
17&#13;
  This link was modified in 2000, from an assessment conducted only in regard to compliance with indicator&#13;
targets, without linking this information to the budget, to one that includes a portion of this assessment&#13;
into the budget. The Management Planning and Control system most frequently has a weight of between&#13;
10 and 15 percent of the total Programas de Mejoramiento de GestiÃ³n. For more background, see GuzmÃ¡n&#13;
(2005) and Arenas and Berner (2010).&#13;
&#13;
&#13;
                                                                                                        22&#13;
&amp;#12;information that can be observed regularly, so they contribute to the follow-up of the&#13;
performance of the programs and agencies evaluated.&#13;
&#13;
Target compliance is used to identify areas that have unacceptable performance, and therefore&#13;
indicators are considered in the selection process to evaluate programs or agencies. Indicators as&#13;
a tool do not explain the causes or factors that determine the values. The evaluations collect&#13;
more information on performance and its causes and can contribute to improving the program or&#13;
agencies.&#13;
&#13;
1.4.2   Evaluations&#13;
&#13;
1.4.2.1 Reporting Evaluation Results&#13;
&#13;
Evaluations have been useful in providing program and agency performance information to&#13;
budget authorities, to authorities in the ministries responsible for them, to other ministries&#13;
through the Inter-ministerial Committee, Congress, communications media, and the public. The&#13;
primary channels are the following:&#13;
&#13;
â&#128;¢   Sending the completed reports of evaluations conducted during the annual budget cycle to&#13;
    Congress and publishing them on the DIPRES website.&#13;
&#13;
â&#128;¢   Presenting summaries of evaluations conducted during the annual budget cycle, and of&#13;
    compliance with institutional commitments from previous evaluations, together with the&#13;
    draft budget law to Congress.&#13;
&#13;
â&#128;¢   Presenting summaries of evaluations conducted during the year and of compliance with&#13;
    institutional commitments from previous evaluations in the Public Finances Report, a&#13;
    publication sent to Congress every year and available to the public.&#13;
&#13;
â&#128;¢   Presenting summarized information from evaluations in the Financial Management&#13;
    Evaluation, a publication presented to Congress every year and available to the public.&#13;
&#13;
1.4.2.2 Support to Resource Allocation and Improvement in the Quality of Public Spending&#13;
&#13;
One way to make use of evaluations is to integrate the information they provide into the budget&#13;
cycle; this has been carried out in different areas. Based on a review of evaluation results in the&#13;
DIPRES, the agency has been leading the following activities, both, in the period 1990-2010 and&#13;
2010-2014:&#13;
&#13;
â&#128;¢   Identifying the implications of the primary evaluation recommendations for the programs&#13;
    evaluated, analyzing their effects, and classifying them into five categories (see Table 5).&#13;
&#13;
â&#128;¢   Defining guidelines for establishing commitments to improve the programs and agencies&#13;
    evaluated.&#13;
&#13;
&#13;
&#13;
                                                                                                   23&#13;
&amp;#12; â&#128;¢    Identifying implications for budgets from adjustments determined in the evaluation, or&#13;
      budget increases if justified by findings and if financial resources are available.&#13;
&#13;
 â&#128;¢    Incorporating background information on evaluations at the Technical Committee 18 meetings&#13;
      during the budget formulation process, to analyze and establish the grounds for decisions&#13;
      among DIPRES and the ministries and their agencies.&#13;
&#13;
 â&#128;¢    Presenting the completed evaluation reports to Congress, and their executive reports,&#13;
      together with the draft budget law, for analysis, together with background information on&#13;
      their financial performance.&#13;
&#13;
 â&#128;¢    Presenting evaluation information and data on compliance with improvement commitments&#13;
      to DIPRESâ&#128;&#153; Management and Financial Evaluation.&#13;
&#13;
 Table 5: Recommendations â&#128;&#147; Implications for Evaluated Programs, 2000-2009&#13;
&#13;
                                                                         Number of         Percentage of&#13;
Effect categories&#13;
                                                                         Programs          Programs&#13;
&#13;
Minor adjustments                                                              50                24&#13;
&#13;
Modifications in the design and/or management processes                        76                37&#13;
internal to the program&#13;
&#13;
Substantial redesign of the program                                            54                26&#13;
&#13;
Institutional relocation                                                       13                 6&#13;
&#13;
End or replacement of the program                                              15                 7&#13;
&#13;
Total programs                                                                208                100&#13;
&#13;
 Source: 2010 Public Finances Report (Informe de Finanzas PÃºblicas 2010), DIPRES.&#13;
&#13;
 In many cases, evaluations have important budgetary implications. For example, a 2004&#13;
 evaluation of a program to provide oral health services to vulnerable and marginalized students in&#13;
 elementary schools found a 98 percent reduction in cavities among students served after just one&#13;
 year. As a result, the budget was increased to support expanded coverage (DIPRES y Banco&#13;
 Interamericano de Desarrollo 2005a). By contrast, an evaluation of a community media center&#13;
 program in 2003 found that, although the program had increased access to information&#13;
 technology and communications, it had lost part of its original focus on its target beneficiaries. As&#13;
&#13;
 18&#13;
   Technical committee meetings are held between the DIPRES and each public service (ministry/agency)&#13;
 whose budget is included in the Budget Law. The meetings are held every year while the draft budget law is&#13;
 being developed. At these meetings ministry and other authorities present the priorities and technical&#13;
 aspects that serve as the basis for their budget proposals for the following year.&#13;
&#13;
&#13;
                                                                                                        24&#13;
&amp;#12;a result, program resources were redirected to focus on providing quality connectivity and&#13;
network expansion to poor, rural, and isolated areas (DIPRES y Banco Interamericano de&#13;
Desarrollo 2005b).&#13;
&#13;
1.4.2.3 Commitments to Improvements&#13;
&#13;
After the budget for the following fiscal year is approved, and based on the analysis of the effects&#13;
and implications from the evaluation, DIPRES and each responsible agency start to work on&#13;
developing the improvements committed to in light of the evaluations. These are known as&#13;
Institutional Commitments; they are formal agreements. They establish a work timeline for&#13;
implementing the primary design, organizational, and/or management modifications arising from&#13;
the evaluation. Later, DIPRES conducts semiannual follow-up to verify compliance with the&#13;
commitments. Since 2009, the commitments and results have been made public on the DIPRES&#13;
website.&#13;
&#13;
&#13;
2   Monitoring and Evaluation System: 2010-14&#13;
&#13;
2.1 Introduction&#13;
The Chilean M&amp;E System during 2010-14 continues to be led by DIPRES and in particular by its&#13;
Public Management Control Division. However, during this period the system has experienced a&#13;
series of modifications related to the simplification of monitoring instruments through a decrease&#13;
on the number of indicators, the incorporation of new actors, and the strengthening of a strategic&#13;
focus on performance for budget implications.&#13;
&#13;
This section focuses on the description and analysis of the principal changes in M&amp;E that have taken&#13;
place since 2010. It provides a broader perspective on the traditional role of DIPRES, principally&#13;
reviewing the roles developed by the newly created Ministry of Social Development (MDS) and the&#13;
presidential priorities monitoring system originating in the center of the government.&#13;
&#13;
During 2011, the Chilean government requested the Organisation for Economic Co-operation and&#13;
Development (OECD) to conduct a review of budget management in Chile: â&#128;&#156;Review of selected&#13;
Budgeting issues in Chileâ&#128;&#157; (OECD, 2012). This report found that â&#128;&#156;the framework of results-based&#13;
budgeting in Chile is very advanced and is dealing with issues in which other OECD countries to date&#13;
have not found clear solutions. Nevertheless, there are a series of areas where the good practices of&#13;
other OECD countries could be of interest to Chile.â&#128;&#157; In that context, the study highlighted a&#13;
perception in the state that performance information is not having a sufficient impact on resource&#13;
allocation. In particular, it appeared that although evaluations often do generate program design&#13;
and management changes, they relatively rarely impact funding of programs. In that scenario, the&#13;
same study proposed improving the classification of programs in the budget, with the goal of better&#13;
serving the objectives of results-based budgeting. With respect to the evaluation system, they&#13;
recommended centering the analytical focus mainly on supporting budget formulation.&#13;
&#13;
&#13;
                                                                                                     25&#13;
&amp;#12;One of the most relevant facts from this period was the promulgation of the law that gave rise to&#13;
the MDS in 2011. This new ministry took over the role of the old Ministry of Planning, adding to its&#13;
responsibilities with respect to M&amp;E and focusing its work on social policies and programs. Since its&#13;
creation, the MDSâ&#128;&#153;s work has been centered on the creation of various M&amp;E tools in coordination&#13;
with DIPRES, the start-up of the new institutional framework, and the integration with the budget&#13;
cycle led by the DIPRES.&#13;
&#13;
Another relevant actor from the period is the new National management improvement plan called&#13;
ChileGestiona created in 2011. ChileGestiona (â&#128;&#156;Chile Managesâ&#128;&#157;) was created by the Ministry of&#13;
Finance and sought to strengthen the role of the central government in Public Services, also&#13;
introducing new mechanisms for monitoring different aspects of these services.&#13;
&#13;
Finally, complementing the role that SEGPRES had previously played with respect to the&#13;
development of mechanisms for Inter-ministerial coordination and monitoring of the central&#13;
governmentâ&#128;&#153;s priorities, the current administration has enhanced its role through the&#13;
implementation of a new strategic management system for presidential priorities. This system&#13;
focuses its role on eight high-priority areas of action for the executive involving distinct sectors of&#13;
the State. It is administered by the Presidential Compliance Management Unit, created exclusively&#13;
for this purpose.&#13;
&#13;
For the elaboration of this chapter, a series of publications from state organizations and other&#13;
authors (see bibliography) were taken into account, in addition to a collection of interviews&#13;
conducted with high level officials in the M&amp;E area from various state institutions. In particular, for&#13;
the review of the DIPRESâ&#128;&#153;s role, the analysis of the first period of the system was used.&#13;
&#13;
2.2 Institutional Arrangements and System Operations&#13;
In institutional terms, the main change that took place during the second period from 2010 to 2014&#13;
was the creation of the MDS. This ministry, created by law in 2011 (Ministry of Social Development,&#13;
2011), replaced the old Ministry of Planning and acquired all its responsibilities. The MDSâ&#128;&#153;s main&#13;
objective is to collaborate with the President in the application of policies and implementation of&#13;
plans and programs related to equity and/or social development. Among its chief roles are ensuring&#13;
coordination, consistency, and coherence of social policies; evaluating public investment initiatives&#13;
to assure the efficient and effective use of public funds; and assuring the availability of information&#13;
to the public with respect to access to and continuation of social programs.&#13;
&#13;
To carry out these functions, the Social Services and Social Evaluation Undersecretaries were also&#13;
created. The first is in charge of formulation and implementation of equality and/or social&#13;
development policies. The second is responsible for M&amp;E tasks. In the following sections, any&#13;
mention of the MDS will refer to the responsibilities carried out by the Undersecretary of Social&#13;
Evaluation.&#13;
&#13;
Prior to the creation of the MDS, the ex-ante and ex post evaluations of social and nonsocial&#13;
programs were carried out by the Public Management Control Division of DIPRES. After the creation&#13;
&#13;
&#13;
                                                                                                      26&#13;
&amp;#12;of this new ministry, the ex-ante evaluation function was distributed, leaving the MDS in charge of&#13;
the evaluation of social programs and DIPRES in charge of the evaluation of all other programs. All&#13;
ex post evaluation continues to be handled by the DIPRES, such as the Evaluation of Government&#13;
Programs, Impact Evaluation, and Evaluation on New Programs (Arenas and Berner, 2010).&#13;
&#13;
However, centralized monitoring focused exclusively on program performance was not being led by&#13;
any organization in particular. The MDS law defines a role in monitoring social programs, whereas&#13;
monitoring for the remainder of programs started to be implemented by DIPRES, although it is not&#13;
legally responsible for this function.&#13;
&#13;
One of the responsibilities that the MDS retains is the ex-ante evaluation of public investments,&#13;
which was previously carried out by the old Ministry of Planning. With the introduction of the new&#13;
ministry, this role is transferred in its entirety to the Undersecretary of Social Evaluation.&#13;
&#13;
In the MDS law, an Interministerial Committee on Social Development was created, which includes&#13;
the Ministers of Social Development, Finance, General Secretariat of the Presidency, Education,&#13;
Health, Housing and Urban Planning, Labor and Social Security, and the Director of the National&#13;
Womenâ&#128;&#153;s Service. The law establishes that the main responsibility of the Committee is to advise the&#13;
President with respect to intersectorial policies of a social nature, in addition to fulfilling a follow up&#13;
role for the monitoring and evaluation information generated by the Undersecretary of Social&#13;
Evaluation. This committee also approves the evaluation criteria, and could, based on the program&#13;
evaluations, recommend the reformulation or termination of programs as well as the adoption of&#13;
measures to strengthen social programs. In other words, the committee is a forum for coordinating&#13;
the governmentâ&#128;&#153;s social policy.&#13;
&#13;
In legal and institutional terms, the DIPRES, through its Public Management Control Division, 19 did&#13;
not experience major changes. Its principal changes involve the M&amp;E functions that it will begin to&#13;
share with the MDS, separating itself in some measure from the protagonist role it had traditionally&#13;
played in the process of formulating programs and public policies in general.&#13;
&#13;
With respect to other organisms highlighted in this document, such as the Presidential Compliance&#13;
Management Unit and the ChileGestiona Plan, they are interesting initiatives that were&#13;
implemented early but do not have the legal support needed to assure their permanence in later&#13;
governments.&#13;
&#13;
&#13;
&#13;
&#13;
19&#13;
  In this section, DIPRES and its Public Management Control Division are mentioned without distinction&#13;
between the two.&#13;
&#13;
&#13;
                                                                                                         27&#13;
&amp;#12;Figure 3: Actors and Roles in the M&amp;E System in Chile&#13;
&#13;
&#13;
&#13;
                                         Monitoring                Ex-Ante Evaluation           Ex-Post Evaluation&#13;
&#13;
&#13;
                   ChileGestiona     Internal Management&#13;
                        Plan         Indicators&#13;
&#13;
&#13;
&#13;
                                     Management                       Non-Social Programs        Governmental&#13;
                                     Improvement Program              Evaluation                 Programs Evaluation&#13;
  Ministry of                        (PMG)                                                       (EPG)&#13;
   Finance&#13;
                   Budget Office     Performance                                                 Comprehensive&#13;
                                     Indicators (Form H)                                         Expenditure Report&#13;
                     (DIPRES)&#13;
&#13;
&#13;
                                                                                                 Impact Evaluation&#13;
&#13;
&#13;
&#13;
&#13;
                      Planning,                                       Public Investments&#13;
                     Studies and                                      Evaluation&#13;
                     Investment&#13;
                       Division&#13;
  Ministry of&#13;
    Social                           Monitoring of Social&#13;
 Development                         Programs                         Social Programs&#13;
                    Social Policy                                     Evaluation&#13;
                      Division       Instrument: Integrated&#13;
                                     Social Programs Bank&#13;
                                     (BIPS)&#13;
&#13;
&#13;
    Ministry        Presidential     Strategic Management&#13;
    General         Compliance       of Presidential&#13;
  Secretariat of    Management       priorities&#13;
 the Presidency        Unit&#13;
&#13;
&#13;
 Inter-ministerial Committee on&#13;
       Social Development            â&#128;¢    Fulfill a follow-up role for the monitoring and&#13;
   Includes de Ministers of Social        evaluation information generated by the&#13;
  Development, Finance, General           Undersecretary of Social Evaluation.&#13;
    Secretariat of the Presidency,   â&#128;¢    Approve evaluation criteria.&#13;
  Education, Health, Housing and     â&#128;¢    Strengthen social programs through the proposal of&#13;
  Urban Planning, Labor and Social        reformulation, termination or adoption of measures,&#13;
  Security and the Director of the        based on program evaluations.&#13;
     National Womenâ&#128;&#153;s Service.&#13;
&#13;
&#13;
&#13;
Source: Developed by author.&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                       28&#13;
&amp;#12;2.3 M&amp;E Components and Instruments&#13;
&#13;
2.3.1   Monitoring&#13;
&#13;
2.3.1.1 Performance Indicators&#13;
&#13;
Over the course of the years, the State organisms have had a tendency to diminish the number of&#13;
process indicators, giving priority to output and outcome indicators. This emphasis can be seen in&#13;
the changes in the proportion of process indicators overtime. Process indicators for the year 2004&#13;
correspond to 30 percent of the total indicators (DirecciÃ³n de Presupuestos, 2010), 16 percent in&#13;
2009 (DirecciÃ³n de Presupuestos, 2010), and 9 percent of the total indicators in 2012 (DirecciÃ³n&#13;
de Presupuestos, 2012).&#13;
&#13;
2.3.1.2 Monitoring of Social Programs&#13;
&#13;
After the creation of the MDS, an Integrated Social Programs Bank (BIPS) was founded, which&#13;
consists of a centralized registry of social programs. It covers a collection of monitoring forms that&#13;
contain information relevant to the programs, whether they are currently being implemented or&#13;
not. According to the same law, the general instructions for the design and appropriate operation&#13;
of the BIPS are established by the MDS and DIPRES together. Its information could be useful for,&#13;
among other things, monitoring the consistency of social programs, evaluating when a program&#13;
needs to be subjected to more rigorous evaluations, and providing sources to DIPRES complement&#13;
the information used during budget discussions. The BIPS could also provide important&#13;
information for the work of the Interministerial Committee on Social Development.&#13;
&#13;
The BIPS is a system that previously did not exist, and its first version, predicted to be completed&#13;
and open to public in 2013, includes 411 social programs. The information contained in the first&#13;
version is chiefly reported by those executing the programs. Its start-up needs an important&#13;
coordination effort, between Public Services and MDS that requires a considerable amount of&#13;
time for its development. The current challenges for the MDS team are to accomplish the release&#13;
of the system and to strengthen the organization of information, directly connecting MDS with&#13;
the databases that administer the programs, thereby improving the quality and reliability of the&#13;
information.&#13;
&#13;
The registry of each social program in the BIPS has basic contents such as descriptive information,&#13;
data on products or services delivered, purpose of the program, target population, indicators&#13;
(process, output, or outcome), and financial information. Ex-ante and ex post evaluations carried&#13;
out by MDS or DIPRES are also included in the registry.&#13;
&#13;
One of the aspects of the monitoring of social programs that is worth highlighting is the use that&#13;
its information could have. According to declarations by DIPRES itself, the information provided&#13;
by the early stage of the BIPS is becoming an additional resource for decision making about those&#13;
programs that require an ex post evaluation, providing warnings for aspects of those programs&#13;
that may not be functioning properly. It could also allow for the improvement of the quality of&#13;
&#13;
&#13;
                                                                                                   29&#13;
&amp;#12;information of the programs, thereby contributing to future ex post evaluations. These&#13;
evaluations often have problems with the information initially provided by the program officers.&#13;
&#13;
2.3.1.3 Management Improvement Program&#13;
&#13;
During the period 2010-14, the Management Improvement Program continued as one of the most&#13;
used instruments in Chile. It is a tool that associates compliance with objectives, to a monetary&#13;
incentive for public service officials. It is composed of multiple weighted systems for which there&#13;
is a compliance framework in which the Public Services establish commitments that are later&#13;
evaluated. Two related systems are linked to monitoring of the delivery process for goods and&#13;
services, which, during the current administration, have been given considerably more weight:&#13;
&#13;
    1) Planning and Management Control System. Its objective is â&#128;&#156;to design and implement&#13;
       planning procedures and information systems for management that allow the institution&#13;
       to access the information necessary to support decision-making with respect to the&#13;
       processes and outputs of the provision of its goods and services, and account for its&#13;
       institutional managementâ&#128;&#157; (DirecciÃ³n de Presupuestos, 2012).&#13;
&#13;
    2) Institutional Performance Monitoring System. Introduced in 2012, its objective to access&#13;
       the performance information necessary to support decision making with respect to the&#13;
       processes and outputs of the provision of its goods and services, and account for its&#13;
       institutional management (DirecciÃ³n de Presupuestos, 2012).&#13;
&#13;
During 2011, the Planning and Management Control System had a mandatory weight of 50&#13;
percent, which increased to 60 percent in 2012. In 2014, the Institutional Performance Monitoring&#13;
System, together with the Planning and Management Control System, represents 80 percent of&#13;
the total weight. The strengthening of these two systems represents part of the focus on&#13;
performance that has been adopted by the Management Improvement Programs.&#13;
&#13;
In 2008, the World Bank carried out an evaluation that criticized the Management Improvement&#13;
Program salary incentives (World Bank, 2008). In its critical challenges, the evaluation concluded&#13;
that the salary incentive is the best-known aspect of this tool and is even considered its central&#13;
aspect, thereby limiting its real impact. Other authors have also commented that the stipulated&#13;
goals in the program are so low that this figure has become in reality a mechanism for salary&#13;
increase (Waissbluth, 2006). In addition, there is a perception among practitioners that indicators&#13;
established through this tool are excessive, though they nevertheless have been reduced by a&#13;
third from 2010 to 2014 (Ministerio de Hacienda, 2012).&#13;
&#13;
2.3.1.4 Tracking Presidential Priorities from the Central Government&#13;
&#13;
Since 2010, the Ministry General Secretariat of the Presidency (SEGPRES) has implemented a new&#13;
tracking system for presidential priorities. For this purpose, the Presidential Compliance&#13;
Management Unit was created to ensure the success of the government. The system is inspired&#13;
by the Delivery Unit in England, implemented by Michael Barber during Prime Minister Tony&#13;
&#13;
&#13;
                                                                                                 30&#13;
&amp;#12;Blairâ&#128;&#153;s government. Other similar systems have existed in previous governments, also under the&#13;
supervision of the SEGPRES. However, the current administration has sought to enhance the role&#13;
of this system.&#13;
&#13;
Part of the emphasis in the design of the system was to maintain the focus on a reduced group of&#13;
maximum priority areas. Together with the sectorial ministries, they defined objectives and&#13;
indicators around areas of action that were coherent with the governmentâ&#128;&#153;s program. They&#13;
created fulfillment plans for each defined area, which are controlled using status reports. Most&#13;
objectives focus on performance. The tracking of commitments is accompanied by opportunities&#13;
for interministerial collaboration, which consist of meetings between the President, the sectorial&#13;
ministers, and other key actors.&#13;
&#13;
The seven prioritized areas of action are growth, employment, public safety, education, health,&#13;
poverty, and democratic quality. Given the events surrounding the earthquake that shook the&#13;
central area of the country in 2010, another itemâ&#128;&#148;action for reconstructionâ&#128;&#148;was added.&#13;
&#13;
In 2013 the Inter-American Development Bank released a review of the system (Dumas, Lafuente,&#13;
and Parrado, 2013). The document highlighted the role adopted by SEGPRES, strengthening the&#13;
functions of the center of government and the role of the Presidential Compliance Management&#13;
Unit, transmitting presidential priorities within the government.&#13;
&#13;
2.3.1.5 ChileGestiona (Chile Manages)&#13;
&#13;
In 2011, the Ministry of Finance initiated a plan centered on improving Public Services. In this&#13;
plan, undersecretaries were directed to take a larger role in the management of Public Services.&#13;
Among other activities designed for this purpose, indicators for internal management were&#13;
introduced in 2011, and indicators for core activities, introduced in 2012, with the latter having a&#13;
focus on outcomes. These indicators should be reported by the undersecretaries themselves, but&#13;
until the publishing of this document, none were. One of the main characteristics of these&#13;
indicators is that they are not associated with salaries, in hopes of reducing the problems that&#13;
other tools showed, like the Management Improvement Program.&#13;
&#13;
The selected indicators assess the management priorities of central authorities. One example is&#13;
the absenteeism of government workers, which, according to the authorities, had reached high&#13;
levels on several Public Services, in some cases more than 30 days for a year. Indicators were&#13;
discussed between the center of government and undersecretaries, for all the services within the&#13;
ChileGestiona Plan. For each service, the level of compliance was monitored by the&#13;
undersecretaries without fixing a specific goal, but encouraging dialog. Then, the results were&#13;
discussed between the undersecretaries and actors of the center of government.&#13;
&#13;
An evaluation of the program was developed at the end of 2013 (Cento de PolÃ­ticas PÃºblicas UC&#13;
2014), showing a slight positive impact for one of the internal indicators. In the year 2014, the&#13;
authorities of the new government discontinued the program.&#13;
&#13;
&#13;
&#13;
                                                                                                    31&#13;
&amp;#12;2.3.2   Evaluation&#13;
&#13;
2.3.2.1 Ex Ante Program Evaluation&#13;
&#13;
DIPRESâ&#128;&#153; ex ante program evaluation was incorporated into budget formulation for the first time in&#13;
2001 (Arenas and Berner, 2010) and to date has experienced various changes to arrive at to its&#13;
current form. In 2008, ex-ante program evaluation was carried out by DIPRES for all programs that&#13;
were new, reformulated, or expanded. 20&#13;
&#13;
In 2011, DIPRES implemented a Web-based platform that allowed program formulators and&#13;
directors to present the programs that should be subject to ex-ante evaluation. The selection of&#13;
programs that are evaluated ex-ante by MDS is based on the functional classification of expenses&#13;
in the budget, which identifies social spending.&#13;
&#13;
During the second period, according to the law that created MDS, the responsibility for ex-ante&#13;
evaluation is distributed between this new ministry and the DIPRESâ&#128;&#153; Public Management Control&#13;
Division. All social programs began to be evaluated by the MDS, whereas other programs&#13;
continued to be evaluated by DIPRES. The MDS has as its objective to determine, among other&#13;
factors, the consistency and appropriateness of social programs proposed for implementation or&#13;
reformulation. This evaluation should be carried out with specific attention to the coordination&#13;
between the program being evaluated and other social programs in execution or that have been&#13;
proposed for implementation.&#13;
&#13;
2.3.2.2 Ex Post Evaluation: Evaluation of Government Programs and Impact Evaluation&#13;
&#13;
During the 2010-14 administration, ex post evaluations continue to be led by DIPRES. However,&#13;
new changes have been introduced as consequences to evaluations. Before 2011, at the end of an&#13;
Evaluation of Government Programs or an Impact Evaluation, the program was rated in a category&#13;
according to its effects, which determined the recommendation from DIPRES with respect to the&#13;
implications for the evaluated program. The categories consisted of minor adjustments; design&#13;
and/or internal management modifications of the program; substantive redesign of the program;&#13;
institutional relocation; and finalization or integral replacement of the program (Arenas and&#13;
&#13;
&#13;
20&#13;
  New programs: Those initiatives that present a new purpose (expected outcome of the program) and&#13;
that have not received funds prior to their implementation (DirecciÃ³n de Presupuestos, 2012).&#13;
Reformulated programs: A pre-existing initiative that, maintaining its purpose (expected outcome of the&#13;
program), introduces changes in some of its key elements, (components, activities and production mode),&#13;
and that may or may not involve an increase in funding (DirecciÃ³n de Presupuestos, 2012). Program&#13;
expansions: Existing initiatives that, maintaining their purpose (expected outcome of the program) and key&#13;
elements (components, activities and production mode), request resources in addition to those&#13;
incorporated into its baseline (budget framework) as communicated by the Ministry of Finance (DirecciÃ³n&#13;
de Presupuestos, 2012).&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                        32&#13;
&amp;#12;Berner, 2010). Starting in 2011, the focus of the expected EPG results was modified, turning&#13;
toward the assessment of effectiveness and efficiency in the delivery of goods and services. This&#13;
new emphasis suggests that the design evaluation of the programs is not as important in and of&#13;
itself, unless it has a direct relation to the expected outcomes.&#13;
&#13;
In other words, the previous tendency was to evaluate the design of the implementation first and&#13;
the program outcomes later. The perspective has now shifted to how the design and the&#13;
management affect the outcomes. Thus, the focus of the evaluation is mainly on measuring the&#13;
programâ&#128;&#153;s performance in dimensions of effectiveness and efficiency, so that the data collected&#13;
can provide more precise evaluative information for the formulation of the budget. However, it is&#13;
too early to assess the impact of these changes.&#13;
&#13;
With this change in focus, the categories for classifying programs at the end of an evaluation were&#13;
modified. The new categories can be summarized as:&#13;
&#13;
    1) Good Performance: The program presents results that are positive and significant at the&#13;
       intermediate and final levels, as well as for design, management, and product aspects.&#13;
&#13;
    2) Sufficient Performance: The program has positive results that account for its objectives;&#13;
       nevertheless, it presents weaknesses in some of the aspects evaluated.&#13;
&#13;
    3) Insufficient Performance: The program presents insufficient results and/or demonstrates&#13;
       weaknesses in the aspects evaluated that do not allow it to account for its objectives.&#13;
&#13;
    4) Non-demonstrated Results: The evaluation does not provide sufficient information to&#13;
       allow for obtaining conclusive results with respect to the programâ&#128;&#153;s performance.&#13;
&#13;
In addition, DIPRES introduced additional consequences from evaluations. A program with&#13;
insufficient performance must be presented for ex-ante evaluation the following year, justifying&#13;
its continuation and the measures adopted for improving its performance (DirecciÃ³n de&#13;
Presupuestos, 2012). This development was implemented for the first time in 2013.&#13;
&#13;
Finally, only for impact evaluations, they have been characterized as much by the evaluation of&#13;
outcomes or impact as, by the analysis of other aspects of the program. During the 2010-14&#13;
administration, impact evaluations have centered on providing information on outcomes or&#13;
impact on beneficiaries, eliminating the requirement for carrying out an exhaustive analysis of the&#13;
programâ&#128;&#153;s management.&#13;
&#13;
2.4 Use of M&amp;E Information&#13;
&#13;
2.4.1   Indicators&#13;
&#13;
2.4.1.1 Reporting and Dissemination of Performance Indicators&#13;
&#13;
Among the emphasis incorporated in the period, there is a concern for maintaining the right&#13;
proportion between performance indicators and process indicators, and a decrease in the number&#13;
&#13;
                                                                                                   33&#13;
&amp;#12;of indicators, and the search for a higher coherence with other state tools stand out. However,&#13;
the dissemination mechanisms of these indicators remained mostly unchanged during 2010-14.&#13;
The main forms of indicator dissemination are the records delivered to Congress during the&#13;
budgetary cycle context.&#13;
&#13;
2.4.1.2 Management Improvement Program&#13;
&#13;
During the current administration this instrument strengthened its focus on performance, giving&#13;
more importance to the systems related with monitoring of the delivery process for goods and&#13;
services. In addition, the number of indicators declared through the instrument was reduced to a&#13;
third to counteract the excessive number of indicators (Ministerio de Hacienda, 2012).&#13;
&#13;
2.4.1.3 A Monitoring System Closer to the Center of Government&#13;
&#13;
The Presidential Compliance Management Unit adopted an important role supporting the&#13;
functions of the center of government. Its implementation seems to have tried to balance or&#13;
replace the strategic planning role of other actors like DIPRES (Dumas, Lafuente, and Parrado,&#13;
2013). This Unit has managed to transmit the main priorities and commitments of the President&#13;
within the administration. Nevertheless, it seems that it has not been able to transmit those&#13;
priorities and results to the public opinion.&#13;
&#13;
2.4.1.4 The Role of ChileGestiona&#13;
&#13;
The introduction of ChileGestiona highlights the management relation between undersecretaries&#13;
and state agencies. This initiative is outside the domain of DIPRES and has had the support of the&#13;
center of government. Multiple work meetings have been held between undersecretaries and&#13;
authorities of the center of government to discuss the indicators defined in the context of the&#13;
initiative. In 2013 a new bill was sent to Congress to give formal support to the objectives of&#13;
ChileGestiona.&#13;
&#13;
2.4.1.5 A New Monitoring System for Social Programs&#13;
&#13;
The MDS monitoring system, even before its public release, has already had some important&#13;
results. In the first place, interviewed DIPRES officers have declared the use of the monitoring&#13;
information for the selection of programs to evaluate. In the second place, a Social Policy Report&#13;
based on the system was released during the years 2011 and 2012 and reviewed existing social&#13;
programs. This was an important step to identify the current public social programs.&#13;
&#13;
2.4.2   Evaluation&#13;
&#13;
2.4.2.1 Consolidation of Ex Post Evaluation&#13;
&#13;
During 2010-14, the largest part of the functions developed by DIPRES with respect to M&amp;E&#13;
information continued to be developed as in previous governments. The evaluation results are&#13;
delivered to Congress as part of the budgetary process, at the same time they are published in&#13;
&#13;
&#13;
                                                                                                  34&#13;
&amp;#12;DIPRESâ&#128;&#153; website. In addition, along with each yearÂ´s budget, are provided consolidated reports&#13;
with the number of evaluations, their results, and the major improvements made to M&amp;E tools.&#13;
&#13;
Table 6 shows the number of evaluations carried out by DIPRESS between the years 2011 and&#13;
2012.&#13;
&#13;
Table 6: Number of Evaluations&#13;
&#13;
  Type of evaluation                       2011                 2012              2013&#13;
  Evaluation of Government                  10                   19                15&#13;
  Programs&#13;
  Comprehensive Spending                     6                   0                     6&#13;
  Review&#13;
&#13;
  Impact Evaluation                          9                   11                    2&#13;
&#13;
  Evaluation of New Programs                 5                   0                     0&#13;
&#13;
Source: Based on DIPRES information.&#13;
&#13;
In addition, taking into consideration the new classification for the evaluation results, Table 7&#13;
shows the number of programs for each category between years 2011 and 2012.&#13;
&#13;
Table 7: Evaluation Results&#13;
&#13;
  Evaluation results               2011                   2012                   2013&#13;
  Good performance                     1                    3                      0&#13;
  Sufficient performance               7                    5                      6&#13;
&#13;
  Insufficient                       6                      8                      7&#13;
  performance&#13;
  Non-demonstrated                   4                      3                      5&#13;
  results&#13;
Source: Based on DIPRES information.&#13;
&#13;
2.4.2.2 Evaluation Implications&#13;
&#13;
Based on the new categories established by DIPRES, since 2013, every program with insufficient&#13;
performance should be presented for evaluation ex-ante the following year, which meant it had&#13;
to justify its continuity and the measures adopted to improve its execution. Besides, programs&#13;
with non-demonstrated results should draw up commitments that assure the availability of&#13;
indicators that measured its performance within an appropriate deadline.&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                 35&#13;
&amp;#12;3       Success Factors and Obstacles&#13;
&#13;
3.1.1   Success Factors&#13;
&#13;
The review of the first period revealed certain characteristics that worked in favor of the systemâ&#128;&#153;s&#13;
development (success factors) and others that made it difficult to move forward.&#13;
&#13;
The most important success factors for the period 1990-2010 of Chileâ&#128;&#153;s M&amp;E system are the&#13;
following:&#13;
&#13;
    â&#128;¢   Political will and credibility of the institutions in the process: The system benefited from a&#13;
        reasonable amount of support from executive authorities and Congress. The evaluation&#13;
        instrument was established through formal agreements in the late 1990s and then&#13;
        consolidated, with new processes and relations generated between the Executive and&#13;
        Legislative Branches.&#13;
&#13;
    â&#128;¢   Technical abilities: In the early stage abilities were at a basic level, but they were&#13;
        developed over time. Within the government, workshops were been held and technical&#13;
        materials and assistance were made available in the workplace; the system encouraged&#13;
        the market to offer training opportunities in higher education centers.&#13;
&#13;
    â&#128;¢   Diversity of instruments and methodological alternatives: The instruments and their&#13;
        methodologies generate different types of information that require different technical&#13;
        abilities, resources and implementation times. This has made it possible to combine&#13;
        instruments and methodologies with available resources to respond to different types of&#13;
        demands.&#13;
&#13;
    â&#128;¢   Gradual pace: Different instruments have degrees of complexity, ranges of areas covered,&#13;
        and operational requirements. They were phased over time, and new capacities&#13;
        generated to meet their requirements, thereby facilitating sustainability.&#13;
&#13;
    â&#128;¢   Institutional design: The Ministry of Finance, through DIPRES, played an important role in&#13;
        providing direction and coordination. The systemâ&#128;&#153;s design also included other&#13;
        stakeholders such as Public Services and in the interministerial committees.&#13;
&#13;
During the period 2010-2014, the main success factors were:&#13;
&#13;
    â&#128;¢   Consolidation of DIPRES M&amp;E system: The M&amp;E systems in Chile have a long history that&#13;
        dates back as far as the 1970s, with the first steps taken by the National Investment&#13;
        System. In the 1990s, DIPRES led the implementation of a collection of M&amp;E mechanisms&#13;
        that support the budget cycle. During the 2000-09 period, DIPRES was able to consolidate&#13;
        its M&amp;E systems and install a culture of evaluation within government, as indicated in an&#13;
        assessment of the evaluation mechanisms applied on social programs (World Bank, 2005).&#13;
        At present, there are procedures that define different instances of evaluation and&#13;
&#13;
&#13;
                                                                                                    36&#13;
&amp;#12;    monitoring mechanisms throughout the public policy cycle. There is also a level of&#13;
    experience that government organizations have acquired with respect to M&amp;E issues,&#13;
    given the evolution of monitoring tools and the large number of ex-ante and ex post&#13;
    evaluations that have been carried out to date. In 2010 the political coalition in charge of&#13;
    the government changed for the first time in 20 years. Nevertheless, from that year&#13;
    onward, the M&amp;E functions developed by DIPRES have not changed drastically, nor the&#13;
    teams behind those functions. The M&amp;E system led by DIPRES has been consolidated and&#13;
    its team has gained professionalism through training.&#13;
&#13;
â&#128;¢   New actors have been incorporated to the system: The Chilean M&amp;E system has been&#13;
    structured on the role of DIPRES, but it has also involved other actors in limited areas. In&#13;
    the current administration, as a reinforcement measure, space has been provided for new&#13;
    organizations to play more active roles, thus empowering a more comprehensive view of&#13;
    M&amp;E. In the first place, the creation of the Ministry of Social Development has added a&#13;
    new institutional structure for the ex-ante evaluation of social programs, sharing&#13;
    responsibilities traditionally held by DIPRES. This same ministry also added new&#13;
    responsibilities in the monitoring area for social programs, work that was not previously&#13;
    covered by any other organization. In the second place, through the Presidential&#13;
    Compliance Management Unit, SEGPRES has focused on tracking the priorities of the&#13;
    central government and on making effective decisions, and in doing so has had great&#13;
    political and institutional support from the presidency. Additionally, the creation of&#13;
    ChileGestiona also constitutes reinforcement of the monitoring role of the ministries with&#13;
    respect to Public Services.&#13;
&#13;
    Some of the changes introduced had already been announced in the current&#13;
    administrationâ&#128;&#153;s Government Program. In a chapter dedicated to Modernization of the&#13;
    State, the creation of the Ministry of Social Development was announced and the&#13;
    strengthening of the coordination role played by the Ministry of the General Secretary of&#13;
    the Presidency is proposed. In addition, the changes experienced by DIPRES are in&#13;
    accordance with the recommendation made by the OECD, which put forth the idea of&#13;
    centralizing the analytical focus for evaluations principally on supporting budget&#13;
    formulation (DirecciÃ³n de Presupuestos, 2012). As a consequence, even if the M&amp;E&#13;
    system led by DIPRES has been consolidated over time, there has been enough space to&#13;
    incorporate new actors and to implement new improvements to the M&amp;E system.&#13;
&#13;
â&#128;¢   A monitoring system closer to the center of the government: The document "El&#13;
    fortalecimiento del Centro de Gobierno para resultados en Chile" suggests that the role&#13;
    assigned to DIPRES from 2012 onward seems to be one of the first visible efforts in Latin&#13;
    America in the last decade, for endowing the center of the government with bigger&#13;
    capacities to exercise its functions. (Dumas, Lafuente, and Parrado, 2013). The&#13;
    Presidential Compliance Management Unit was created in that context and, according to&#13;
&#13;
&#13;
&#13;
                                                                                              37&#13;
&amp;#12;        the conclusions of the same document, has been able to transmit the priorities of the&#13;
        government within the administration.&#13;
&#13;
3.1.2   Obstacles&#13;
&#13;
Although the above factors facilitated the M&amp;E systemâ&#128;&#153;s development, others hindered its&#13;
operations and slowed down its development. Some of the latter for the first period include:&#13;
   â&#128;¢    System centralization: The high degree of centralizationâ&#128;&#148;though it has advantagesâ&#128;&#148; also&#13;
        led to diminished, and in some cases insufficient, motivation for capacity building and&#13;
        integration of instruments. For example, in some agencies the administration of&#13;
        instruments was turned over to functionaries or units at modest hierarchical and capacity&#13;
        levels, with only limited involvement by higher authorities.&#13;
&#13;
   â&#128;¢    DIPRESâ&#128;&#153; relationship with Public Services: The presentation, systematization, and&#13;
        generation of new performance information from the M&amp;E system have not always been&#13;
        carried out with Public Services in an atmosphere of trust and teamwork. As a result, the&#13;
        technical work has not been as sound as it could have been, and its potential was not&#13;
        optimized.&#13;
   â&#128;¢    Suboptimal information use by Congress: Despite the advances made, Congressâ&#128;&#153;s use of&#13;
        information was not optimal. A more intensive use of information would have permitted&#13;
        more technical exchanges, and a better understanding of the system, its good qualities&#13;
        and limitations, and the needs for performance information would have been better&#13;
        expressed, thereby introducing feedback into the cycle.&#13;
&#13;
   â&#128;¢    Dissemination limitations: The inherent technical and operational complexity of the&#13;
        system required major efforts in dissemination, which in turn required time and&#13;
        resources. More efforts were needed in terms of dissemination, focused on key&#13;
        stakeholders, some of which were outside the current institutional design, such as&#13;
        research and public opinion centers, universities and communication media. In the case&#13;
        of institutional indicators, an aspect that could have improved the dissemination would be&#13;
        to strengthen the ownership of indicators between management information systems.&#13;
   â&#128;¢    Information availability: This is a factor that has both facilitated the M&amp;E systemâ&#128;&#153;s&#13;
        development and made it more difficult. The dynamics of the programs required the&#13;
        creation of new information systems concurrently with adjustments to those that already&#13;
        existed. In addition, the implementation of M&amp;E instruments required more and better&#13;
        information, such as information on baselines and control groups, making impact&#13;
        evaluations possible. Although progress was made in the use of the systemâ&#128;&#153;s information,&#13;
        more needs to be done to use the system to support budget flexibility. The measures&#13;
        implemented on budget flexibility instead were been minimal and episodic, so they had&#13;
        had minimal effects.&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                38&#13;
&amp;#12;   â&#128;¢   The M&amp;E system was still weak, following up changes in postevaluation performance: The&#13;
       evaluated programs and agencies were monitored to verify their compliance with&#13;
       commitments to improvements, but focused primarily on modifications in designs,&#13;
       organizational, and/or management processes. This follow-up did not include changes in&#13;
       postevaluation performance as a result of the incorporation of the modifications for&#13;
       which commitments were made. It would have been therefore necessary to incorporate a&#13;
       process that reports on the progress made in performance, using measurements of&#13;
       indicators for key outputs and results.&#13;
&#13;
During the second period, the main obstacles were:&#13;
&#13;
   â&#128;¢   Worn-down methodologies: DIPRES has been the main actor behind M&amp;E in Chile.&#13;
       Nevertheless, systems change over time, and emphases are placed according to the needs&#13;
       and contexts of each administration. Initiatives that may have been very important in the&#13;
       beginning are worn down or become bureaucratic. The commitments made by evaluated&#13;
       organizations are many times of a formal nature and do not imply substantive&#13;
       improvement in management (Bellolio, y otros, 2012). DIPRESâ&#128;&#153;s M&amp;E systems mainly&#13;
       contribute to generating a results-informed budget, rather than a results-based budget.&#13;
&#13;
   â&#128;¢   Excessive number of indicators: The incorporation of new actors emphasizes problems&#13;
       found in prior governments, such as an excessive number of existing indicators. This&#13;
       paired with the lack of clear coordination mechanisms between the different tools implies&#13;
       that the organizations responsible for giving those indicators must spend a considerable&#13;
       amount of resources in the generation of information. This means more obstacles, both in&#13;
       quality and usability of created indicators, and in the cost of reporting them.&#13;
&#13;
   â&#128;¢   No clear impact from the M&amp;E system on the budgetary cycle: The OECD document&#13;
       â&#128;&#156;Review of selected budgeting issuesâ&#128;&#157; (OECD, 2012) reveals a perception that the&#13;
       performance information is not having enough impact in resource allocation. The review&#13;
       highlights four factors that could explain the limited used of information in the budget:&#13;
&#13;
       (1) Weakness in the budgetary program structure: At present it is difficult to identify&#13;
       programs in the budget, because the budget has a higher level of aggregation. Hence, it is&#13;
       difficult to transform evaluation results on budgetary decisions.&#13;
&#13;
       (2) Lack of focus of the evaluation system on budget preparation: The document&#13;
       differentiates between evaluations for budgetary purposes and policy/management&#13;
       improvement purposes. Evaluations made by DIPRES are not focused enough for&#13;
       budgetary purposes, even though they inform policy or management improvements.&#13;
&#13;
       (3) Lack of prioritization: In the evaluation system, there is no institution responsible for&#13;
       the identification of programs that could be cut because of their low priority. It is a role&#13;
&#13;
&#13;
&#13;
                                                                                                       39&#13;
&amp;#12;        inherently much more political and possibly from authorities from the center of the&#13;
        government.&#13;
&#13;
        (4) Lack of spending review mechanisms. The document highlights that even when&#13;
        evaluations do provide information that could be used for budgetary purposes, there is no&#13;
        clearly responsible body to identify or recommend budget cuts.&#13;
&#13;
    â&#128;¢   No knowledge management system: Currently, many actors generate relevant&#13;
        information for decision making, and at the same time there are many who demand it.&#13;
        However, there is a lack of coordination between the different actors and there is no&#13;
        centralized record of the information generated from the indicators and evaluations. This&#13;
        makes it difficult to both access the information and use it effectively in the decision-&#13;
        making process or in the development of new evaluations.&#13;
&#13;
    â&#128;¢   Lack of coherence between M&amp;E components: The expansion of the M&amp;E systems makes&#13;
        the need to improve the coordination mechanisms at more strategic levels even more&#13;
        important. Thus, the creation of an agency that is dedicated to M&amp;E functions and that&#13;
        has the capacity to integrate the various actors involved in the public policy cycle is still a&#13;
        pending issue. It is important to note that since previous administrations, there have been&#13;
        various proposals for the creation of a transversal ex post evaluation agency, though none&#13;
        of these proposals has been concretized.&#13;
&#13;
    â&#128;¢   Lack of regulatory policy: There are no current instances of feedback for the formulation&#13;
        of new public policies. Although the information generated from M&amp;E systems is available&#13;
        to the different decision and policy makers, there are no known mechanisms within the&#13;
        executive administration to show that the evaluations are being considered when new&#13;
        bills are being formulated and reviewed in the Congress.&#13;
&#13;
&#13;
4       Challenges&#13;
&#13;
Based on the success factors and obstacles of both periods, the following are the main challenges&#13;
of the M&amp;E system in Chile.&#13;
&#13;
    â&#128;¢   Optimizing the use of information: One of the main challenges in the system is to continue&#13;
        to enhance and motivate participation in developing and using information, on the part of&#13;
        both Public Services and high levels within ministries responsible for policies. In Chile,&#13;
        public institutions fulfill key roles in the systemâ&#128;&#153;s functioning, but the degree to which&#13;
        ownership is taken in the process varies from one institution to another.&#13;
&#13;
    â&#128;¢   Defining objectives and strategic goals: Neither a top-down rational planning model nor a&#13;
        bottom-up empirical approach is sufficient for establishing objectives or strategic goals.&#13;
        Most likely, a combination of both approaches is needed.&#13;
&#13;
&#13;
                                                                                                    40&#13;
&amp;#12;â&#128;¢   Establishing the common elements and differences in evaluation of programs, agencies,&#13;
    and policies: M&amp;E is focused on programs and agencies and has made efforts to cover&#13;
    sets of programs that have different aims but are part of the same policy. In this regard it&#13;
    is necessary to clarify the differences between policy evaluation and evaluation of its&#13;
    constituent parts, also identifying which are the methodological approaches, processes,&#13;
    and different institutional actors required.&#13;
&#13;
â&#128;¢   Periodically evaluating the system for continuous improvement and accountability: The&#13;
    system requires periodic evaluations to systematize lessons and establish legitimacy in the&#13;
    eyes of internal and external stakeholders.&#13;
&#13;
â&#128;¢   The systemâ&#128;&#153;s growth--Direction and caution: The level of success that the Chilean system&#13;
    has achieved makes it necessary to pay attention to its growth and the direction this&#13;
    growth might take, with the objective of safeguarding its achievements. With regard to&#13;
    evaluations, one of the primary challenges is how to respond to the growth in&#13;
    participation without jeopardizing the quality and timeliness of the information&#13;
    generated, and even more so, how to guarantee improvements as systematic practices.&#13;
    The growth experienced makes it necessary to review these aspects with the potential&#13;
    aim of incorporating measures for assuring adequate implementation times, standards of&#13;
    excellence, and costs that assure sustainability.&#13;
&#13;
â&#128;¢   Maintaining coherence among instruments, responsibilities, and organizational units: It is&#13;
    important to maintain coherence between organizational units and the designation of&#13;
    responsibilities with respect to the instruments, to assure the optimization of capacities&#13;
    and institutional lessons learned.&#13;
&#13;
â&#128;¢   Fragmented legal framework: Product of the incremental development of the M&amp;E&#13;
    system, there is a diversified legal framework. The incorporation of the MDS was done&#13;
    through the approval of a new law, which at once assures the permanence of this new&#13;
    institution but also formalizes the breakup of the system.&#13;
&#13;
â&#128;¢   Balance in the legal framework: Emerging initiatives like the Presidential Compliance&#13;
    Management Unit or ChileGestiona do not have a legal framework that allows for&#13;
    projecting the permanence of these organizations in future administrations. Given that&#13;
    they complement the arrangement of institutions that make up the M&amp;E system, there&#13;
    must be a balance between giving legal support to new actors of the M&amp;E system and not&#13;
    compromising future improvements of the system.&#13;
&#13;
â&#128;¢   New evaluation agency: There is some tension regarding the place of some functions&#13;
    currently led by DIPRES. At different points in time it has been suggested that the system&#13;
    be revised to establish an agency in charge of ex post evaluation. There may be different&#13;
    alternatives for technically strengthening evaluations of the quality of public policies and&#13;
    their programs and projects; the integration of instruments; and the legitimacy and&#13;
    transparency of their functioning. The challenge is how to move forward on the basis of&#13;
&#13;
                                                                                               41&#13;
&amp;#12;        what has already been constructed and the experience already gained, without losing any&#13;
        ground in terms of quality and availability of information, or in the promotion of the&#13;
        system and its integration with the decision making process.&#13;
&#13;
    â&#128;¢   Stronger link with budgetary decisions: The OECD document recommends that the M&amp;E&#13;
        components led by DIPRES should focus primarily on evaluation to support budget&#13;
        preparation, and more specifically to provide information to the budget. Since the release&#13;
        of the document, DIPRES has already conducted various initiatives to achieve this goal.&#13;
        One of them is to focus indicators primarily on performance. Additionally, they have&#13;
        implemented a new classification for evaluated programs, which prioritizes the results of&#13;
        program evaluation in dimensions of effectiveness and efficiency so the evaluation results&#13;
        provide more precise information for budgetary decision-making.&#13;
&#13;
    â&#128;¢   Better linkage with the decision making process on the center of government: The center&#13;
        of government is the set of institutions that support the decision making process of the&#13;
        president, it fulfills an important coordination role in the policy formulation process (Ben-&#13;
        Gera, 2004). It is necessary to strengthen the use of M&amp;E information within the center&#13;
        of government to have a better policy formulation process.&#13;
&#13;
&#13;
5       Lessons for Other Countries&#13;
&#13;
The building of Chilean M&amp;E has not been linear. Although it has kept its structure and functions,&#13;
its processes have been prioritized differently over time. From this experience certain lessons may&#13;
be interesting to other countries in the process of development or institutionalization of their&#13;
own M&amp;E systems.&#13;
&#13;
5.1     M&amp;E Systems Are Dynamic&#13;
Implementation of evaluation should be done gradually: It is recommended that evaluations be&#13;
developed gradually in terms of selecting the evaluation targets, the methodology, and foci, as&#13;
well as the corresponding operational processes. Thus, it is possible to begin with simpler&#13;
program evaluations, using rapid evaluation methodologies and focusing on evaluating program&#13;
designs and basic management processes. Depending on the availability of information,&#13;
measurements can be made using performance indicators. Later, and in line with advances made,&#13;
the focus can move toward more complex methodologies, increasing the number of evaluations&#13;
to be conducted each year, in accordance with available resources and abilities.&#13;
&#13;
The process for introducing new mechanisms and tools might not be linear: In fact, some tools&#13;
that appeared to be major initiatives initially have gradually worn down or become less important&#13;
over time. Also, new priorities arose that were then imposed on previous mechanisms, as in the&#13;
case of the effort toward increased concentration on outcomes. Thus, even if these systems&#13;
require a strong dose of stability and coherence, they will necessarily be subject to changes over&#13;
time.&#13;
&#13;
                                                                                                   42&#13;
&amp;#12;5.2   Strategic Roles&#13;
      Strategic roles of each actor in the M&amp;E system: The first period was strongly led by&#13;
      DIPRES, which made possible its strong positioning. Currently, however, new actors and&#13;
      mechanisms have been incorporated to the system. Each of these actors may support&#13;
      objectives of a different nature, for example, the improvement of public policies, support&#13;
      to the compliance of government priorities, or search for higher efficiency in the use of&#13;
      public resources. It is important to make these actors achieve effective coordination,&#13;
      avoiding the excess of M&amp;E tools and possible function duplicities.&#13;
&#13;
5.3   Institutional Arrangements&#13;
      M&amp;E needs to be institutionalized and managed: For an M&amp;E system to meet its&#13;
      objectives of informing and providing feedback to decision-making processes, it is&#13;
      necessary to consider some basic aspects in relation to its institutional arrangements and&#13;
      management of implementation. The development and use of information is not&#13;
      something that is automatically achieved. Rather, it requires new practices and abilities&#13;
      that involve a range of technical and political stakeholders, and technical and&#13;
      administrative processes. With these elements in mind, several tasks should be&#13;
      considered. The first one is identifying units that will fulfill the roles, as well as defining,&#13;
      designating, and informing them of their various functions and responsibilities. Also&#13;
      designing the operational process, procedures, and scheduling for the entire year,&#13;
      including ones for analyzing information to be integrated into decision-making processes,&#13;
      and for establishing commitments and following up on commitments.&#13;
&#13;
      Avoiding formalism: There is a tension between, on the one side advancing an M&amp;E&#13;
      system that manages to become institutionalized, creating formal procedural routines,&#13;
      and gaining greater public awareness, with on the other, the excessive formalism that&#13;
      these procedures can lead to. In the case of Chile, M&amp;E procedures might be followed but&#13;
      there might be no consequences; M&amp;E is often not oriented to strengthening&#13;
      performance but rather to towards salary or paid benefits, and it often does not feed into&#13;
      management.&#13;
&#13;
      An M&amp;E system needs pragmatic, flexible development: Instruments and tools can be&#13;
      implemented as practices and procedures that are not tided to permanent laws, but&#13;
      rather incorporated in transitory norms, such as the Budget Law, or in administrative&#13;
      instructions in the framework of the budget process in Chile. In the case of the Evaluation&#13;
      of Government Programs, in Chile it was only in 2003--after it had been developed and&#13;
      technically and operationally perfected--that it was established in a permanent law that&#13;
      mandates that the Ministry of Finance must conduct these evaluations. This took place&#13;
      seven years after its initial implementation and after it had been allowed to advance&#13;
      gradually and with flexibility, with the benefit of lessons learned, which were shared and&#13;
      widely disseminated.&#13;
&#13;
&#13;
&#13;
                                                                                                    43&#13;
&amp;#12;5.4     Components of the M&amp;E System&#13;
Evaluation is a vital piece of the system: Evaluations generate a type of information that lends&#13;
itself to its intensive use in decision-making processes. It has facilitated the process of informing&#13;
external stakeholders and has presented a basis for following up on necessary changes in&#13;
programs, in accordance with findings and recommendations. In addition, the evaluation process&#13;
has served as a learning opportunity for the organizational units evaluated, and this has&#13;
contributed to the development of capacities.&#13;
&#13;
Unit of analysis of an evaluation, methods, and topics must be defined: It is recommended that&#13;
the development of an evaluation system take into consideration the need for definitions of three&#13;
central, interrelated aspects: the unit of analysis of an evaluation, methodology to be used, and&#13;
foci in each evaluation.&#13;
&#13;
   â&#128;¢    The unit of analysis of an evaluation. It can be a program, a set of programs with a&#13;
        common goal, or an organization. The case of Chile demonstrates that it is possible to&#13;
        initiate a system for evaluating individual programs, with between five and eight&#13;
        evaluations each year, and then gradually increase the number, while consistently&#13;
        prioritizing the relative needs for performance information.&#13;
&#13;
   â&#128;¢    The evaluation methodology. After the unit of analysis of the evaluation has been defined,&#13;
        it is necessary to identify the methodology that will be used to conduct the evaluation. In&#13;
        general this selection should consider the resources available for evaluations, both&#13;
        organizational and financial in nature, as well as professional abilities; the amount of time&#13;
        each program will need for its implementation; previous evaluations available; and when&#13;
        the information will be needed. In Chile, initial evaluations were rapid or desk evaluations,&#13;
        using a simple methodology that allowed for developing abilities, making it possible to&#13;
        apply more complex methodologies later. Eventually, the evaluations themselves&#13;
        contributed to the technical development of abilities, both within the pool of consultants&#13;
        used for the evaluations and in the public sector itself.&#13;
&#13;
   â&#128;¢    The foci of evaluation. After both the unit of analysis of evaluation and the methodology&#13;
        have been selected, perhaps the most important, its foci can be identified. To this end, it&#13;
        is important to gather the opinions of those responsible for programs and the&#13;
        stakeholders who should use the information (technical professionals and authorities).&#13;
&#13;
&#13;
&#13;
There should be a mechanism for following up on recommendations: The work of designing an&#13;
evaluation system does not end when findings have been analyzed or when the final report has&#13;
been presented. It is important to incorporate a process that facilitates meeting the objective of&#13;
evaluation-based â&#128;&#156;improvements.â&#128;&#157; The recommendations could serve as a basis for the units&#13;
responsible for evaluated programs to make commitments for changes. This means that&#13;
recommendations must be pertinent. And in this regard, it is suggested that an important aspect&#13;
&#13;
&#13;
                                                                                                   44&#13;
&amp;#12;to be taught in evaluation processes is that all recommendations must be precise and relevant, to&#13;
facilitate improved performance.&#13;
&#13;
Caution is required in the construction, selection, and use of indicators: Indicators are very useful&#13;
as an instrument for collecting performance information, and it is very important that special care&#13;
be taken in their selection, construction, and use, given their limitations and difficulties, some of&#13;
which are listed here:&#13;
&#13;
   â&#128;¢    Indicators alone cannot explain the levels of performance achieved.&#13;
&#13;
   â&#128;¢    Measurements may be affected by variables that are outside the control of those&#13;
        responsible for management. These situations should be registered, verified, and&#13;
        incorporated into the analysis of performance achieved.&#13;
&#13;
   â&#128;¢    Determining the relevance of indicators requires technical work carried out with experts&#13;
        in the different areas.&#13;
&#13;
   â&#128;¢    An adequate selection of indicators is necessary to avoid generating undesired effects in&#13;
        an organizationâ&#128;&#153;s behavior while maintaining a balance, particularly between efficiency&#13;
        and effectiveness.&#13;
&#13;
&#13;
Process versus performance indicators: Another tension indicated by the Chilean experience is the&#13;
emphasis that can be placed on performance rather than processes. Even if the ultimate goal of&#13;
all policies or public programs is to produce concrete impacts that are the result of an&#13;
intervention, it is widely known that often it is difficult to isolate the effects or precisely define the&#13;
final impacts. Thus, maintaining the focus on processes should not be totally devalued.&#13;
&#13;
M &amp; E are complementary: Monitoring devices (indicators, report cards, and other tools) usually&#13;
comprise a large proportion of government activities and its budget, whereas evaluation is mostly&#13;
concentrated on specific programs. Monitoring focuses mostly on processes, whereas evaluation&#13;
is about outcomes. Usually these aspects are considered separately; however, monitoring has a&#13;
very relevant role in raising initial warnings about programs or policies that demand further&#13;
analysis through evaluations.&#13;
&#13;
5.5     Availability of Information&#13;
Availability of information is critical: Information is vital for the development of an M&amp;E system.&#13;
Whatever the methodology selected, it uses information, and without information, its application&#13;
will be limited. Thus, what an M&amp;E system is able to achieve, will depend not only on the time&#13;
designated for the processes, technical abilities, and the counterpart, but also on the information&#13;
available. It is therefore recommended that special attention be given to generating and collecting&#13;
information as a regular work practice.&#13;
&#13;
Evaluation needs to take into account information limitations: In evaluations, there are often&#13;
situations in which the responsible units do not have complete or reliable information on&#13;
&#13;
                                                                                                       45&#13;
&amp;#12;performance. This can make it difficult to determine a baseline for the program and thus prevent&#13;
an accurate measurement of changes occurring. In these cases it is suggested that the focus be&#13;
diverted to evaluating other aspects, such as the program design, basic management processes,&#13;
and the effectiveness of outputs, particularly the levels of production and/or provision of goods&#13;
and services, and at the same time providing incentives and exerting pressure for making&#13;
improvements in information systems.&#13;
&#13;
5.6     Work Teams&#13;
Work teams can be a key to success: When an M&amp;E system is developed, it is necessary to&#13;
establish internal work teams. At the same time, it is necessary to build a pool of external&#13;
evaluators. An internal team of five to seven people could be provided with solid training, to fulfill&#13;
the role of technical leadership, and to carry out other important functions such as training other&#13;
professionals or persons in charge (cascade training), preparing technical guides, training&#13;
evaluators, serving as the technical counterpart and bringing together the lessons learned in order&#13;
to perfect the system in future cycles. More staff should also often be hired as the number and&#13;
complexity of the evaluations grow.&#13;
&#13;
5.7     Integration with the Decision-Making Process&#13;
&#13;
System usability: One important key for the validity and recognition of the M&amp;E system is its&#13;
usability. The tools and mechanisms that make up the M&amp;E system should be useful for decision&#13;
making and public management. To the extent that these procedures become sophisticated, they&#13;
can earn their independence and conceptual solidity, but care must be taken that these benefits&#13;
not threaten the user-friendly nature of the system.&#13;
&#13;
M&amp;E should be integrated into decision-making processes and improve policy design: An M&amp;E&#13;
system needs to provide effective feedback on the decision-making of public policy makers. In the&#13;
case of Chile, the construction of this system has used the budget process as its basis and&#13;
motivation. It has taken into consideration the opportunity offered by budget management in&#13;
which the well-defined, regulated, and repetitive stages of the annual cycle have permitted the&#13;
integration of instruments and processes throughout the year, linking them to concrete&#13;
milestones and thus generating accumulative institutional lessons.&#13;
&#13;
Performance information cannot be used mechanically in reaching budget decisions: The use of&#13;
performance information in decision-making processes also needs to consider other information&#13;
categories, such as policy-program priorities and restrictions imposed by fiscal policy. In other&#13;
words, the link between performance information and decisions regarding budget allocation is&#13;
not linear. Rather, the aim is for performance information to be integrated into a decision-making&#13;
process that is essentially technical-political in nature. This characteristic recognizes the need for&#13;
using performance information in budget management, but also the nature of the budget as a&#13;
financial instrument for achieving policy goals.&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                    46&#13;
&amp;#12;References&#13;
&#13;
Arenas, A. and Berner, H. (2010). â&#128;&#156;Presupuesto por Resultados y la ConsolidaciÃ³n del Sistema de&#13;
     EvaluaciÃ³n y Control de GestiÃ³n del Gobierno Central.â&#128;&#157; DirecciÃ³n de Presupuesto,&#13;
     Ministerio de Hacienda.&#13;
&#13;
Armijo, M. (2003). La EvaluaciÃ³n de la GestiÃ³n PÃºblica en Chile, EvaluaciÃ³n de Resultados para&#13;
      una GestiÃ³n Publica Moderna y DemocrÃ¡tica, Centro Latinoamericano de AdministraciÃ³n&#13;
      para el Desarrollo, CLAD.&#13;
&#13;
Bellolio, Ã&#129;., De los RÃ­os, B., IrarrÃ¡zaval, I., LarraÃ­n, L., Marshall, J., Morales, J., et al. (2012). Agencia&#13;
       de EvaluaciÃ³n PÃºblica. Santiago.&#13;
&#13;
Ben-Gera, M. (2004). â&#128;&#156;Co-ordination at the Centre of Government: The Functions and&#13;
     Organization of the Government Office Comparative Analysis of OECD Countries, CEECs and&#13;
     Western Balkan Countries.â&#128;&#157; SIGMA Paper NÂ°35. Paris: OECD.&#13;
&#13;
Centro de PolÃ­ticas PÃºblicas UC. (2011). DiagnÃ³stico del Sistema Nacional de Inversiones. Santiago:&#13;
      Pontificia Universidad CatÃ³lica.&#13;
&#13;
Centro de PolÃ­ticas PÃºblicas UC. (2014). EvaluaciÃ³n de la MetodologÃ­a del Plan ChileGestiona.&#13;
      Santiago: Pontificia Universidad CatÃ³lica.&#13;
&#13;
ComitÃ© Inter-ministerial de ModernizaciÃ³n de la GestiÃ³n PÃºblica. 2000. â&#128;&#156;El Estado al Servicio de la&#13;
     Gente, Balance 1994 â&#128;&#147; 2000.â&#128;&#157;&#13;
&#13;
DirecciÃ³n de Presupuesto (DIPRES). Undated. â&#128;&#156;GuÃ­a, para la construcciÃ³n de, Indicadores de&#13;
      DesempeÃ±o, en los Servicios PÃºblicos.â&#128;&#157; Ministerio de Hacienda.&#13;
&#13;
DirecciÃ³n de Presupuestos (DIPRES). (1993). â&#128;&#156;Plan Piloto de ModernizaciÃ³n en la GestiÃ³n de los&#13;
      Servicios PÃºblicos,â&#128;&#157; Informe Final Primera Fase, Ministerio de Hacienda, August,&#13;
      unpublished.&#13;
&#13;
DirecciÃ³n de Presupuestos (DIPRES). (1995). â&#128;&#156;EvaluaciÃ³n del Plan Piloto de ModernizaciÃ³n de la&#13;
      GestiÃ³n (PPMG) en Servicios PÃºblicos,â&#128;&#157; Ministerio de Hacienda, December, unpublishsed.&#13;
&#13;
DirecciÃ³n de Presupuestos (DIPRES). (2001), â&#128;&#156;Informe de Finanzas Publicas.â&#128;&#157; Ministerio de&#13;
      Hacienda.&#13;
&#13;
DirecciÃ³n de Presupuestos (DIPRES). (2001a). â&#128;&#156;Programa de Mejoramiento de la GestiÃ³n (PMG).â&#128;&#157;&#13;
      Ministerio de Hacienda.&#13;
&#13;
DirecciÃ³n de Presupuestos (DIPRES). (2001b) â&#128;&#156;Balance Estructural del Gobierno Central,&#13;
      MetodologÃ­a y Estimaciones para Chile: 1987 â&#128;&#147; 2000.â&#128;&#157; Estudios de Finanzas Publicas,&#13;
      Ministerio de Hacienda.&#13;
&#13;
&#13;
&#13;
                                                                                                           47&#13;
&amp;#12;DIPRES (DirecciÃ³n de Presupuestos). (2001c). EvaluaciÃ³n de Programas e Indicadores de&#13;
     DesempeÃ±o, Transparencia y Mejoramiento de Los Procedimientos para la ElaboraciÃ³n y&#13;
     DiscusiÃ³n Presupuestaria, Ministerio de Hacienda.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2004). Encuesta Resultados Programa de EvaluaciÃ³n DIPRES,&#13;
     DivisiÃ³n de Control de GestiÃ³n, Ministerio de Hacienda, January, unpublished.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuesto), IDB. (2005a.) â&#128;&#156;Programa de EvaluaciÃ³n Documentos TÃ©cnicos&#13;
     y Administrativos del Proceso de EvaluaciÃ³n La Experiencia Chilena,â&#128;&#157; Ministerio de&#13;
     Hacienda, September.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuesto). (2005). â&#128;&#156;Resultados AplicaciÃ³n Encuestas, Proceso de&#13;
     EvaluaciÃ³n, Evaluaciones de Programas Gubernamentales (EPG), Evaluaciones de Impacto&#13;
     (EI), Evaluaciones Comprensivas del Gasto (ECG), Procesos 2003-2004-2005,â&#128;&#157; Volume I,&#13;
     DivisiÃ³n de Control de GestiÃ³n , Ministerio de Hacienda, October, unpublished.&#13;
&#13;
DIPRES and Banco Interamericano de Desarrollo (2005a). Estudio de Caso. EvaluaciÃ³n del&#13;
     Programa de Salud Bucal.&#13;
&#13;
DIPRES and Banco Interamericano de Desarrollo (2005b). Funcionamiento del Sistema de Control&#13;
     de GestiÃ³n en el Sector PÃºblico: El caso de la Subsecretaria de Telecomunicaciones de Chile.&#13;
     Septiembre de 2005.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuesto). (2009a.) â&#128;&#156;Proyecto de Presupuesto para el aÃ±o 2010,&#13;
     Formulario e Instrucciones,â&#128;&#157; Ministerio de Hacienda, July.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuesto). (2009b). â&#128;&#156;Programa de Mejoramiento de la GestiÃ³n (PMG).&#13;
     AÃ±o 2010 Programa Marco BÃ¡sico,â&#128;&#157; Documento TÃ©cnico, Ministerio de Hacienda,&#13;
     September.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2010). Informe de Finanzas PÃºblicas 2011. Santiago:&#13;
     DirecciÃ³n de Presupuestos - Ministerio de Hacienda.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2010). Instructivo Indicadores 2011. Retrieved November&#13;
     2012, from http://www.dipres.gob.cl/594/w3-channel.html&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2011). Informe de Finanzas PÃºblicas 2012. Santiago:&#13;
     DirecciÃ³n de Presupuestos - Ministerio de Hacienda.&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2012a). Balance de GestiÃ³n Integral (BGI). Retrieved from&#13;
     http://www.dipres.gob.cl/594/w3-channel.html&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2012b). Definiciones EstratÃ©gicas. Retrieved from&#13;
     http://www.dipres.gob.cl/594/w3-channel.html&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2012c). Informe de Finanzas PÃºblicas 2013. Santiago:&#13;
     DirecciÃ³n de Presupuestos - Ministerio de Hacienda.&#13;
&#13;
&#13;
                                                                                                 48&#13;
&amp;#12;DIPERS (DirecciÃ³n de Presupuestos). (2012d). Instrucciones para la presentaciÃ³n de programas y&#13;
     otras iniciativas al presupuesto. Retrieved from http://www.dipres.gob.cl/594/w3-&#13;
     channel.html&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2012e). Sistema de Monitoreo del DesempeÃ±o Institucional.&#13;
     Retrieved from http://www.dipres.gob.cl/594/w3-channel.html&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2012f). Sistema PlanificaciÃ³n-Control de GestiÃ³n. Retrieved&#13;
     from http://www.dipres.gob.cl/594/w3-channel.html&#13;
&#13;
DIPRES (DirecciÃ³n de Presupuestos). (2013). Informe de Finanzas PÃºblicas 2014. Santiago:&#13;
     DirecciÃ³n de Presupuestos - Ministerio de Hacienda.&#13;
&#13;
Dumas, V. Lafuente, M. y Parrado, S. (2013) El fortalecimiento del Centro de Gobierno para&#13;
    resultados en Chile. Nota TÃ©cnica IDB-TN-563. Banco Interamericano de Desarrollo.&#13;
&#13;
GuzmÃ¡n, M. (2003). â&#128;&#156;Sistema de Control de GestiÃ³n y Presupuestos por Resultados, La&#13;
    Experiencia Chilena,â&#128;&#157; DirecciÃ³n de Presupuestos, Ministerio de Hacienda, October.&#13;
&#13;
GuzmÃ¡n, M. (2005). â&#128;&#156;Sistema de Control de GestiÃ³n y Presupuestos por Resultados La Experiencia&#13;
    Chilena,â&#128;&#157; DivisiÃ³n de Control y GestiÃ³n, Ministerio de Hacienda, September.&#13;
&#13;
GuzmÃ¡n, M. (2007). â&#128;&#156;EvaluaciÃ³n de Programas. Notas TÃ©cnicas,â&#128;&#157; GestiÃ³n PÃºblica, Instituto&#13;
    Latinoamericano y del Caribe de PlanificaciÃ³n EconÃ³mica y Social (ILPES), United Nations&#13;
    (ECLAC), August.&#13;
&#13;
GuzmÃ¡n, M., and Marcel, M. (2008). â&#128;&#156;Hacia un CÃ­rculo Virtuoso en la Reforma Presupuestaria en&#13;
    Chile,â&#128;&#157; Presupuesto y Gasto PÃºblico 51 â&#128;&#147;(2/2008), Tendencias en la GestiÃ³n Presupuestaria,&#13;
    Secretaria General de Presupuestos y Gastos, Instituto de Estudios Fiscales, January.&#13;
&#13;
Marcel, M. (1993). â&#128;&#156;Gobernabilidad Fiscal, Presupuestos y Finanzas Publicas: Un Estudio a Partir&#13;
     de la Experiencia Chilena,â&#128;&#157; Final Report, July, unpublished.&#13;
&#13;
Marcel, M. (2002). â&#128;&#156;Las Opciones para la Reforma del Estado de Chile,â&#128;&#157; Reforma del Estado,&#13;
     Volume II, DirecciÃ³n Publica y Compras PÃºblicas, Centro de Estudios PÃºblicos, CEP,&#13;
     September.&#13;
&#13;
Ministerio de Desarrollo Social. (2011). Ley 20.530 - Crea el Ministerio de Desarrollo Social y&#13;
      modifica cuerpos legales que indica. Santiago.&#13;
&#13;
Ministerio de Hacienda. (2012). ModernizaciÃ³n del Estado: plan Chile Gestiona. Santiago, RM,&#13;
      Chile.&#13;
&#13;
Ministerio SecretarÃ­a General de la Presidencia. (2006). Reforma del Estado en Chile 2000 â&#128;&#147; 2006,â&#128;&#157;&#13;
      Proyecto de Reforma y ModernizaciÃ³n del Estado, February.&#13;
&#13;
OECD (Organization for Economic Cooperation and Development). (2004). â&#128;&#156;Budgeting in Chile,â&#128;&#157;&#13;
     Volume 4, No. 2.&#13;
&#13;
                                                                                                   49&#13;
&amp;#12;OECD (Organization for Economic Cooperation and Development). (2012). â&#128;&#156;Review of selected&#13;
     Budgeting Issues in Chile: Performance budgeting, medium term budgeting, budget&#13;
     fluexibilityâ&#128;&#157;.&#13;
&#13;
Waissbluth, M. (2006). La Reforma del Estado en Chile (1990-2005). Santiago: Departamento de&#13;
     IngenierÃ­a Industrial, Universidad de Chile.&#13;
&#13;
World Bank. (2008). â&#128;&#156;Chile: Estudio de EvaluaciÃ³n en Profundidad del Programa de Mejoramiento&#13;
     de la GestiÃ³n (PGM)," Volume 1, Poverty Reduction and Economic Management Unit, Latin&#13;
     America and the Caribbean, December.&#13;
&#13;
World Bank. (2005). Estudio de evaluaciÃ³n de impacto del Programa de EvaluaciÃ³n de Programas.&#13;
     Santiago.&#13;
&#13;
World Bank. (2001). â&#128;&#156;La FormulaciÃ³n de PolÃ­ticas PÃºblicas en la OECD: Ideas para AmÃ©rica Latina."&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                               50&#13;
&amp;#12;</ml:original-txt><ml:search-metadata><doc id="23610465">
        <url>
            http://documents.worldbank.org/curated/en/2014/07/23610465/monitoring-evaluation-system-case-chile-1990-2014
        </url>
        <availablein>English</availablein>
        <url_friendly_title>http://documents.worldbank.org/curated/en/2014/07/23610465/monitoring-evaluation-system-case-chile-1990-2014</url_friendly_title>
        <new_url>2014/07/23610465/monitoring-evaluation-system-case-chile-1990-2014</new_url>
        <disclosure_date>2015-01-12T00:00:00Z</disclosure_date>
        <disclosure_type>NA</disclosure_type>
        <ext_pub_date>2015-01-12T00:00:00Z</ext_pub_date>
        <disclstat>Disclosed</disclstat>
        <docm_id>090224b082c2557a</docm_id>
        <chronical_docm_id>090224b082c2557a</chronical_docm_id>
        <txturl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2015/01/12/000442464_20150112134537/Rendered/INDEX/936210NWP0Box30LIC00ecd0wp0290Chile.txt</txturl>
        <pdfurl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2015/01/12/000442464_20150112134537/Rendered/PDF/936210NWP0Box30LIC00ecd0wp0290Chile.pdf</pdfurl>
        <docdt>2014-07-01T00:00:00Z</docdt>
        <datestored>2015-01-12T00:00:00Z</datestored>
        <totvolnb>1</totvolnb>
        <versiontyp>Final</versiontyp>
        <versiontyp_key>1309935</versiontyp_key>
        <volnb>1</volnb>
        <repnme>
            Monitoring and evaluation system : the case
            of Chile 1990-2014
        </repnme>
        <abstracts>
            From its creation in the 1990s, the
            Chilean monitoring and evaluation (M and E) system has
            represented a substantial part of the effort to improve the
            use of Chile's public resources within a broader
            context of multiple initiatives designed to modernize and
            improve public management in many areas. This close
            relationship with the budget has determined the primary
            characteristics of the M and E system, in both its design
            and operations. The M and E system's institutional
            coverage includes all the organizations in the executive
            branch of the central government and those included in the
            budget law for the public sector. The objective of this
            document is to give a broad view of the M and E systems in
            Chile, distinguishing the three stages and providing lessons
            for other countries that are developing their own systems.
            The first section focuses on the first period and its two
            stages: 1990-2000 and 2000-2010. These stages concentrate
            mainly on the role played by the budget office. The second
            period covers 2010-13, in which light is shed on both the
            new system's actors and the emphasis adopted by the
            authorities in charge, but at the same time the authorities
            largely continue and strengthen the existing tools from the
            M and E system of the previous period. The third section of
            the paper summarizes success factors and obstacles to
            success in the two periods. Section four states general
            conclusions regarding the main system's challenges and
            section five includes lessons for other countries.
        </abstracts>
        <docna>
            Monitoring and evaluation system : the case
            of Chile 1990-2014
        </docna>
        <display_title>Monitoring and evaluation system
            : the case of Chile 1990-2014</display_title>
        <listing_relative_url>/research/2014/07/23610465/monitoring-evaluation-system-case-chile-1990-2014</listing_relative_url>
        <topic>Budget Execution and Treasury Management
            m1326100 2062,Budget Preparation  m1327722 2061,Monitoring and Evaluation m1326054 727,Finance and Growth m1327404 1081,Monitoring and Evaluation Systems m1326029 1156</topic>
        <subtopic>Poverty Impact Evaluation,E-Business,Poverty Monitoring &amp; Analysis,Labor Policies,Technology Industry</subtopic>
        <docty>Working Paper (Numbered Series)</docty>
        <teratopic>Industry,Private Sector Development,Social Protections and Labor,Poverty Reduction</teratopic>
        <count>Chile</count>
        <authors>
            <author>Guzman, Marcela</author>
            <author>Irarrazaval, Ignacio</author>
            <author>de los Rios, Boris</author>
        </authors>
        <geo_region_mdks>
            <geo_region_mdk>World!$!80475</geo_region_mdk>
            <geo_region_mdk>America!$!80450</geo_region_mdk>
            <geo_region_mdk>South America!$!80469</geo_region_mdk>
        </geo_region_mdks>
        <entityids>
            <entityid>000442464_20150112134537</entityid>
        </entityids>
        <admreg>Latin America &amp; Caribbean,Latin America &amp; Caribbean</admreg>
        <colti>Evaluation Capacity Development (ECD)
            working paper series ; no. 29</colti>
        <lang>English</lang>
        <historic_topic>Industry,Private Sector Development,Social Protections and Labor,Poverty Reduction</historic_topic>
        <topicv3>Budget Execution and Treasury Management
            m1326100 2062,Budget Preparation  m1327722 2061,Monitoring and Evaluation m1326054 727,Finance and Growth m1327404 1081,Monitoring and Evaluation Systems m1326029 1156</topicv3>
        <majdocty>Publications &amp; Research</majdocty>
        <keywd>
            absenteeism, access to information, access
            to information technology, accountability, accounting,
            algorithms, application of information, Auditing, audits,
            basic, beneficiaries, budget allocations, capacity building,
            communication media, communication technologies,
            communications media, comparison groups, Components,
            connectivity, control groups, Control System, coordination
            mechanisms, decision making process, delivery of goods,
            development effectiveness, Development Planning, domain,
            e-mail, economics, Employment, Evaluation Capacity,
            Evaluation Results, evaluators, ex post evaluation, ex post
            impact evaluation, Facsimile, Financial Administration,
            Financial Management, financial performance, financial
            resources, flexibility, general public, government
            employees, government organizations, government policies,
            group interviews, Impact Monitoring, implementation
            processes, implementation stage, information systems,
            information technologies, innovations, installation,
            institution, institutional capacities, institutional
            capacity, institutional framework, institutional support,
            international consultant, knowledge management, Learning,
            legal framework, M&amp;amp;E mechanisms, M&amp;amp;E
            Systems, M&amp;amp;E tools, Management System, monitoring
            mechanisms, monitoring tools, motivation, National Training,
            operational requirements, organization of information,
            Organizational Structure, outcome indicators, outputs,
            performance indicators, Performance Monitoring, process
            indicators, Program Evaluation, program implementation,
            program outcomes, Protocol, protocols, public actions,
            Public Administration, Public Policies, publishing,
            registers, registry, reliability, resource allocation,
            result, safety, search, Social Development, social policies,
            Social Programs, Social Services, supervision, targets,
            taxonomy, technical aspects, Technical Assistance, technical
            requirements, technical support, Telephone, tracking system,
            transparency, usability, uses, value chain, Web, website
        </keywd>
        <owner>Comm., Learning &amp; Strategy (IEGCS)</owner>
        <geo_regions>
            <geo_region>World</geo_region>
            <geo_region>America</geo_region>
            <geo_region>South America</geo_region>
        </geo_regions>
        <repnb>93621</repnb>
    </doc></ml:search-metadata><ml:annotations><ml:concepts><ml:concept>ICT</ml:concept><ml:concept>ICT for Development</ml:concept><ml:concept>Information Technology</ml:concept><ml:concept>Information and Communication Technologies (ICT)</ml:concept><ml:concept>Social Development &amp; Poverty</ml:concept><ml:concept>Finance and Development</ml:concept><ml:concept>Finance and Financial Sector Development</ml:concept><ml:concept>Teaching and Learning</ml:concept><ml:concept>Poverty Reduction</ml:concept><ml:concept>Poverty Reduction and Distributional Analysis</ml:concept><ml:concept>Poverty Reduction and Equity</ml:concept><ml:concept>Poverty and Inequality</ml:concept><ml:concept>General Public Administration Sector</ml:concept><ml:concept>Governance and Public Sector Management</ml:concept><ml:concept>Government</ml:concept><ml:concept>Institutions</ml:concept><ml:concept>Public Administration</ml:concept><ml:concept>Public Sector Development</ml:concept><ml:concept>Public Sector Management and Reform</ml:concept><ml:concept>Public Sector and Governance</ml:concept><ml:concept>Social Protections and Labor</ml:concept><ml:concept>International Competitiveness</ml:concept><ml:concept>International Economics and Trade</ml:concept><ml:concept>Trade Liberalization</ml:concept><ml:concept>Trade Liberalization and Regional Integration</ml:concept><ml:concept>Trade Restrictiveness</ml:concept><ml:concept>Trade and Integration</ml:concept><ml:concept>Information and Communication Technologies</ml:concept><ml:concept>Social Development</ml:concept><ml:concept>Financial Sector Development</ml:concept><ml:concept>Private Sector Development</ml:concept><ml:concept>Arts and Culture</ml:concept><ml:concept>Education</ml:concept><ml:concept>Health, Nutrition and Population</ml:concept><ml:concept>Poverty</ml:concept><ml:concept>Public Sector Management</ml:concept><ml:concept>Social Protection and Labor</ml:concept><ml:concept>Trade</ml:concept><ml:concept>Alternative Sentencing Options</ml:concept><ml:concept>Community Policing</ml:concept><ml:concept>Community based Policing</ml:concept><ml:concept>Correctional Services and Facilities</ml:concept><ml:concept>Corrections</ml:concept><ml:concept>Crime Policies</ml:concept><ml:concept>Crime Prevention</ml:concept><ml:concept>Crime and Society</ml:concept><ml:concept>Defense Services</ml:concept><ml:concept>Detention</ml:concept><ml:concept>Enforcement Policies and Oversight Mechanism</ml:concept><ml:concept>Forensic</ml:concept><ml:concept>Forensic Services</ml:concept><ml:concept>Investigation</ml:concept><ml:concept>Investigative Task Force Police</ml:concept><ml:concept>Juvenile Justice</ml:concept><ml:concept>Law Enforcement</ml:concept><ml:concept>Offender Reintegration</ml:concept><ml:concept>Police Administration and Management</ml:concept><ml:concept>Police Reform</ml:concept><ml:concept>Problem solving Policing</ml:concept><ml:concept>Prosecution</ml:concept><ml:concept>Restorative Justice</ml:concept><ml:concept>Therapeutic Justice</ml:concept><ml:concept>Victim Assistance</ml:concept><ml:concept>Victim Services</ml:concept><ml:concept>Victim-Offender Mediation</ml:concept><ml:concept>Impact Evaluations</ml:concept><ml:concept>Randomized Control Trials</ml:concept><ml:concept>Performance Appraisal</ml:concept><ml:concept>Performance Appraisal System</ml:concept><ml:concept>Performance Bonuses</ml:concept><ml:concept>Performance Incentives</ml:concept><ml:concept>Performance Pay</ml:concept><ml:concept>Medium Term Expenditure Frameworks (MTEF)</ml:concept><ml:concept>Participatory Budgeting</ml:concept><ml:concept>Performance Budgeting</ml:concept><ml:concept>Program Budgeting</ml:concept><ml:concept>Spending Reviews</ml:concept><ml:concept>Policy Coordination</ml:concept><ml:concept>Demographics</ml:concept><ml:concept>Measurement and Analysis</ml:concept><ml:concept>Poverty Assessment</ml:concept><ml:concept>Poverty Diagnostics</ml:concept><ml:concept>Poverty Impact Evaluation</ml:concept><ml:concept>Poverty Monitoring &amp; Analysis</ml:concept><ml:concept>Poverty Monitoring and Analysis</ml:concept><ml:concept>Management of Public Finance</ml:concept><ml:concept>Public Finance Management</ml:concept><ml:concept>Public Finances</ml:concept><ml:concept>Public Sector Economics</ml:concept><ml:concept>Public Sector Economics &amp; Finance</ml:concept><ml:concept>Efficiency of Public Expenditures</ml:concept><ml:concept>Public Expenditures</ml:concept><ml:concept>Public Financial Management</ml:concept><ml:concept>Public Spending</ml:concept><ml:concept>Analysis &amp; Monitoring</ml:concept><ml:concept>Delivery Units</ml:concept><ml:concept>Grievance Redress</ml:concept><ml:concept>Indicators</ml:concept><ml:concept>M&amp;E</ml:concept><ml:concept>Performance Measurement</ml:concept><ml:concept>Performance Reviews</ml:concept><ml:concept>Rapid Results Approaches</ml:concept><ml:concept>Performance Monitoring</ml:concept><ml:concept>Tracking Performance</ml:concept><ml:concept>GVCs</ml:concept><ml:concept>Production Sharing Networks</ml:concept><ml:concept>Value Chains</ml:concept><ml:concept>Contract Management</ml:concept><ml:concept>Governance Institutions</ml:concept><ml:concept>Institutional Arrangements in Public Procurement</ml:concept><ml:concept>Institutional Capacity</ml:concept><ml:concept>Institutional Reform</ml:concept><ml:concept>Legal Regulatory Framework</ml:concept><ml:concept>State-Society Relations</ml:concept><ml:concept>Civil Society</ml:concept><ml:concept>Banking</ml:concept><ml:concept>Media</ml:concept><ml:concept>Social Policy</ml:concept><ml:concept>Criminal Justice</ml:concept><ml:concept>Boundaries</ml:concept><ml:concept>Monitoring and Evaluation Systems</ml:concept><ml:concept>Impact Evaluation</ml:concept><ml:concept>Impact Assessment</ml:concept><ml:concept>Individual Performance Management</ml:concept><ml:concept>Budget Preparation and Management Techniques</ml:concept><ml:concept>External Audit</ml:concept><ml:concept>Center of Government</ml:concept><ml:concept>Population</ml:concept><ml:concept>Knowledge Management</ml:concept><ml:concept>Poverty Measurement and Analysis</ml:concept><ml:concept>Public Finance</ml:concept><ml:concept>Managing Public Finances</ml:concept><ml:concept>Monitoring and Evaluation</ml:concept><ml:concept>Management Information Systems</ml:concept><ml:concept>Global Value Chains</ml:concept></ml:concepts><ml:geo-regions><ml:geo-region>Americas</ml:geo-region><ml:geo-region>Caribbean</ml:geo-region><ml:geo-region>Chile</ml:geo-region></ml:geo-regions></ml:annotations></ml:doc-envelope>