<?xml version="1.0" encoding="UTF-8"?><ml:doc-envelope xmlns:ml="http://marklogic.com/poolparty/worldbank"><ml:original-txt>ï»¿                                                                           68236&#13;
 S A B E R â&#128;&#147; S Y S T E M S A P P R O A C H F O R B E T T E R E D U C AT I O N R E S U LT S&#13;
&#13;
                                                          STUDENT ASSESSMENT&#13;
                                                                                             3&#13;
&#13;
&#13;
&#13;
&#13;
      Disseminating&#13;
  and Using Student&#13;
        Assessment&#13;
Information in Chile&#13;
                                              MarÃ­a-JosÃ© RamÃ­rez&#13;
&amp;#12;&amp;#12;                   WORKING PAPER NO. 3&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student&#13;
Assessment Information in Chile&#13;
                       MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;Â© 2012 The International Bank for Reconstruction and Development / The World Bank&#13;
1818 H Street NW&#13;
Washington DC 20433&#13;
Telephone: 202 473 1000&#13;
Internet: www.worldbank.org&#13;
&#13;
1234    15 14 13 12&#13;
&#13;
This work is a product of the staff of The World Bank with external contributions. The findings,&#13;
interpretations, and conclusions expressed in this work do not necessarily reflect the views of&#13;
The World Bank, its Board of Executive Directors, or the governments they represent.&#13;
    The World Bank does not guarantee the accuracy of the data included in this work. The&#13;
boundaries, colors, denominations, and other information shown on any map in this work do&#13;
not imply any judgment on the part of The World Bank concerning the legal status of any&#13;
territory or the endorsement or acceptance of such boundaries.&#13;
&#13;
Rights and Permissions&#13;
The material in this work is subject to copyright. Because The World Bank encourages&#13;
dissemination of its knowledge, this work may be reproduced, in whole or in part, for&#13;
noncommercial purposes as long as full attribution to this work is given.&#13;
    Any queries on rights and licenses, including subsidiary rights, should be addressed to the&#13;
Office of the Publisher, The World Bank, 1818 H Street NW, Washington, DC 20433, USA; fax:&#13;
202 522 2422; e mail: pubrights@worldbank.org.&#13;
&#13;
Cover design: Patricia Hord.Graphik Design, Alexandria, VA&#13;
&amp;#12;Contents&#13;
About the Series ...............................................................................................................v&#13;
About the Author.......................................................................................................... vii&#13;
Abstract ............................................................................................................................ix&#13;
Executive Summary ........................................................................................................xi&#13;
Introduction ......................................................................................................................1&#13;
Chileâ&#128;&#153;s Overall Assessment Program............................................................................3&#13;
Dissemination Purposes and Mechanisms...................................................................5&#13;
Drivers for Change......................................................................................................... 13&#13;
Impact of the Assessment Program............................................................................. 14&#13;
Lessons Learned ............................................................................................................. 15&#13;
References ....................................................................................................................... 21&#13;
&#13;
Figures&#13;
Figure 1. Trends in Studentsâ&#128;&#153; Reading Mean Scores: SIMCE, Grade 4 ....................5&#13;
Figure 2. School Report with Results for Teachers and Principals ...........................8&#13;
Figure 3. School Results Published in a Chilean Newspaper .................................. 10&#13;
Figure 4. Parent Report ................................................................................................. 11&#13;
Figure 5. Geo referential System with School Results .............................................. 12&#13;
&#13;
Table&#13;
Table 1. SIMCE Dissemination Strategy: Mechanisms, Purpose, Audiences,&#13;
    and Content...............................................................................................................6&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                                                                           iii&#13;
&amp;#12;&amp;#12;About the Series&#13;
Building strong education systems that promote learning is fundamental to&#13;
development and economic growth. Over the past few years, as developing&#13;
countries have succeeded in building more classrooms, and getting millions&#13;
more children into school, the education community has begun to actively&#13;
embrace the vision of measurable learning for all children in school. However,&#13;
learning depends not only on resources invested in the school system, but also&#13;
on the quality of the policies and institutions that enable their use and on how&#13;
well the policies are implemented.&#13;
     In 2011, the World Bank Group launched Education Sector Strategy 2020:&#13;
Learning for All, which outlines an agenda for achieving â&#128;&#156;Learning for Allâ&#128;? in&#13;
the developing world over the next decade. To support implementation of the&#13;
strategy, the World Bank commenced a multi year program to support countries&#13;
in systematically examining and strengthening the performance of their&#13;
education systems. This evidence based initiative, called SABER (Systems&#13;
Approach for Better Education Results), is building a toolkit of diagnostics for&#13;
examining education systems and their component policy domains against&#13;
global standards, best practices, and in comparison with the policies and&#13;
practices of countries around the world. By leveraging this global knowledge,&#13;
SABER fills a gap in the availability of data and evidence on what matters most&#13;
to improve the quality of education and achievement of better results.&#13;
     SABER Student Assessment, one of the systems examined within the SABER&#13;
program, has developed tools to analyze and benchmark student assessment&#13;
policies and systems around the world, with the goal of promoting stronger&#13;
assessment systems that contribute to improved education quality and learning&#13;
for all. To help explore the state of knowledge in the area, the SABER Student&#13;
Assessment team invited leading academics, assessment experts, and&#13;
practitioners from developing and industrialized countries to come together to&#13;
discuss assessment issues relevant for improving education quality and learning&#13;
outcomes. The papers and case studies on student assessment in this series are&#13;
the result of those conversations and the underlying research. Prior to&#13;
publication, all of the papers benefited from a rigorous review process, which&#13;
included comments from World Bank staff, academics, development&#13;
practitioners, and country assessment experts.&#13;
     All SABER Student Assessment papers in this series were made possible by&#13;
support from the Russia Education Aid for Development Trust Fund (READ TF).&#13;
READ TF is a collaboration between the Russian Federation and the World Bank&#13;
that supports the improvement of student learning outcomes in low income&#13;
countries through the development of robust student assessment systems.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                    v&#13;
&amp;#12;          The SABER working paper series was produced under the general guidance&#13;
     of Elizabeth King, Education Director, and Robin Horn, Education Manager in&#13;
     the Human Development Network of the World Bank. The Student Assessment&#13;
     papers in the series were produced under the technical leadership of Marguerite&#13;
     Clarke, Senior Education Specialist and SABER Student Assessment Team&#13;
     Coordinator in the Human Development Network of the World Bank. Papers in&#13;
     this series represent the independent views of the authors.&#13;
&#13;
&#13;
&#13;
&#13;
vi                                                                  MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;About the Author&#13;
MarÃ­a JosÃ© RamÃ­rez is an Education Specialist in the Human Development&#13;
Network at the World Bank. She has been working on the SABER Student&#13;
Assessment initiative, developing tools for evaluating the quality of assessment&#13;
systems. Before joining the Bank, she was involved in key reforms of the&#13;
assessment system in Chile, with responsibilities in both national and&#13;
international assessments. In the Chilean Ministry of Education, she headed the&#13;
data analysis unit of the assessment program (SIMCE) (2005â&#128;&#147;06) and worked as a&#13;
national coordinator for TIMSS (1998â&#128;&#147;2000). She also was the College Director of&#13;
Universidad Diego Portales, Chile (2007â&#128;&#147;09). She led university level projects&#13;
related to quality assurance, institutional analysis, accreditation, and academic&#13;
evaluation. In the United States, she was a research assistant in the TIMSS and&#13;
PIRLS International Study Center (2000â&#128;&#147;04). She received her PhD in educational&#13;
research, measurement, and evaluation from Boston College (2004) and was the&#13;
recipient of a Fulbright scholarship (2000) and the 2005 award for best empirical&#13;
dissertation from the International Association for the Evaluation of Educational&#13;
Achievement (IEA). Her work and publications focus on student assessments,&#13;
education quality, and comparative education.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                     vii&#13;
&amp;#12;&amp;#12;Abstract&#13;
Student assessment plays a key role in improving education. However, many&#13;
countries do not disseminate and make effective use of their student assessment&#13;
information. This paper discusses Chileâ&#128;&#153;s effective use of its assessment&#13;
information and draws lessons for other countries. A key lesson from the Chilean&#13;
experience is that effective use of assessment information is a challenging task&#13;
that takes time, effort, and resources. Another lesson is that the task requires&#13;
leadership, long term planning, and consensus building. Countries able to learn&#13;
from Chileâ&#128;&#153;s lessons will be in a better position to make effective use of their&#13;
student assessments and, ultimately, to contribute to education quality and&#13;
learning.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                    ix&#13;
&amp;#12;&amp;#12;Executive Summary&#13;
The effective use of student assessment information remains a key challenge for&#13;
developing countries. Countries that have managed to put in place their large&#13;
scale assessment may still face important barriers to effectively disseminate and&#13;
use assessment information. How can countries make more effective use of&#13;
assessment information? What can they learn from other countries that have&#13;
more experience using assessment information?&#13;
     Chileâ&#128;&#153;s assessment program, SIMCE (Sistema de MediciÃ³n de la Calidad de&#13;
la EducaciÃ³n), offers important lessons to other countries aiming to better use&#13;
their assessment information. SIMCEâ&#128;&#153;s dissemination strategy is the product of&#13;
more than 20 years of experience. Chile systematically uses assessment to inform&#13;
decision making at different levels of the education system. The country has&#13;
shown increases in student learning during the last decade. These increases are,&#13;
at least in part, the consequence of good decision making informed by evidence&#13;
from the assessment.&#13;
     SIMCE is a highly institutionalized assessment program. It meets most of the&#13;
technical standards for educational assessments, and provides the most credible&#13;
indicator of educational quality in Chile. SIMCE has a comprehensive&#13;
dissemination strategy that responds to three main purposes: to inform policy, to&#13;
provide pedagogical support to educators, and to hold schools accountable. For&#13;
each one of these purposes, SIMCE has in place one or more mechanisms to&#13;
disseminate information. Each mechanism targets a specific audience with&#13;
tailored information. The most important mechanisms are the website, the&#13;
national report, the school report, and the parent report.&#13;
     Several contextual drivers allowed for development of the SIMCE&#13;
dissemination strategy. These drivers include the political context in which the&#13;
assessment took place, the institutional conditions of the assessment office,&#13;
political pressures to improve the assessment, and international influences. The&#13;
single most important driver to further develop the dissemination strategy was&#13;
the SIMCE Commission. This technical political commission was appointed by&#13;
the Minister of Education to review the assessment program. The commission&#13;
built consensus around the purposes of the assessment and the mechanisms to&#13;
disseminate assessment information. SIMCE has been gradually implementing&#13;
the recommendations of this commission.&#13;
     The purpose of this paper is twofold. First, it aims to describe the uses of&#13;
student assessment information in Chile, highlighting the purposes, audiences,&#13;
and mechanisms to disseminate information, as well as the drivers that allowed&#13;
for these uses to take place. Second, the paper aims to draw lessons from the&#13;
Chilean experience in order to inform other countries seeking to improve their&#13;
assessment programs. The Chilean experience shows that making effective use of&#13;
assessment information is a very challenging task that takes time, effort, and&#13;
resources. A sustainable dissemination strategy needs to be built gradually, and&#13;
the conditions for the disseminated information to be used needs to be ensured.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                     xi&#13;
&amp;#12;&amp;#12;Disseminating and Using Student&#13;
Assessment Information in Chile&#13;
MarÃ­a JosÃ© RamÃ­rez&#13;
&#13;
&#13;
&#13;
Introduction&#13;
The effective use of assessment information remains a key challenge for&#13;
developing countries. Those that have managed to put in place large scale&#13;
assessment program may still face important barriers to effectively disseminating&#13;
and using assessment information. For instance, stakeholders may have negative&#13;
attitudes toward the assessment; information may be collected but not&#13;
disseminated; or information may be disseminated, but not understood or used&#13;
by stakeholders. In all these cases, the assessment would fail to contribute to its&#13;
ultimate purpose of improving learning and education. How can developing&#13;
countries make more effective use of assessment information and what can they&#13;
learn from other countriesâ&#128;&#153; experiences?&#13;
     Chileâ&#128;&#153;s SIMCE assessment program offers important lessons to other&#13;
countries aiming to better use their assessment information. SIMCE was the first&#13;
national assessment in Latin America, and it has been operating on a yearly basis&#13;
since 1988. The program is highly institutionalized and has been mandated by&#13;
law since 1990. SIMCE has a comprehensive dissemination strategy aimed at&#13;
informing policy, providing pedagogical support to educators, and holding&#13;
schools accountable. Chile systematically uses assessment to inform decision&#13;
making at different levels of the education system.&#13;
     Student achievement has been gradually improving in Chile. SIMCE shows&#13;
that students have been reaching significantly higher mean scores since year&#13;
2000, and the OECD Programme for International Student Assessment (PISA)&#13;
has singled out Chile as the country that most improved its reading results&#13;
between 2000 and 2009. The 2010 McKinsey report upheld Chile as a â&#128;&#156;promising&#13;
starâ&#128;? because of its sustained increase in student learning. This increase is, at&#13;
least in part, the consequence of good decision making informed by evidence&#13;
from SIMCE.1&#13;
     In considering the lessons from this case study, countries should&#13;
acknowledge the context from which these lessons come from. Chile is a political&#13;
and economically stable upper middle income country that still needs to reduce&#13;
poverty and inequality rates. The countryâ&#128;&#153;s return to democracy in 1990&#13;
&#13;
&#13;
1&#13;
 All data gathered from OECDâ&#128;&#153;s Education at a Glance report and PISA program (http://www.oecd.org/edu/),&#13;
Chileâ&#128;&#153;s national assessment program (www.simce.cl), and McKinsey &amp; Co. (2010).&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                                            1&#13;
&amp;#12;    provided the necessary political stability to allow for social and economic&#13;
    growth. Chile is a leader in Latin America for its economic development (gross&#13;
    national income per capita of US$9,950), economic growth (4.1 percent annual&#13;
    growth per capita between 1991 and 2005), and its â&#128;&#156;very highâ&#128;? human&#13;
    development index. Poverty was reduced from 20 percent to 15 percent between&#13;
    2000 and 2009. However, Chile is lagging in the distribution of the wealth: its&#13;
    Gini coefficient (52) is the worst among OECD countries.2&#13;
         The education system in Chile is relatively strong when compared to Latin&#13;
    America, but still weak when compared to richer countries. Coverage is&#13;
    universal in primary education and is widely available in secondary education&#13;
    (gross enrollment rate 96 percent). There are 3.5 million students distributed in&#13;
    nearly 9,000 schools, most of which (57 percent) are private. The schools are&#13;
    funded through a national voucher policy, where the state pays a fixed amount&#13;
    of money to the school (no matter if public or private) based on the number of&#13;
    students attending classes. Investment in education is very high when&#13;
    considering public and private expenditures (7.1 percent of GDP), but it is low&#13;
    when considering public investment only (4.2 percent of GDP). The results of&#13;
    national and international assessment programs show that Chilean students are&#13;
    slowly reaching higher performance levels. However, the overall performance&#13;
    remains low compared to richer OECD countries, and is very unevenly&#13;
    distributed along social classes.3&#13;
         The purpose of this paper is twofold. First, it aims to describe the uses of&#13;
    student assessment information in Chile; highlighting the purposes, audiences,&#13;
    and mechanisms to disseminate information; and describe the drivers that&#13;
    allowed for these uses to take place. Second, the paper aims to draw lessons from&#13;
    the Chilean experience in order to inform other countries seeking to improve&#13;
    their assessment programs. The Chilean experience shows that making effective&#13;
    use of assessment information is a very challenging task that takes time, effort,&#13;
    and resources. To begin, a sustainable dissemination strategy needs gradually to&#13;
    be built. Then, an assessment culture and the right institutional conditions need&#13;
    to be developed for the assessment information to be used.&#13;
         The paper is structured as follows. After the introduction, the next section&#13;
    provides some historical background and describes the current status of Chileâ&#128;&#153;s&#13;
    assessment program. Subsequent sections outline the dissemination purposes&#13;
    and mechanisms currently in place; analyze the drivers that allowed the current&#13;
    dissemination strategy to take place; and discuss the evidence regarding the&#13;
&#13;
&#13;
    2&#13;
      All data gathered from the World Bank (www.worldbank.org), the United Nations Development&#13;
    Program (http://hdr.undp.org/en/statistics), The Central Bank of Chile (www.bcentral.cl), Chileâ&#128;&#153;s&#13;
    Ministry of Social Development (www.ministeriodesarrollosocial.gob.cl), and from the Human&#13;
    Development Report of the United Nations Development Program (http://hdr.undp.org/en/).&#13;
    3&#13;
      All data gathered from OECDâ&#128;&#153;s Education at a Glance report and PISA program (www.oecd.org/edu),&#13;
    Chileâ&#128;&#153;s Ministry of Education (www.mineduc.cl), and Chileâ&#128;&#153;s national assessment program&#13;
    (www.simce.cl).&#13;
&#13;
&#13;
&#13;
2                                                                                MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;impact of the assessment. The last section presents the main lessons to be&#13;
extracted from the Chilean experience.&#13;
&#13;
&#13;
&#13;
Chileâ&#128;&#153;s Overall Assessment Program&#13;
History&#13;
Chileâ&#128;&#153;s political context has shaped the purposes, uses, and consequences of the&#13;
assessment program. Therefore, it is important to highlight that context in order&#13;
to understand how the assessment information has been used to improve&#13;
quality, and how these uses have grown in complexity across the years.&#13;
     Chileâ&#128;&#153;s large scale assessment program was created under a right wing&#13;
dictatorship that ran from 1973 to 1990. The assessment was piloted during the&#13;
1980s with the purpose of holding schools accountable by informing parents&#13;
about school quality. Parent would choose the best school for their children&#13;
based on school results, no matter if the school was public or private. Therefore,&#13;
the assessment was developed to serve as an information mechanism in the&#13;
context of a national voucher policy. According to this policy, the state would&#13;
pay a subsidy to public and private schools based on student attendance. The&#13;
assessment program was tasked with improving efficiency, to be achieved by&#13;
pushing the schools to compete for higher test scores, parent choice, and funding&#13;
(Majluf 1987).&#13;
     The assessment program was also created with the aim of monitoring&#13;
effectiveness of educational policies and supporting pedagogy. Effectiveness&#13;
would be addressed by monitoring how many students were reaching the&#13;
performance standards set by the national curriculum. Pedagogical support&#13;
would be provided by disseminating pedagogical guidelines and reports to&#13;
school supervisors and teachers (Himmel 1996; Majluf 1987).&#13;
     With the return of democracy in 1990, the education priorities shifted&#13;
towards quality and equity, and an ambitious education reform was launched. A&#13;
new curriculum was introduced, putting a greater emphasis on the learning of&#13;
higher order skills and on the capacity of the students to apply their knowledge&#13;
and skills to real life situations. The introduction of this new curriculum pushed&#13;
for the alignment of other components of the school system, including the&#13;
assessment. This alignment involved adjusting the tests so that they measured&#13;
what students were expected to learn according to the curriculum. It also&#13;
involved reporting results to teachers in a more meaningful way. SIMCE started&#13;
reporting the percentage of students reaching different performance standards,&#13;
and provided descriptions of what students knew and were able to do at each&#13;
standard level.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                      3&#13;
&amp;#12;    Current Status&#13;
    SIMCE is a technically sophisticated assessment program. The core subject areas&#13;
    of the assessment are mathematics, Spanish language, and social and natural&#13;
    sciences. In recent years, new areas of the curriculum have been added on a&#13;
    sample base (writing, English language, computer skills, and physical&#13;
    education). The test questions are mainly in multiple choice format, but open&#13;
    ended questions and essays have gradually been introduced. All schools and&#13;
    students in the target grades (grades 4, 8, and 10) participate in the assessment&#13;
    (census). In 2010, nearly 500,000 students from near 9,000 schools answered the&#13;
    SIMCE tests. Students, their parents, and teachers provide background&#13;
    information (for example, socioeconomic status, opportunities to learn at school,&#13;
    teaching qualifications) through questionnaires. Around 22,500 test supervisors&#13;
    and external administrators are directly involved in the field operation, the&#13;
    success of which requires high levels of expertise.&#13;
         SIMCE meets most of the technical standards for educational assessments,&#13;
    hence ensuring the validity and reliability of the assessment. The tests are&#13;
    constructed following rigorous procedures to ensure that test questions are an&#13;
    accurate representation of the curriculum. Tests from consecutive years are&#13;
    equated to ensure the comparability of results. Test administration is&#13;
    standardized to ensure the same testing conditions for all the students.&#13;
    Accommodations for special needs students have been gradually introduced.&#13;
    Test results and related information are widely disseminated to reach different&#13;
    audiences and stakeholders. SIMCE has high credibility and has never suffered&#13;
    from a major leakage.&#13;
         SIMCE has centered attention on student learning, and its results are&#13;
    systematically used to inform decision making. The programâ&#128;&#153;s results are widely&#13;
    covered by the media, usually on the front pages of newspapers or as the main&#13;
    story of the news on television. The assessment results are regularly used for&#13;
    policy design, analysis, and evaluation. Incentives are assigned to teachers and&#13;
    schools based on assessment results. To a lesser extent, schools and teachers&#13;
    analyze their studentsâ&#128;&#153; results and make pedagogical decisions accordingly.&#13;
         Despite important improvements, SIMCE still needs to move forward to&#13;
    meet some important standards of educational assessment. First, SIMCE does not&#13;
    have permanent mechanisms to monitor the consequences of the assessment.&#13;
    That is, the assessment program does not conduct regular studies to monitor&#13;
    how test results are being understood, valued, and used by educators, parents,&#13;
    and policy makers, and how they ultimately impact student learning. The&#13;
    information available about the consequences of the assessment mainly comes&#13;
    from ad hoc studies. Second, SIMCE does not publish a comprehensive technical&#13;
    report and does not provide data files that would allow independent researchers&#13;
    to replicate results.&#13;
&#13;
&#13;
&#13;
&#13;
4                                                                   MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;Dissemination Purposes and Mechanisms&#13;
The following sections describe how Chile has used the assessment information&#13;
to meet three main purposes: to inform policy, to provide pedagogical support,&#13;
and to hold schools accountable.&#13;
&#13;
Inform Policy&#13;
The primary use of the assessment information has been to inform policy.&#13;
Political pressures to improve education have lead to more evidence based&#13;
decision making, especially at the Ministry of Education. SIMCE has been used&#13;
to monitor quality and equity of education, to design and evaluate intervention&#13;
programs, and to target resources toward the lowest performing schools. For&#13;
example, SIMCE data is used to monitor education quality at the country level&#13;
(figure 1). The data was also used to evaluate the impact of the SNED&#13;
accountability program discussed later in this paper (Gallego 2008; Rau and&#13;
Contreras 2008).&#13;
&#13;
Figure 1. Trends in Studentsâ&#128;&#153; Reading Mean Scores: SIMCE, Grade 4&#13;
&#13;
&#13;
&#13;
&#13;
Source: SIMCE 2010 national report.&#13;
&#13;
&#13;
     Both quality and equity indicators are used to inform policy and decision&#13;
making. The most widely used indicator to inform policy (and the one with the&#13;
strongest impact in the media) is the change in national mean scores across years.&#13;
Changes in mean scores for public and private schools and for schools that serve&#13;
students from different socioeconomic backgrounds also receive considerable&#13;
attention. The impact of policies in equity is mainly measured by the changes in&#13;
the achievement gap between lower and higher income students.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                      5&#13;
&amp;#12;         SIMCE information is disseminated within the Ministry of Education to&#13;
    ensure its use for decision making. Previous to the release of the SIMCE results,&#13;
    the dissemination strategy is widely discussed with the minister and his/her&#13;
    advisors, therefore ensuring that they have firsthand understanding of the&#13;
    results. After the results release, the main findings are presented to the broader&#13;
    staff at the Ministry of Education. The mechanisms used to inform policy are the&#13;
    SIMCE national report, the press kit, the data files, and website (table 1).&#13;
&#13;
&#13;
    Table 1. SIMCE Dissemination Strategy: Mechanisms, Purpose, Audiences, and&#13;
    Content&#13;
    Assessment guidelines (since 1988)&#13;
    Purpose: Provide pedagogical support.&#13;
    Audience: School principal, pedagogical coordinators and teachers.&#13;
    Content: (a) Assessment framework and its relationship to the national curriculum. (b) Examples of&#13;
    test questions with an analysis of the contents and skills required to answer them correctly.&#13;
    Others: Distributed to all schools before the assessment (usually in the middle of the school year).&#13;
    Also available online. Publication highly valued by teachers.&#13;
    School report (since 1988)&#13;
    Purpose: Provide pedagogical support.&#13;
    Audience: School principal, pedagogical coordinators and teachers.&#13;
    Content: (a) National-, school-, and class-level mean scores by subject areas and grades tested.&#13;
    (b) Differences between school mean scores and mean scores from the previous assessment, from&#13;
    the national mean, and from schools of the same socioeconomic group. (c) Percent of students by&#13;
    performance levelâ&#128;&#148;advanced, intermediate, beginner. (d) Examples of test questions with an&#13;
    analysis of the contents and skills required to answer them correctly. (e) Workshop guidelines for&#13;
    the schools to analyze assessment results and set improvement plan. (See figure 2.)&#13;
    Others: Distributed to all schools that participated in the assessment once the SIMCE results are&#13;
    released (usually at the beginning of the next school year).&#13;
    National report (since 2006)&#13;
    Purpose: Inform policy.&#13;
    Audience: Decision makers, general public.&#13;
    Content: (a) National and regional mean scores in subject areas and grades tested. (b) Percent of&#13;
    students by performance levelâ&#128;&#148;advanced, intermediate, beginner. (c) Mean scores by&#13;
    socioeconomic background, gender, public/private school. (d) Trends in mean scores across years.&#13;
    Others: Distributed at the central, regional, and provincial offices of the Ministry of Education.&#13;
    Distributed to persons likely to be interviewed by the media (e.g., university professors).&#13;
    Newspaper supplement (since 1995)&#13;
    Purpose: Hold schools accountable.&#13;
    Audience: Parents, general public.&#13;
    Content: (a) School mean scores, and mean scores by subject areas and grades tested. (b)&#13;
    Differences between school mean scores and mean scores from the previous assessment, from&#13;
    the national mean, and from the mean of schools from the same socioeconomic group.&#13;
    Others: Published in a newspaper with national and regional coverage. Usually accompanied by&#13;
    rankings of schools.&#13;
                                                                               (Table continues on next page)&#13;
&#13;
&#13;
&#13;
&#13;
6                                                                                    MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;Table 1 (continued)&#13;
&#13;
Parent report (since 2005)&#13;
Purpose: Hold schools accountable and involve parents in school.&#13;
Audience: Parents.&#13;
Content: (a) School mean scores, and mean scores by subject areas and grades tested. (b)&#13;
Differences between school mean scores, and between subject area/grade mean scores of schools&#13;
from the same socioeconomic group. (c) Percent of students reaching different performance&#13;
standards. (d) Recommendations to support student learning. (See figure 4.)&#13;
Others: Distributed to parents through the schools once the assessment results are released&#13;
(usually at the beginning of the school year). Also available online.&#13;
Online item bank (since 2007)&#13;
Purpose: Provide pedagogical support.&#13;
Audience: Teachers.&#13;
Content: Offers released test questions from all subject areas and target grades. Includes&#13;
questions from both the national and international assessments.&#13;
Others: Teachers can search test questions based on subject area, school cycle, and questions&#13;
format (multiple choice or open-ended).&#13;
Press kit (since 2006)&#13;
Purpose: Inform policy.&#13;
Audience: Journalists and regional offices of education.&#13;
Content: PowerPoint presentation with main results.&#13;
Others: Distributed to journalists during the press release or before with embargo.&#13;
Data files (since 2005)&#13;
Purpose: Inform policy, provide pedagogical support, and hold schools accountable, depending on&#13;
research topic.&#13;
Audience: Researchers.&#13;
Content: Data files with school-level results.&#13;
Others: Data files with student-level results are provided upon request after justifying the research&#13;
project and committing not to use the results to identify students or teachers.&#13;
Data analysis tool (since 2007)&#13;
Purpose: Inform policy, provide pedagogical support, and hold schools accountable, depending on&#13;
the type of analysis.&#13;
Audience: Researchers and decision makers.&#13;
Content: Computes mean scores, differences in mean scores, and percent of students reaching&#13;
different performance standards. Computes results for different years, grades, public and private&#13;
schools, subject areas, gender, and socioeconomic level, among others.&#13;
Others: Data file with student-level results are provided upon request after justifying the research&#13;
project and committing not to use the results to identify students or teachers.&#13;
Geo-referential system (since 2010)&#13;
Purpose: Hold schools accountable.&#13;
Audience: Parents.&#13;
Content: Google maps with the geographical location of schools and their mean scores (figure 5).&#13;
Others: Parents can compare the scores of schools that are in the same geographic area.&#13;
Website www.simce.cl (since 2001)&#13;
Purpose: Inform policy, provide pedagogical support, and hold schools accountable.&#13;
Audience: General public.&#13;
Content: All the mechanisms described above. Also purposes of the assessment, organizational&#13;
structure of SIMCE, technical documents, and references to publications using SIMCE data.&#13;
Source: SIMCE.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                                         7&#13;
&amp;#12;    Provide Pedagogical Support&#13;
    The assessment information is also used to provide pedagogical support to the&#13;
    schools. However, this use has been second in importance compared to&#13;
    informing policy. Two main factors that have contributed to this are a weak&#13;
    assessment culture in the schools, and the publication of assessment results that&#13;
    have little pedagogical meaning for teachers.&#13;
         Several mechanisms allow using the assessment to provide pedagogical&#13;
    support to the schools. The two most important ones are the assessment&#13;
    guidelines and the school report. Complimentary mechanisms are the online&#13;
    item bank, the assessment data files, the data analysis tool, and the website&#13;
    (table 1).&#13;
         The school report           Figure 2. School Report with Results for&#13;
    (figure 2) is distributed to     Teachers and Principals&#13;
    all participating schools,&#13;
    and     includes     detailed&#13;
    information about the&#13;
    school results compared to&#13;
    the previous year, the&#13;
    national mean, and the&#13;
    mean of schools that serve&#13;
    students from a similar&#13;
    socioeconomic background.&#13;
    The      report     provides&#13;
    examples of the test&#13;
    questions, distribution of&#13;
    studentsâ&#128;&#153; responses in&#13;
    multiple choice questions,&#13;
    examples of responses to&#13;
    open ended questions, and&#13;
    scoring criteria. The test&#13;
    questions and student&#13;
    responses are analyzed in&#13;
    terms of contents and&#13;
    skills. Since 2000, results      Source: SIMCE.&#13;
&#13;
    indicate the percentage of&#13;
    students reaching different performance levels; this was an important step to&#13;
    provide pedagogical meaning to the results.&#13;
         However, there are weak institutional conditions and incentives for&#13;
    educators to use SIMCE results at the school level. The Ministry of Education has&#13;
    addressed this weakness with seminars and workshops for the schools to analyze&#13;
    their results. Guidelines for the workshops are provided in the school report.&#13;
    From 2004 to 2008, the Ministry of Education mandated that all schools&#13;
    implement a full day â&#128;&#156;SIMCE workshopâ&#128;? to analyze their results and plan for&#13;
&#13;
&#13;
8                                                                   MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;improvement. However, doing so implied cancelling classes for all the students.&#13;
Now schools are expected to run the workshops without cancelling classes,&#13;
during non teaching hours. For many schools it is just not feasible to gather all its&#13;
teachers to review the assessment. Another problem is that the schools are not&#13;
accountable to an external body (for example, municipalities) regarding their&#13;
improvement plans.&#13;
     A new law approved in 2011 (yet to be implemented), should create better&#13;
institutional conditions and incentives for educators to analyze and use SIMCE&#13;
results (Government of Chile 2011). It is promising that this new law will require&#13;
schools create improvement plans (based on SIMCE results among other&#13;
indicators) and be accountable to an external body for their improvements.&#13;
Providing feedback to the schools and teachers with useful assessment&#13;
information does not seem to be enough to improve higher student learning. The&#13;
right institutional arrangements and incentives should also be in place for the&#13;
assessment information to have an effect.4&#13;
     Moreover, SIMCE does not systematically inform teacher training&#13;
institutions to ensure that future educators are â&#128;&#156;assessment literate.â&#128;? In fact, pre&#13;
service and in service teacher training programs barely cover assessment topics.&#13;
As a consequence, educators know little about how to analyze student responses&#13;
and how to use this information to improve pedagogy.&#13;
&#13;
Hold Schools Accountable&#13;
A third important use of assessment information is holding schools accountable&#13;
for student performance. This use of assessment is reached by a combination of&#13;
strategies aimed to inform the general public about the school results and to&#13;
distribute incentives (economic and symbolic) to the schools. These strategies are:&#13;
(i) the publication of school results, (ii) the dissemination of information to the&#13;
parents, and (iii) the accountability programs. Each of these strategies is&#13;
described in the following paragraphs.&#13;
      Publication of schools results. The publication of school results has been&#13;
mandated by law since 1990 (Government of Chile 1990, 2009, 2011). However,&#13;
the law was not implemented until 1995, when school results were published for&#13;
the first time in a newspaper supplement (since 2001, school results have also&#13;
been available online). The publication includes the school mean scores, as well&#13;
as differences between school means and school mean results from the previous&#13;
assessment, from the national mean, and from schools from the same&#13;
socioeconomic group.5 The publication of school results has a wide impact, with&#13;
&#13;
&#13;
&#13;
&#13;
4&#13;
  Evidence supporting this statement can be found in an experiment comparing the impact of assessment&#13;
information without and without incentives to the schools (see Muralidharan and Sundararaman 2010).&#13;
5&#13;
  Schools are classified in five socioeconomic groups, depending on the student population they serve.&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                                          9&#13;
&amp;#12;     both positive and negative consequences. SIMCE results are on the front pages of&#13;
     the newspapers, and education is on top of the public discussion (figure 3). On&#13;
     the negative side, the information allows for the stigmatization of low&#13;
     performing schools serving the poorest students. In fact, around 80 percent of the&#13;
     variance in school mean scores can be predicted by the socioeconomic status of&#13;
     the student population served by the schools (Mizala, Romaguera, and Urqueola&#13;
     2007).&#13;
&#13;
&#13;
     Figure 3. School Results Published in a Chilean Newspaper&#13;
&#13;
&#13;
&#13;
&#13;
     Source: Diario La Tercera 2011: 11.&#13;
&#13;
&#13;
&#13;
&#13;
          Dissemination of information to parents. Informing parents plays a double&#13;
     function: holding schools accountable and parent involvement. SIMCE has two&#13;
     main mechanisms to inform parents: the parent report and a geo referential&#13;
     system. The parent report informs about school results (the school mean, and&#13;
     differences between the school mean and the national results, the school results&#13;
     from the previous assessment, and from schools from the same socioeconomic&#13;
     group). The report also provides recommendations on how parents can support&#13;
     their childrenâ&#128;&#153;s education at home (figure 4).&#13;
&#13;
&#13;
&#13;
&#13;
10                                                                    MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;Figure 4. Parent Report&#13;
&#13;
&#13;
&#13;
&#13;
Source: SIMCE.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile   11&#13;
&amp;#12;          A low cost and sustainable strategy was used to introduce the parent report.&#13;
     First, the SIMCE Commission built consensus around the importance of&#13;
     disseminating this report. Second, SIMCE used the cheapest mechanism, which&#13;
     was a black and white flyer that could be easily reproduced and distributed to&#13;
     schools. Third, SIMCE distributed a few printed reports to the schools, and asked&#13;
     them to photocopy and distribute the report to parents. In the following years,&#13;
     SIMCE gradually absorbed the costs of making the reports available to all&#13;
     parents. Parents value the information provided, but still have difficulties&#13;
     understanding and using it (Taut et al. 2009).&#13;
          The geo referential system (SIMCEâ&#128;&#153;s Maps) is available online and displays&#13;
     Google maps with schools and their mean scores all over the country (figure 5).&#13;
     This system was launched in 2010, and triggered an immediate and strong&#13;
     debate in education. Initially, the geo referential system displayed the school&#13;
     mean scores together with a green, yellow, or red light (stoplights), depending&#13;
     on if the school mean score was above, at, or below the national mean. After a&#13;
     strong debate that reached the congress, stoplights were eliminated to avoid the&#13;
     stigmatization of low performing schools. It is not known to what extent parents&#13;
     are using the geo referential system.&#13;
&#13;
&#13;
     Figure 5. Geo referential System with School Results&#13;
&#13;
&#13;
&#13;
&#13;
     Source: SIMCE.&#13;
&#13;
&#13;
&#13;
&#13;
12                                                                   MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;      Accountability programs. Chile uses a combination of accountability programs&#13;
to put pressure on and distribute incentive to the schools. The first of these&#13;
programs, the National Performance Assessment System (Sistema Nacional de&#13;
EvaluaciÃ³n de DesempeÃ±oâ&#128;&#148;SNED), was passed into law in 1995. It provides&#13;
monetary incentives to teachers from high performing schools. The second&#13;
program, the Preferential Subsidy (SubvenciÃ³n Escolar Preferencialâ&#128;&#148;SEP), was&#13;
passed into law in 2008. It provides economic incentives and pedagogical&#13;
support to schools serving low income students that reach agreed objectives.&#13;
Finally, the Quality Assurance Law of 2011 (yet to be implemented) will set up a&#13;
stronger regulatory framework, will monitor school results, and will support&#13;
them with technical assistance. The law will also allow for closing schools that do&#13;
not show improvements.&#13;
      The specific mechanisms through which schools are hold accountable are the&#13;
newspaper supplement, the parent report, the geo referential system, the data&#13;
files, and the website (table 1).&#13;
&#13;
Negative Uses of the Assessment&#13;
Beyond the â&#128;&#156;officialâ&#128;? uses of the assessment, there are unintended negative uses&#13;
that are a concern for the assessment program. The SIMCE Commission warned&#13;
against the following: teachers teaching the subject areas covered in the&#13;
assessment only; teachers overusing multiple choice questions in classroom&#13;
assessment; schools focusing resources on the tested grades only; schools&#13;
excluding low performing students from the assessment; the stigmatization of&#13;
low performing schools; and the further segregation of the school system along&#13;
academic performance and socioeconomic level (ComisiÃ³n SIMCE 2003). It is not&#13;
know to what extent these negative uses are affecting the school system in Chile.&#13;
&#13;
&#13;
Drivers for Change&#13;
Several contextual drivers allowed for the development of the SIMCE&#13;
dissemination strategy. These included the political context, legal mandate,&#13;
institutional conditions, leadership, and international influences.&#13;
     The political context provided a strong support for developing the&#13;
assessment. When education became a national priority in the 1990s, SIMCE&#13;
provided a much needed, credible indicator of education quality.&#13;
     The legal mandate to publish school results led to important innovations.&#13;
SIMCE started publishing school results in a newspaper supplement and on its&#13;
website, which boosted the coverage of SIMCE results in the media. SIMCE has&#13;
to classify schools in socioeconomic groups to make school comparisons fairer.&#13;
     Important institutional conditions allowed for strengthening SIMCEâ&#128;&#153;s&#13;
dissemination strategy. First, SIMCE benefited from strong and stable technical&#13;
and political leadership. This leadership was key to setting long term goals.&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                       13&#13;
&amp;#12;     Second, the yearly budget for the assessment increased from US$2.5 million in&#13;
     2001 to US$23 million in 2011.6 This allowed for strengthening the assessment&#13;
     teams and, most notably, for creating in 2005 a unit fully devoted to the analysis&#13;
     and dissemination of assessment information. The provision of a stable budget&#13;
     was a key ingredient for the implementation of the current dissemination&#13;
     strategy. In 2010/11, around 10 percent of the SIMCE budget was spent on&#13;
     dissemination.&#13;
          The leadership provided by a technical political commission allowed&#13;
     planning for future development of the dissemination strategy. Criticism of the&#13;
     government was growing because the reform efforts of the 1990s did not&#13;
     translate into increased test scores. This raised concern about the capacity of&#13;
     SIMCE to detect changes in student performance. In 2003, the Minister of&#13;
     Education asked a technical political commission to review the assessment&#13;
     program. The members of the commission included representatives of the&#13;
     teachers union, parents, school administrators, universities, think tanks, and the&#13;
     Ministry of Education. Over five months, the SIMCE Commission went through&#13;
     a strategic planning process. The commission backed the assessment, and made&#13;
     recommendations for its further development. The recommendations included&#13;
     (i) publishing the parent report, (ii) reporting performance standards, (iii)&#13;
     reporting results to school administrators, (iv) increasing the participation of&#13;
     teachers in the assessment, and (v) providing teachers with greater access to&#13;
     information. These recommendations became the roadmap for SIMCE for the&#13;
     coming years (ComisiÃ³n SIMCE 2003).&#13;
          Finally, international influences also shaped SIMCEâ&#128;&#153;s dissemination&#13;
     strategy. In the decade of the 2000s, there was a push for greater transparency&#13;
     that translated into publishing more and better information about the&#13;
     assessment. A critical step was releasing the SIMCE databases. This allowed for&#13;
     an increase in the number of researchers and policy makers using the assessment&#13;
     to inform decision making and evaluate policies. Another international influence&#13;
     that shaped SIMCEâ&#128;&#153;s dissemination strategy was the accountability movement.&#13;
     This boosted the development of incentive schemes based on SIMCE results.&#13;
&#13;
&#13;
&#13;
     Impact of the Assessment Program&#13;
     Has the Chilean assessment program contributed to education quality through&#13;
     improved student learning? While this is the ultimate criteria with which the&#13;
     effectiveness of an assessment program should be judged, this is a very hard&#13;
     question to answer. Assessment programs operate in combination with other&#13;
     policies, and therefore it is not possible to disentangle their unique contributions&#13;
     to improved education. Their effectiveness is conditioned not only by their&#13;
     technical quality, but also by external factors such as teachersâ&#128;&#153; capacity to&#13;
&#13;
     6&#13;
         Data based on Chileâ&#128;&#153;s national budget (http://www.dipres.gob.cl).&#13;
&#13;
&#13;
&#13;
14                                                                           MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;analyze results, set learning goals, and teach their students in order to reach&#13;
those goals.&#13;
     Despite these limitations, there is some evidence that supports the&#13;
contribution of SIMCE to improved student performance. Chileâ&#128;&#153;s gains in&#13;
student performance in the last decade are documented both by SIMCE and&#13;
PISA. These gains seem to be, at least in part, the consequence of stable and&#13;
effective policies. Since these policies have been directly informed by SIMCE,&#13;
therefore it is possible to argue that SIMCE has had an indirect effect on student&#13;
performance. This rationale is backed by the high value ministers of education&#13;
and policy makers give to the SIMCE information. This rationale is also backed&#13;
by the McKinsey report (2010), which showed that the most improved school&#13;
systems (including Chileâ&#128;&#153;s system) systematically use assessment information to&#13;
inform policy.&#13;
     Nevertheless, at the school level, SIMCE information seems to be underused.&#13;
While educators value the SIMCE information, they have difficulties&#13;
understanding and using it with pedagogical purposes (Taut et al. 2009).&#13;
Nevertheless, schools report making important decisions based on the&#13;
assessment results, including decisions such as implementing remedial courses,&#13;
focusing instruction on topics covered by SIMCE, and assigning the best teachers&#13;
to the â&#128;&#156;SIMCE grades.â&#128;?&#13;
     Regarding the use of SIMCE for accountability purposes, parents do not&#13;
seem to use assessment information to â&#128;&#156;shop for schools.â&#128;? While parents declare&#13;
choosing schools based on quality, most do not use SIMCE results to inform their&#13;
decisions. School demographics have more weight than SIMCE when choosing a&#13;
school. This makes sense, considering the difficulties parents have had in&#13;
accessing and understanding SIMCE results (Elacqua, Schneider, and Buckley&#13;
2006; Taut et al. 2009). It is not known to what extent SIMCE information&#13;
promotes parent involvement in school.&#13;
     So far, only the oldest accountability program, SNED, has been subjected to&#13;
impact evaluation. Research shows that SNED had small but significant effects&#13;
on student performance, ranging from 0.1 to 0.2 standard deviation, but that it&#13;
has not affected demand side indicators like increased student enrollment.&#13;
However, SNED seems to be a very cost effective program when compared to&#13;
other reforms (Cabezas, Cuesta, and Gallego 2011; Gallego 2008; Rau and&#13;
Contreras 2008; Mizala and Urquiola 2007). No studies were found about the&#13;
impact of SNED on teacher motivation and pedagogical practices.&#13;
&#13;
&#13;
Lessons Learned&#13;
Countries aiming to strengthen the uses of their national large scale assessment&#13;
program may extract some important lessons from this case study. Chile&#13;
systematically uses assessment information to inform policies, to distribute&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                      15&#13;
&amp;#12;     incentives to the schools, and to support pedagogy. The McKinsey report (2010)&#13;
     points to the systematic use of assessment information as a key feature of the&#13;
     most improved school systems, including Chileâ&#128;&#153;s system.&#13;
          Several drivers allowed for the systematic use of assessment information in&#13;
     Chile. Probably the most important drivers were the political pressure to&#13;
     improve education quality, and the need to have a valid, fair, and credible&#13;
     indicator of quality. The legal support of the assessment pushed for a strong&#13;
     dissemination strategy, including the publication of school results. The SIMCE&#13;
     Commission built consensus around the purposes and mechanisms of the&#13;
     assessments, and pushed for providing more and better information to teachers&#13;
     and parents. Finally, the injection of additional resources to the assessment office&#13;
     was a necessary condition to improve SIMCEâ&#128;&#153;s dissemination strategy.&#13;
          Countries aiming to improve their assessment systems can draw important&#13;
     lessons from Chileâ&#128;&#153;s use of assessment information. These lessons are grouped&#13;
     into those that refer to the dissemination strategy and those that refer to the&#13;
     conditions for using the assessment information.&#13;
&#13;
     Lessons Regarding the Dissemination Strategy&#13;
     Having a clear vision. Countries need to have a clear vision about assessment. This&#13;
     requires agreeing upon the purposes of the assessment, the target audiences to&#13;
     be reached, the messages to be delivered and the uses to be promoted. Strong&#13;
     technical and political leadership need to converge for this vision to take shape.&#13;
     In Chile, this vision came first from the leadership of key officials from the&#13;
     Ministry of Education. Later, it came from the consensus reached by the SIMCE&#13;
     Commission. The report elaborated by this commission became the roadmap for&#13;
     the strategic development of the assessment program.&#13;
          Building consensus. This is important to ensure the political viability of the&#13;
     assessment program. Stakeholders need to agree on a vision for the assessment.&#13;
     That is, they need to reach consensus regarding the purposes, audiences, and&#13;
     uses of the assessment. In Chile, this consensus was reached through a high level&#13;
     technical political commission whose members included all stakeholders. Thanks&#13;
     to a strategic planning process, this commission and its report allowed for&#13;
     strengthening the legitimacy of the assessment, and for identifying and&#13;
     prioritizing strategic goals. The commission agreed on the importance of&#13;
     strengthening the dissemination of information to parents and school&#13;
     administrators.&#13;
          Strengthening the dissemination strategy. The dissemination strategy should be&#13;
     the â&#128;&#156;leading horseâ&#128;? that orients all the assessment activities. The starting&#13;
     question should always be â&#128;&#156;What information do we want to put out there?â&#128;?&#13;
     Based on the response to this question, decisions have to be made regarding&#13;
     what to measure, who to measure, and how to measure. All the assessment&#13;
     activities should be planned in order to provide the required information to be&#13;
     disseminated, no more and no less. The dissemination strategy should clearly&#13;
&#13;
&#13;
&#13;
16                                                                      MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;identify the purposes and intended use of the assessment information, the target&#13;
audience, and the dissemination mechanism.&#13;
      Countries usually make the mistake of collecting much more data than they&#13;
are able to communicate. Chile was not an exception. For years, SIMCE collected&#13;
background information through questionnaires, but this information was not&#13;
published. This was expensive and inefficient. Another common mistake is that&#13;
countries run out of money before publishing the results. Thanks to good&#13;
planning, this was never the case in Chile.&#13;
      Implementing gradual changes. Countries should not attempt to develop in&#13;
two years a dissemination strategy that took other countries decades to develop.&#13;
Implementing a comprehensive dissemination strategy takes years, even&#13;
decades. The dissemination strategy should be implemented gradually, should&#13;
move from simple to complex, and should be built so that the first steps serve as&#13;
a foundation for the following ones. Gradualism should go hand in hand with&#13;
the capacity of the assessment office to implement changes. It should also go&#13;
hand in hand with the country capacity to â&#128;&#156;digestâ&#128;? assessment information.&#13;
      Whereas nowadays Chile has a comprehensive dissemination strategy, it is&#13;
important to note that at the beginning the strategy only included a school report&#13;
and assessment guidelines for teachers. New dissemination mechanisms had&#13;
been introduced gradually. These changes responded to new political priorities&#13;
(for example, involving parents), and changes in technology (such as the&#13;
Internet), among others. They also responded to changes in assessment&#13;
techniques. For instance, in the 1980s SIMCE reported student results as the&#13;
percentage of correct responses only; in the late 1990s, it started reporting&#13;
comparable scores using an Item Response Theory (IRT) scale; and in the 2000s it&#13;
added the percentage of students that reached different performance standards&#13;
to its reports.&#13;
      Ensuring sustainable changes. Countries should be cautioned against&#13;
launching reports that are not sustainable in time, and against experimenting&#13;
with different types of reports in each assessment cycle. These actions create&#13;
frustration and confusion. Once a report is published, stakeholders expect it to&#13;
come on a regular base. Before introducing a modification in the dissemination&#13;
strategy, the assessment office should make sure that the changes are sustainable&#13;
in time. Many times, this means looking for the simplest and most cost effective&#13;
solution. In Chile, a good example of a sustainable change was the introduction&#13;
of SIMCEâ&#128;&#153;s parent report. This is a one page black and white flyer that can easily&#13;
be photocopied.&#13;
      Moving from lower to higher stakes. When a new assessment program is&#13;
introduced, it is important to ensure its legitimacy. This requires that&#13;
stakeholders, especially educators, perceive the assessment results as valid, fair,&#13;
and useful for improving education quality. If educators perceive the results as a&#13;
threat, or if they do not trust them, then the assessment will not contribute to&#13;
improving quality. Attaching consequences to an assessment program when it is&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                       17&#13;
&amp;#12;     first launched is not good for building trust. Stakeholders need first to know the&#13;
     program in a â&#128;&#156;protected setting,â&#128;? without the pressure of incentives. Once the&#13;
     program is recognized as an important piece of the school system, then it is a&#13;
     more appropriate time for introducing incentives. When introduced, incentives&#13;
     should be balanced with other uses of information (for example, an assessment&#13;
     component without consequences for the school).&#13;
           In Chile, SIMCE gradually attached higher stakes to the assessment results.&#13;
     In the 1980s, results were distributed to the schools only, without consequences.&#13;
     In the mid 1990s, school results were published, and in the late 1990s and 2000s,&#13;
     accountability programs with higher stakes for teachers and schools were&#13;
     introduced.&#13;
           Introducing comprehensive accountability programs. School and teacher quality&#13;
     are complex concepts and no single indicator can fully capture this complexity. If&#13;
     an accountability program were to rely on student assessment results only, other&#13;
     important aspects of quality would not be considered when distributing&#13;
     incentives. This would contribute to a perception of unfairness and lack of&#13;
     legitimacy of the accountability program. Therefore, countries aiming to&#13;
     distribute incentives to schools should avoid relying on a single indicator (such&#13;
     as mean test scores) for doing so. Multiple indicators that cover different facets of&#13;
     quality are preferable (for example, dropout rates, gain scores, and meeting&#13;
     yearly goals).&#13;
           Different accountability programs have been gradually being introduced in&#13;
     Chile. In all of them, student scores are the main indicator. Other indicators&#13;
     include school repetition rates, school policies, and administration.&#13;
&#13;
     Lessons Regarding the Conditions for Using the Assessment Information&#13;
     Building an assessment culture. This means having a workforce that is assessment&#13;
     literate, with educators that can value, understand, and use assessment&#13;
     information to improve education. If educators have a prejudice against the&#13;
     assessment, they will ignore it. If they have difficulties understanding&#13;
     assessment results, they will never use the information to improve pedagogy.&#13;
          The assessment program has to make all possible efforts to provide&#13;
     educators with opportunities to learn about the assessment. This can be done in&#13;
     several ways. First, expose educators to several assessment experiences. Second,&#13;
     involve educators in the assessment, for instance by providing teachers with tests&#13;
     to administer to their own students, and scoring criteria and guidelines with&#13;
     which to analyze and use assessment results. Finally, build bridges between the&#13;
     assessment program and pre and in service teacher training programs.&#13;
          After more than two decades of assessments results, Chilean schools still&#13;
     have a poor assessment culture and too many educators are not assessment&#13;
     literate. This is in part the consequence of teachers having little opportunity to&#13;
     learn about SIMCE. This is a weakness that other countries aiming to develop&#13;
     their assessment program should try to avoid.&#13;
&#13;
&#13;
&#13;
18                                                                       MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;      Creating the right institutional conditions. Disseminating assessment&#13;
information is a necessary but not sufficient condition for the information to be&#13;
used. The right institutional conditions need to be in place for the information to&#13;
be used. Chile has been gradually introducing institutional conditions for the&#13;
schools to use the assessment results. For example, schools organize meetings&#13;
with parents to distribute and discuss the parent reports, and they also organize&#13;
workshops to analyze SIMCE results. In addition, schools receive monetary&#13;
incentives based on their assessment results. Countries aiming to ensure the&#13;
effective use of assessment information should plan for these or other conditions.&#13;
      Ensuring that assessment results are valued and are perceived as fair, valid, and&#13;
useful. The ultimate goal of the assessment is to contribute to improve education&#13;
quality. For this to happen, stakeholders should value the assessment, and&#13;
perceive the data it provides as fair, valid, and useful. Results are more likely to&#13;
be perceived as fair if the socioeconomic status of the students served by the&#13;
schools is recognized. Results are more likely to be perceived as valid if teachers&#13;
can see links between the curriculum and the assessment. Results are more likely&#13;
to be perceived as useful if teachers can understand them, can analyze student&#13;
responses, and can plan pedagogy accordingly.&#13;
      In Chile, fairness in results was threatened in 2010 when a stoplight system&#13;
was introduced to report school results. Stoplights were strongly criticized&#13;
because they did not recognize the socioeconomic status of the students served&#13;
by the schools. This was perceived as unfair because socioeconomic status was a&#13;
strong predictor of the school results (for instance, poorer schools got red lights,&#13;
richer schools got green lights). After a strong debate, SIMCE dropped the&#13;
stoplights.&#13;
      To contribute to the validity of the assessment program, SIMCE has been&#13;
publishing assessment guidelines since the 1980s. These guidelines present the&#13;
assessment framework of the tests, and explain the links between the framework&#13;
and the curriculum.&#13;
      Regarding the utility of the assessment, this is an area that still needs to be&#13;
strengthened in Chile. While teachers value the SIMCE information, they have&#13;
difficulties understanding and using it. To address this issue, SIMCE introduced&#13;
workshops to train teachers in the analysis of assessment results.&#13;
      Monitoring the consequences of the assessment. It is not enough just to&#13;
disseminate information; the assessment program needs to make sure that&#13;
information is used in the right way, while avoiding negative uses. Yearly&#13;
interviews and surveys are important for determining that stakeholders are&#13;
getting the assessment information, they value it, and they understand and use&#13;
it. SIMCE has not yet systematically incorporated this feature into its design.&#13;
      Countries aiming to improve the dissemination, use, and impact of their&#13;
assessment programs should critically review these lessons. Their utility will&#13;
depend on the countriesâ&#128;&#153; capacity to select and adapt these lessons according to&#13;
their cultural background, assessment development, and resources, among&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                           19&#13;
&amp;#12;     others. Ultimately, the contribution an assessment program can make to&#13;
     improving education quality will depend on the effectiveness of its&#13;
     dissemination strategy.&#13;
&#13;
&#13;
&#13;
&#13;
20                                                           MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;References&#13;
Cabezas, V., J. I. Cuesta, and F. Gallego. 2011. â&#128;&#156;Effects of Short Term Tutoring on&#13;
    Cognitive and Non Cognitive Skills: Evidence from a Randomized&#13;
     Evaluation in Chile.â&#128;? Unpublished manuscript. Instituto de EconomÃ­a, P.&#13;
     Universidad CatÃ³lica de Chile.&#13;
Clarke, Marguerite. 2012. â&#128;&#156;What Matters Most for Student Assessment Systems:&#13;
     A Framework Paper.â&#128;? SABERâ&#128;&#147;Student Assessment Working Paper No. 1.&#13;
     World Bank, Washington, DC.&#13;
ComisiÃ³n para el Desarrollo y Uso del Sistema de MediciÃ³n de la Calidad de la&#13;
    EducaciÃ³n (ComisiÃ³n SIMCE). 2003. EvaluaciÃ³n de Aprendizajes para una&#13;
    EducaciÃ³n de Calidad. Santiago, Chile: Ministerio de EducaciÃ³n.&#13;
Diario La Tercera. 2011. â&#128;&#156;School Results.â&#128;? April 7, p. 11.&#13;
Elacqua, G., M. Schneider, and J. Buckley. 2006. â&#128;&#156;School Choice in Chile: Is it&#13;
     Class or the Classroom?â&#128;? Journal of Policy Analysis and Management 25(3):&#13;
     577â&#128;&#147;601.&#13;
Gallego, F. 2008. â&#128;&#156;Efectos del SNED en resultados del proceso educativo.â&#128;?&#13;
     Unpublished manuscript. Instituto de EconomÃ­a, P. Universidad CatÃ³lica&#13;
     de Chile.&#13;
Government of Chile. 1990 Constitutional Law of Education (Ley OrgÃ¡nica&#13;
    Constitucional de EducaciÃ³n). Santiago.&#13;
â&#128;&#148;â&#128;&#148;â&#128;&#148;. 2009 General Law of Education (Ley General de EducaciÃ³nâ&#128;&#148;LGE).&#13;
  Santiago, Chile.&#13;
â&#128;&#148;â&#128;&#148;â&#128;&#148;. 2011 Quality Assurance Law (Sistema Nacional de Aseguramiento de la&#13;
  Calidad de la EducaciÃ³n Parvularia, BÃ¡sica y Media y su fiscalizaciÃ³n). Santiago,&#13;
  Chile.&#13;
Himmel, E. 1996. â&#128;&#156;National Assessment in Chile.â&#128;? In P. Murphy, V. Greaney, M.&#13;
    Lockheed, and C. Rojas, National Assessments: Testing the System.&#13;
    Washington, DC: World Bank.&#13;
Majluf, N. 1987. The National Assessment of Education in Chile. Operational Research.&#13;
     Dept. IngenierÃ­a de Sistemas, Escuela de IngenierÃ­a, Pontificia Univ.&#13;
     CatÃ³lica de Chile, Santiago, Chile.&#13;
McKinsey &amp; Co. 2010. How the Worldâ&#128;&#153;s Most Improved School Systems Keep Getting&#13;
    Better. London: McKinsey &amp; Co.&#13;
Mizala, A., and M. Urquiola. 2007. â&#128;&#156;School Markets: The Impact of Information&#13;
     Approximating Schoolsâ&#128;&#153; Effectiveness.â&#128;? Working Paper 13676. National&#13;
     Bureau of Economic Research, Cambridge, MA.&#13;
&#13;
&#13;
&#13;
&#13;
Disseminating and Using Student Assessment Information in Chile                         21&#13;
&amp;#12;     Mizala, A., P. Romaguera, and M. Urqueola. 2007. â&#128;&#156;Socioeconomic Status or&#13;
          Noise? Tradeoffs in the Generation of School Quality Information.â&#128;? Journal&#13;
          of Development Economics 84: 61â&#128;&#147;75.&#13;
     Muralidharan, K., and V. Sundararaman. 2010. â&#128;&#156;The Impact of Diagnostic&#13;
         Feedback to Teachers on Student Learning: Experimental Evidence from&#13;
         India.â&#128;? The Economic Journal 120 (August): F187â&#128;&#147;F203.&#13;
     Organisation for Economic Co operation and Development (OECD) n.d.&#13;
         Education at a Glance. Paris: OECD.&#13;
     Rau, T., and D. Contreras. 2008. â&#128;&#156;Tournaments, Gift Exchanges and the Effect of&#13;
          Monetary Incentive for Teachers: The Case of Chile.â&#128;? Unpublished&#13;
          manuscript. Departamento de EconomÃ­a, Universidad de Chile.&#13;
     Sistema de MediciÃ³n de la Calidad de la EducaciÃ³n (SIMCE). 2010. National&#13;
          Report. Chile: SIMCE.&#13;
     Taut, S., F. Cortes, C. Sebastian, and D. Preiss. 2009. â&#128;&#156;Evaluating School and&#13;
          Parent Reports of the National Student Achievement Testing System&#13;
          (SIMCE) in Chile: Access, Comprehension, Use.â&#128;? Evaluation and Program&#13;
          Planning 32: 129â&#128;&#147;137.&#13;
     United Nations Development Program (UNDP). n.d. Human Development Report.&#13;
          New York: UNDP. Available at: http://hdr.undp.org/en/.&#13;
&#13;
     Websites&#13;
     The Central Bank of Chile (www.bcentral.cl)&#13;
     Ministry of Social Development, Chile (www.ministeriodesarrollosocial.gob.cl)&#13;
     PISA program (http://www.pisa.oecd.org)&#13;
     SIMCE, Chileâ&#128;&#153;s national assessment program (www.simce.cl)&#13;
     United Nations Development Program (http://hdr.undp.org/en/statistics)&#13;
     World Bank (www.worldbank.org)&#13;
&#13;
&#13;
&#13;
&#13;
22                                                                  MarÃ­a JosÃ© RamÃ­rez&#13;
&amp;#12;&amp;#12;&amp;#12;&amp;#12;Student assessment plays a key role in improving education. However,&#13;
many countries do not disseminate and make effective use of their student&#13;
assessment information. This paper discusses Chileâ&#128;&#153;s effective use of its&#13;
assessment information and draws lessons for other countries. A key lesson&#13;
from the Chilean experience is that effective use of assessment information&#13;
is a challenging task that takes time, effort, and resources. Another lesson&#13;
is that the task requires leadership, long-term planning, and consensus&#13;
building. Countries able to learn from Chileâ&#128;&#153;s lessons will be in a better&#13;
position to make effective use of their student assessments and, ultimately,&#13;
to contribute to education quality and learning.&#13;
&#13;
MarÃ­a-JosÃ© RamÃ­rez, Education Specialist, Human Development&#13;
Network, the World Bank&#13;
&#13;
&#13;
&#13;
&#13;
The Russia Education Aid for Development Trust Fund is a collaboration between the Russian Federation&#13;
and the World Bank that supports the improvement of student learning outcomes in low-income countries&#13;
through the development of robust student assessment systems. Visit the READ website at&#13;
www.worldbank.org/readtf for additional information.&#13;
&amp;#12;</ml:original-txt><ml:search-metadata><doc id="16238811">
        <url>
            http://documents.worldbank.org/curated/en/2012/01/16238811/disseminating-using-student-assessment-information-chile
        </url>
        <availablein>Russian,English</availablein>
        <fullavailablein>
            <available_in lang="Russian" entityid="000442464_20130312114701" node_id="16238811"/>
        </fullavailablein>
        <url_friendly_title>http://documents.worldbank.org/curated/en/2012/01/16238811/disseminating-using-student-assessment-information-chile</url_friendly_title>
        <new_url>2012/01/16238811/disseminating-using-student-assessment-information-chile</new_url>
        <disclosure_date>2012-04-23T00:00:00Z</disclosure_date>
        <disclosure_type>NA</disclosure_type>
        <ext_pub_date>2012-04-23T00:00:00Z</ext_pub_date>
        <disclstat>Disclosed</disclstat>
        <txturl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2012/04/24/000333038_20120424014532/Rendered/INDEX/682360WP00PUBL0WP30READ0web04006012.txt</txturl>
        <pdfurl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2012/04/24/000333038_20120424014532/Rendered/PDF/682360WP00PUBL0WP30READ0web04006012.pdf</pdfurl>
        <docdt>2012-04-01T00:00:00Z</docdt>
        <datestored>2012-04-24T00:00:00Z</datestored>
        <totvolnb>1</totvolnb>
        <versiontyp>Final</versiontyp>
        <versiontyp_key>1309935</versiontyp_key>
        <volnb>1</volnb>
        <repnme>
            Disseminating and using student assessment
            information in Chile
        </repnme>
        <abstracts>
            Student assessment plays a key role in
            improving education.  However, many countries do not
            disseminate and make effective use of their student
            assessment information. This paper discusses Chile's
            effective use of its assessment information and draws
            lessons for other countries. A key lesson from the Chilean
            experience  is  that  effective  use  of  assessment
            information  is  a  challenging  task  that  takes  time,
            effort,  and  resources.  Another lesson is that the task
            requires leadership, long term planning, and consensus
            building. Countries able to learn  from  Chile's
            lessons  will  be  in  a  better  position  to  make
            effective  use  of  their  student  assessments  and,
            ultimately,  to  contribute  to  education  quality  and  learning.
        </abstracts>
        <docna>
            Disseminating and using student assessment
            information in Chile
        </docna>
        <display_title>Disseminating and using student
            assessment information in Chile</display_title>
        <listing_relative_url>/research/2012/04/16238811/disseminating-using-student-assessment-information-chile</listing_relative_url>
        <subtopic>Secondary Education,Teaching and Learning,Primary Education,Education For All,Tertiary Education</subtopic>
        <docty>Working Paper (Numbered Series)</docty>
        <teratopic>Education</teratopic>
        <count>Chile</count>
        <authors>
            <author>Ramirez, Maria Jose</author>
        </authors>
        <geo_region_mdks>
            <geo_region_mdk>World!$!80475</geo_region_mdk>
            <geo_region_mdk>America!$!80450</geo_region_mdk>
            <geo_region_mdk>South America!$!80469</geo_region_mdk>
        </geo_region_mdks>
        <entityids>
            <entityid>000333038_20120424014532</entityid>
        </entityids>
        <admreg>Latin America &amp; Caribbean,Latin America &amp; Caribbean</admreg>
        <colti>Systems Approach for Better Education
            Results (SABER) student assessment working paper ; no. 3</colti>
        <lang>English</lang>
        <historic_topic>Education</historic_topic>
        <majdocty>Publications &amp; Research</majdocty>
        <keywd>
            academic evaluation, academic performance,
            access to information, accreditation, Assessment framework,
            Assessment guidelines, Assessment of Education, assessment
            system, assessment teams, assessment techniques, classroom,
            classrooms, Cognitive Skills, comparative education,
            computer skills, curriculum, decision making, dissertation,
            dropout rates, economic development, economic growth,
            Education Aid, education community, education quality,
            education reform, Education Sector, education system,
            education systems, Educational Achievement, educational
            assessment, educational assessments, educational policies,
            educational quality, educational research, educators,
            expenditures, global knowledge, gross enrollment, gross
            enrollment rate, higher student learning, higher test
            scores, Human Development, in service teacher training,
            instruction, International Student Assessment, Investment in
            education, leadership, learning, learning goals, learning
            outcomes, mathematics, ministers of education, Ministry of
            Education, national assessment, National Assessments,
            national curriculum, natural sciences, number of students,
            papers, parent involvement, participation of teachers,
            pedagogical decisions, pedagogical practices, pedagogical
            support, pedagogy, physical education, primary education,
            Principals, private schools, quality assurance, quality of
            education, Reading, repetition, repetition rates,
            researchers, school administrators, school level, school
            policies, school quality, school supervisors, school system,
            school systems, school year, schools, secondary education,
            Social Development, special needs, Student achievement,
            STUDENT ASSESSMENT, student assessment systems, student
            assessments, student attendance, student enrollment, student
            learning, student learning outcomes, student performance,
            student population, student scores, subject areas, teacher,
            teacher motivation, teacher quality, teacher training,
            teacher training institutions, teacher training programs,
            Teachers, teaching, technical assistance, Test
            administration, training programs, Tutoring, universities,
            university level, university professors
        </keywd>
        <owner>Education Team (HDNED)</owner>
        <geo_regions>
            <geo_region>World</geo_region>
            <geo_region>America</geo_region>
            <geo_region>South America</geo_region>
        </geo_regions>
        <repnb>68236</repnb>
    </doc></ml:search-metadata><ml:annotations><ml:concepts><ml:concept>Finance and Development</ml:concept><ml:concept>Finance and Financial Sector Development</ml:concept><ml:concept>Economic Management</ml:concept><ml:concept>Macroeconomic Management</ml:concept><ml:concept>Macroeconomic Policy</ml:concept><ml:concept>Macroeconomics Policy</ml:concept><ml:concept>Macroeconomics and Economic Growth</ml:concept><ml:concept>Macroeconomics and Growth</ml:concept><ml:concept>Teaching and Learning</ml:concept><ml:concept>Poverty Reduction</ml:concept><ml:concept>Poverty Reduction and Distributional Analysis</ml:concept><ml:concept>Poverty Reduction and Equity</ml:concept><ml:concept>Poverty and Inequality</ml:concept><ml:concept>General Public Administration Sector</ml:concept><ml:concept>Governance and Public Sector Management</ml:concept><ml:concept>Government</ml:concept><ml:concept>Institutions</ml:concept><ml:concept>Public Administration</ml:concept><ml:concept>Public Sector Development</ml:concept><ml:concept>Public Sector Management and Reform</ml:concept><ml:concept>Public Sector and Governance</ml:concept><ml:concept>Social Protections and Labor</ml:concept><ml:concept>Financial Sector Development</ml:concept><ml:concept>Private Sector Development</ml:concept><ml:concept>Arts and Culture</ml:concept><ml:concept>Macroeconomic and Structural Policies</ml:concept><ml:concept>Education</ml:concept><ml:concept>Economic Growth</ml:concept><ml:concept>Health, Nutrition and Population</ml:concept><ml:concept>Poverty</ml:concept><ml:concept>Public Sector Management</ml:concept><ml:concept>Social Protection and Labor</ml:concept><ml:concept>Central Banks</ml:concept><ml:concept>Central Banking</ml:concept><ml:concept>Nutritional supplements</ml:concept><ml:concept>Vitamins</ml:concept><ml:concept>Private Investment in Education</ml:concept><ml:concept>Private Provision of Education</ml:concept><ml:concept>Private Provision of Education Services</ml:concept><ml:concept>Private School</ml:concept><ml:concept>Education Reform and Management</ml:concept><ml:concept>Teacher Professional Development</ml:concept><ml:concept>Basic Education</ml:concept><ml:concept>Education Quality</ml:concept><ml:concept>Quality and Education</ml:concept><ml:concept>Demographics</ml:concept><ml:concept>Analysis &amp; Monitoring</ml:concept><ml:concept>Delivery Units</ml:concept><ml:concept>Grievance Redress</ml:concept><ml:concept>Indicators</ml:concept><ml:concept>M&amp;E</ml:concept><ml:concept>Performance Measurement</ml:concept><ml:concept>Performance Reviews</ml:concept><ml:concept>Rapid Results Approaches</ml:concept><ml:concept>Economic Development</ml:concept><ml:concept>Income</ml:concept><ml:concept>Banking</ml:concept><ml:concept>Media</ml:concept><ml:concept>Boundaries</ml:concept><ml:concept>Copyright</ml:concept><ml:concept>Central Banking Institutional Set-up</ml:concept><ml:concept>Supplements</ml:concept><ml:concept>Private Education</ml:concept><ml:concept>Education Reform</ml:concept><ml:concept>Teacher Training</ml:concept><ml:concept>Scholarships</ml:concept><ml:concept>Subsidies</ml:concept><ml:concept>Primary Education</ml:concept><ml:concept>Secondary Education</ml:concept><ml:concept>Quality of Education</ml:concept><ml:concept>Population</ml:concept><ml:concept>Monitoring and Evaluation</ml:concept></ml:concepts><ml:geo-regions><ml:geo-region>Americas</ml:geo-region><ml:geo-region>Caribbean</ml:geo-region><ml:geo-region>Chile</ml:geo-region></ml:geo-regions></ml:annotations></ml:doc-envelope>