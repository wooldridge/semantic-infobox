<?xml version="1.0" encoding="UTF-8"?><ml:doc-envelope xmlns:ml="http://marklogic.com/poolparty/worldbank"><ml:original-txt>                                     102967&#13;
&#13;
&#13;
world development report&#13;
&#13;
&#13;
            BACKGROUND PAPER&#13;
&#13;
            Digital Dividends&#13;
&#13;
            When Does ICT-Enabled Citizen&#13;
            Voice Lead to Government&#13;
            Responsiveness?&#13;
&#13;
            Tiago Peixoto&#13;
            World Bank Group&#13;
&#13;
            Jonathan Fox&#13;
            American University&#13;
&amp;#12;&amp;#12;                  2016 World Development Report&#13;
                                             Digital Dividends&#13;
                                           www.worldbank.org/wdr2016&#13;
&#13;
&#13;
&#13;
&#13;
                                       BACKGROUND PAPER&#13;
&#13;
  When Does ICT-Enabled Citizen Voice&#13;
  Lead to Government Responsiveness?*&#13;
&#13;
&#13;
                                     Tiago Peixoto, World Bank&#13;
                                  Jonathan Fox, American University&#13;
&#13;
                                                   JANUARY 2016&#13;
&#13;
&#13;
&#13;
&#13;
                                          IN COLLABORATION WITH&#13;
&#13;
&#13;
&#13;
&#13;
                                    Evaluation Team | DEET&#13;
&#13;
&#13;
&#13;
 We are thankful to Sanna Ojanpera who provided research assistance on case description. Thanks also to Brandon Brockmyer,&#13;
 Susan Crawford, Duncan Edwards, Archon Fung, Brendan Halloran, Zahid Hasnain, Renee Ho, Anna Levy, Rosemary McGee,&#13;
and Dennis Whittle, for valuable comments and insights, and to Claudio Mendonca for support with graphic design. An abridged&#13;
            version of this paper is also published in the January 2016 issue (Vol. 47, number 1) of the IDS Bulletin.&#13;
&amp;#12;                                                                     2016 World Development Report Background Paper&#13;
&#13;
&#13;
Abstract&#13;
This paper reviews evidence on the use of 23 information and communication technology (ICT) platforms&#13;
to project citizen voice to improve public service delivery. This meta-analysis focuses on empirical studies&#13;
of initiatives in the global South, highlighting both citizen uptake (â&#128;&#152;yelpâ&#128;&#153;) and the degree to which public&#13;
service providers respond to expressions of citizen voice (â&#128;&#152;teethâ&#128;&#153;). The conceptual framework further distin-&#13;
guishes between two trajectories for ICT-enabled citizen voice: Upwards accountability occurs when users&#13;
provide feedback directly to decision-makers in real time, allowing policy-makers and program managers&#13;
to identify and address service delivery problems â&#128;&#147; but at their discretion. Downwards accountability, in&#13;
contrast, occurs either through real time user feedback or less immediate forms of collective civic action&#13;
that publicly call on service providers to become more accountable and depends less exclusively on deci-&#13;
sion-makersâ&#128;&#153; discretion about whether or not to act on the information provided. This distinction between&#13;
the ways in which ICT platforms mediate the relationship between citizens and service providers allows for&#13;
a precise analytical focus on how different dimensions of such platforms contribute to public sector respon-&#13;
siveness. These cases suggest that while ICT platforms have been relevant in increasing policymakersâ&#128;&#153;&#13;
and senior managersâ&#128;&#153; capacity to respond, most of them have yet to inï¬&#130;uence their willingness to do so.&#13;
&#13;
&#13;
&#13;
Introduction&#13;
Around the world, civil society organisations (CSOs) and governments are experimenting with information&#13;
communication technology (ICT) platforms that try to encourage and project citizen voice, with the goal of&#13;
improving public service delivery. This meta-analysis focuses on empirical studies of initiatives in the global&#13;
South, highlighting both citizen uptake (â&#128;&#152;yelpâ&#128;&#153;) and the degree to which public service providers respond to&#13;
expressions of citizen voice (â&#128;&#152;teethâ&#128;&#153;). The conceptual framework is informed by the key distinction between&#13;
two distinct genres of ICT-enabled citizen voice â&#128;&#147; aggregated individual assessments of service provision&#13;
and collective civic action. The ï¬&#129;rst approach constitutes user feedback, providing precise information&#13;
in real time to decisionmakers. This allows policymakers and programme managers to identify and ad-&#13;
dress service delivery problems â&#128;&#147; but at their discretion. Collective civic action, in contrast, can encourage&#13;
service providers to become more publicly accountable â&#128;&#147; an approach that depends less exclusively on&#13;
decisionmakersâ&#128;&#153; discretion about whether or not to act on the information embodied in feedback. This con-&#13;
ceptual distinction between two different ways in which ICT platforms mediate the citizenâ&#128;&#147;service provider&#13;
relationship allows for a more precise analytical focus on how different dimensions of these ICT platforms&#13;
contribute to public sector responsiveness.&#13;
&#13;
This study begins with a conceptual framework intended to clarify the different links in the causal chain in&#13;
between ICT-enabled opportunities to express voice (platforms) and institutional responses. In other words,&#13;
how and why are these platforms supposed to leverage responses from service providers? The answers turn&#13;
out not to be so obvious. Our approach was informed by a close review of the available evidence, primarily&#13;
quantitative, about experiences with 23 ICT platforms in 17 countries1. This focus on unpacking causal chains&#13;
is informed by two factors. First, the broader literature on the drivers of accountability increasingly emphasis-&#13;
&#13;
1 This also included an international platform, Change.Org. The data analysis in that case referred to a total of 132 countries&#13;
  (World Bank 2014b).&#13;
&#13;
                     EVALUATION TEAM | DEET                                                                                       2&#13;
&amp;#12;                                                               2016 World Development Report Background Paper&#13;
&#13;
&#13;
es using causal chains to address the analytical puzzle of how to distinguish how and why citizen action may&#13;
or may not lead to public sector response (Fox 2014; Grandvoinnet et al. 2015; Joshi 2014; Peixoto 2013).&#13;
Second, analysis revealed that we do not see a generic type of platform leading to a generic type of response.&#13;
Instead, we see key differences in the institutional (not technological) design of the interface that may be&#13;
relevant for voice, citizen action and institutional response. The evidence so far indicates that most of the ICT&#13;
platforms that manage to leverage responsiveness somehow directly involve government.&#13;
&#13;
While ICT-enabled voice platforms vary widely across many dimensions, this analysis emphasises several&#13;
differences that are hypothesised to inï¬&#130;uence both citizen uptake and institutional response. These include&#13;
the degree of public access to information about the expression of voice â&#128;&#147; does the public see what the pub-&#13;
lic says? Does the ICT platform document and disclose how the public sector responds? They also include&#13;
institutional mechanisms for public sector response â&#128;&#147; do the agencies or organisations take speciï¬&#129;c ofï¬&#130;ine&#13;
actions to prompt service providersâ&#128;&#153; response? As a ï¬&#129;rst step towards homing in on these variables, this&#13;
paper maps the 23 platforms studied in terms of various empirical indicators of these distinct dynamics. This&#13;
exercise is followed by a discussion of propositions that may or may not link voice to institutional response.&#13;
&#13;
Note that this study does not focus on two ways in which service delivery agencies use ICT that are very&#13;
relevant for understanding their full array of relationships with users. First, many public agencies are us-&#13;
ing mobile phones and social media to disseminate information efï¬&#129;ciently. However, if those interfaces&#13;
are one-way (â&#128;&#152;inside-outâ&#128;&#153;, or â&#128;&#152;top-downâ&#128;&#153;), then they do not â&#128;&#152;countâ&#128;&#153; as ICT-enabled citizen voice for the&#13;
purposes of this study. Second, agencies can use ICT for internal administrative reforms that can bolster&#13;
their capacity to respond to citizen concerns â&#128;&#147;by reducing the discretionary power of front-line providers&#13;
through increasing the capacity of managers to monitor service provider performance, as well as by&#13;
helping consistently track whether and how problems are being addressed. This study covers evidence&#13;
of institutional response to ICT-enabled systems for users to exercise voice, rather than the broader set&#13;
of cases of relevant e-government initiatives.&#13;
&#13;
&#13;
&#13;
Conceptual map: Unpacking digital engagement&#13;
The broader analytical context for this paper involves three simultaneous trends in the literature on the&#13;
role of information in leveraging public accountability. First, the number and diversity of practitioner-led&#13;
digital engagement for service delivery initiatives continue to grow, involving both effervescent experimen-&#13;
tation and efforts to scale up. Experimentation with social accountability tools has been growing within&#13;
the portfolios of both large public and private aid donors for the past decade, and some involve ICT. For&#13;
instance, many World Bank projects with â&#128;&#152;identiï¬&#129;able beneï¬&#129;ciariesâ&#128;&#153; now include some kind of feedback&#13;
mechanism, and citizen engagement has become a policy framework which includes the use of ICT (World&#13;
Bank 2014a). Major private donors, such as the Omidyar Network and Google, are also making signiï¬&#129;cant&#13;
investments to encourage â&#128;&#152;civic technologyâ&#128;&#153;â&#128;&#147; in both the global North and South. New donor partnerships&#13;
are also encouraging experimentation with civic technology in very low-income countries, led most notably&#13;
by Making All Voices Count.2&#13;
&#13;
&#13;
2 Making All Voices Count is supported by DFID, USAID, Sida and Omidyar Network&#13;
&#13;
                   EVALUATION TEAM | DEET                                                                      3&#13;
&amp;#12;                                                                        2016 World Development Report Background Paper&#13;
&#13;
&#13;
Second, while growing media coverage of ICT-enabled voice platforms is often enthusiastic, social science&#13;
research on the dynamics and impacts of these initiatives lags far behind, and the limited existing evidence&#13;
does not yet support unqualiï¬&#129;ed optimism.3 This study is distinctive in that it draws on a recent round of&#13;
unusually comprehensive empirical studies that involve both large-scale surveys and access to govern-&#13;
ment agency data. This new research suggests that the key dynamics that drive both voice and institutional&#13;
response may be different from some of the widely-held impressions projected by the media, donors and&#13;
platform developers. Take for example the case of Kenyan urban water agencyâ&#128;&#153;s MajiVoice (see also Welle&#13;
and Williams, this IDS Bulletin), a large-scale user feedback system widely presented as an ICT-enabled&#13;
voice platform. Recent surveys ï¬&#129;nd signiï¬&#129;cant evidence of institutional response, grounded in an effective&#13;
complaint tracking system â&#128;&#147; yet three-quarters of the complaints are ï¬&#129;led in person, 21% by phone and&#13;
less than 3% by SMS or online (Belcher and Lopes 2016).&#13;
&#13;
Third, the focus on the potential for citizen voice to improve public service delivery involves at least four dis-&#13;
tinct yet overlapping arenas of practice â&#128;&#147; the open data movement, open government reforms, anti-corrup-&#13;
tion efforts and social accountability initiatives. In spite of the apparent new policy consensus that all these&#13;
good things go together, in practice, the limited synergy between these distinct approaches suggests that&#13;
the whole is still not greater than the sum of the parts (Carothers and Brechenmacher 2014). Most of these&#13;
governance reform approaches rely heavily on the potential power of information to stimulate voice, yet&#13;
they assign information different roles. There are several conceptual challenges involved in specifying the&#13;
causal mechanisms that may link voice and institutional response â&#128;&#147; aside from the empirical questions&#13;
involved (documenting uptake is more straightforward than institutional response). The ï¬&#129;rst analytical chal-&#13;
lenge is to disentangle voice from responsiveness. Much of the ï¬&#129;rst wave of research on ICT-enabled voice&#13;
platforms focuses primarily on citizen uptake (e.g. Gigler and Bailur 2014), without clear evidence that the&#13;
feedback loop actually closes. In practice, the concept of feedback loop often used to imply that uptake&#13;
(e.g. citizen usage of crowd-sourced platforms to report feedback) necessarily leads to positive institutional&#13;
responses. In other words, there is a high degree of optimism embedded in the way the concept tends to&#13;
be used. In contrast, the framework proposed here avoids this assumption by treating the degree of insti-&#13;
tutional response as an open question.&#13;
&#13;
The second conceptual challenge is to specify the relationship between the role of ICT-enabled voice plat-&#13;
forms and the broader question of the relationship between transparency and accountability. In spite of the&#13;
widely-held view that â&#128;&#152;sunshine is the best disinfectantâ&#128;&#153;, the empirical literature on the relationship between&#13;
transparency and accountability is far from clear (Fox 2007; Gaventa and McGee 2013; Peixoto 2013). The&#13;
assumed causal mechanism is that transparency will inform and stimulate collective action, which in turn&#13;
will provoke an appropriate institutional response (Brockmyer and Fox 2015, Fox 2014).4 In this model, both&#13;
analysts and practitioners have only just begun to spell out the process behind that collective action (Fung,&#13;
Graham and Weil 2007; Joshi 2014; Lieberman, Posner and Tsai 2014). In light of widely held unrealistic&#13;
expectations about the â&#128;&#152;power of sunshineâ&#128;&#153;, convincing propositions about causal mechanisms involved&#13;
3 The current enthusiasm â&#128;&#147; among development stakeholders and the media â&#128;&#147; over the potential of technology in citizen&#13;
  participation in the developing world is reminiscent of the wave of optimism surrounding such initiatives in Europe over the&#13;
  past decade, despite the signiï¬&#129;cantly less favorable conditions of developing countries. Even in Europe, with generous&#13;
  funding and a more favorable institutional and technological context, most experiences present limited results at best (see, for&#13;
  instance, Prieto-Martin et al 2011; Susha and Gronlund 2014; Diecker and Galan 2014).&#13;
4 Note that this widely assumed causal mechanism does not distinguish explicitly between two different kinds of accountability â&#128;&#147;&#13;
  preventative (reforms that make future transgressions more transparent) and reactive (answerability and the possibility of sanctions).&#13;
&#13;
                      EVALUATION TEAM | DEET                                                                                           4&#13;
&amp;#12;                                                                 2016 World Development Report Background Paper&#13;
&#13;
&#13;
need to specify how and why the availability of an ICT platform (a) would motivate citizen action and (b) why&#13;
the resulting user feedback would motivate improvements in service provision. After all, decisionmakersâ&#128;&#153;&#13;
lack of information about problems is not the only cause of low-quality service provision.&#13;
&#13;
Third, the relationship between ICT-enabled voice platforms and the transparency/accountability question&#13;
is complicated by the fact that, in practice, a signiï¬&#129;cant subset of those platforms does not publicly dis-&#13;
close the user feedback. Yet if citizen voice is not made visible to other citizens, where does its leverage&#13;
come from? Such feedback systems aggregate data â&#128;&#147; by asking citizens to share their assessments of&#13;
service provision â&#128;&#147; but if the resulting information is not made public, then it cannot inform citizen action. In&#13;
these systems, if usersâ&#128;&#153; input is going to inï¬&#130;uence service provision, voice must activate â&#128;&#152;teethâ&#128;&#153; through a&#13;
process other than public transparency â&#128;&#147; such as the use of data dashboards that inform senior managersâ&#128;&#153;&#13;
discretionary application of administrative discipline.&#13;
&#13;
These conceptual propositions suggest that it is relevant to distinguish explicitly between two different&#13;
accountability pathways that link voice and â&#128;&#152;teethâ&#128;&#153; â&#128;&#147; shorthand for institutional willingness and capacity to&#13;
respond (Fox 2014). In downwards accountability relationships, service providers are held accountable by&#13;
citizen voice and action. The arrow of answerability points downwards, insofar as it is driven by the poten-&#13;
tial political cost to policymakers of not responding to a publicly visible concern. In contrast, in upwards&#13;
accountability relationships, frontline and middle level service providers are held accountable to senior&#13;
policymakers and programme managers, who use the user information to take administrative action. The&#13;
arrow of answerability points upwards. In this approach, the incentives for policymakers to act on user&#13;
information are less clear. Clearly, both mechanisms can operate together, but they are empirically and&#13;
analytically distinct (see Table 1).&#13;
&#13;
&#13;
Table 1. How does voice trigger teeth? Upwards and downwards accountability&#13;
&#13;
                                            PRIMARY CAUSAL MECHANISM&#13;
&#13;
 Voice pathway                    Upwards accountability                    Downwards accountability&#13;
&#13;
 Individual user feedback         From frontline service providers to&#13;
                                  managers and policymakers by&#13;
                                  identifying problems and triggering&#13;
                                  administrative action&#13;
&#13;
 Collective civic action                                                    From public sector to society, by bring-&#13;
                                                                            ing external pressure to bear and raising&#13;
                                                                            the political cost of non-responsiveness&#13;
&#13;
&#13;
Based on these conceptual propositions, this review of 23 ICT-enabled voice platforms distinguishes be-&#13;
tween two different types of citizen voice, â&#128;&#152;user feedbackâ&#128;&#153; and â&#128;&#152;civic actionâ&#128;&#153;. While these two approaches&#13;
can overlap in practice, they are analytically distinct. Their common denominator is the use of dedicated&#13;
ICT platforms to solicit and collect feedback on public service delivery. The differences between them in-&#13;
volve three dimensions: i) whether the feedback provided is disclosed; ii) through which pathway individual&#13;
&#13;
&#13;
                   EVALUATION TEAM | DEET                                                                               5&#13;
&amp;#12;                                                          2016 World Development Report Background Paper&#13;
&#13;
&#13;
or collective citizensâ&#128;&#153; preferences and views are expressed; and iii) whether these mechanisms tend to&#13;
promote downwards or upwards accountability. Note that this analytical approach differs from the World&#13;
Bankâ&#128;&#153;s current policy framework, which considers user feedback to be a variant of â&#128;&#152;citizen engagementâ&#128;&#153;&#13;
(World Bank 2014a). The approach proposed here, in contrast, does not treat the adjectives â&#128;&#152;citizenâ&#128;&#153; and&#13;
â&#128;&#152;civicâ&#128;&#153; as pure synonyms (though they overlap). We use citizen (as in â&#128;&#152;citizen voiceâ&#128;&#153;) to refer to individual,&#13;
non-public actions, while civic refers to public, collective actions. The two approaches are potentially mu-&#13;
tually reinforcing and in practice, some voice platforms combine them (see Figure 1, below).&#13;
&#13;
With regard to the ï¬&#129;rst dimension, we will assess cases in terms of the extent to which the feedback pro-&#13;
vided by individuals is publicly disclosed or not, thus enabling citizens to potentially act to hold govern-&#13;
ments accountable. Citizensâ&#128;&#153; capacity to hold governments accountable depends, among other things,&#13;
on the accessibility of publicly available relevant and actionable information (Fung, Graham and Weil&#13;
2007). In this respect, whether the feedback provided by citizens on service delivery is publicised or not&#13;
is directly related to the extent to which citizens can hold governments accountable for their performance&#13;
and actions. Thus, a ï¬&#129;rst distinction between user feedback and civic engagement is that, while a grow-&#13;
ing number of ICT platforms collect input from individuals, only user feedback that is made public counts&#13;
here as civic engagement (in Figure 1, this is the area of overlap between the two circles, involving both&#13;
individual feedback and public disclosure).&#13;
&#13;
For instance, in the case of Punjab Proactive Governance model, the government solicits feedback via mo-&#13;
bile phones on the quality of services provided on a large scale, on an ongoing basis (Bhatti, Zall Kusek and&#13;
Verheijen 2014). However, the feedback provided is not disclosed to the public, only to senior policymakers,&#13;
as it is intended to inform internal administrative monitoring processes. This process does not contribute to&#13;
citizensâ&#128;&#153; ability to act based on the feedback. In contrast, Uruguayâ&#128;&#153;s PorMiBarrio is a mobile and web-based&#13;
platform that enables Montevideoâ&#128;&#153;s citizens to report problems like vandalism and breakdowns of public in-&#13;
frastructure. The problems reported, and the actions taken in response by government (e.g. repaired, or not),&#13;
are displayed on a map on the public website. Not only is the government able to act on citizen reports, the&#13;
publication of the feedback makes it possible for citizens to hold governments accountable.&#13;
&#13;
The second dimension that we use to categorise platforms assesses the mechanisms by which citizensâ&#128;&#153;&#13;
views and preferences are expressed â&#128;&#147; either individually or collectively. Individualised mechanisms refer to&#13;
those that do not involve collective action, yet the feedback provided by a single individual is expected to&#13;
trigger a response, possibly through aggregation in order to identify problem areas in public service delivery.&#13;
This is the case, for instance, of web-based citizen reporting initiatives such as PorMiBarrio, FixMyStreet in&#13;
Georgia and I Paid a Bribe in India. In these cases, each individual report of very speciï¬&#129;c service issues&#13;
needing attention is assumed to be enough to lead to a governmental response. In contrast, collective&#13;
mechanisms refer to those in which it is the magnitude, nature and intensity of the aggregation of citizen&#13;
concerns that is expected to trigger governmental action. Examples of platforms for collective voice include&#13;
online petitions such as Change.org and mobile and web-voting in Brazilâ&#128;&#153;s state-wide Rio Grande do Sul&#13;
Participatory Budgeting (PB) process. In both initiatives, it is the collective mobilisation around a cause or&#13;
preference that is intended to trigger government responsiveness. The core of the technological platforms&#13;
that support these mechanisms lies in the reduction of transaction costs for collective action that can ad-&#13;
dress policy agenda-setting, in contrast to reacting to policy outputs. This collective dimension, we argue,&#13;
&#13;
&#13;
                 EVALUATION TEAM | DEET                                                                      6&#13;
&amp;#12;                                                           2016 World Development Report Background Paper&#13;
&#13;
&#13;
is what gives the character of â&#128;&#152;civic-nessâ&#128;&#153; to ICT-enabled voice platforms, insofar as they enable individuals&#13;
to engage in collective action â&#128;&#147; or at least to address public concerns. In contrast to feedback systems that&#13;
receive individual reactions to speciï¬&#129;c service delivery problems, ICT platforms that enable the public aggre-&#13;
gation of citizensâ&#128;&#153; views have more potential to constitute input into the setting of broader policy priorities.&#13;
This potential civic agenda-setting contribution goes beyond the conventional understanding of feedback,&#13;
in which the agendas that citizens are supposed to respond to are set from above (See Box 1 below).&#13;
&#13;
Thus, our conceptual distinction can be summarised as follows: citizen feedback initiatives provide feed-&#13;
back from individual clients of services. Where such feedback is not publicly disclosed, the causal pathway&#13;
to governmental response is via upwards accountability, from frontline and mid-level public servants to se-&#13;
nior managers and policymakers. Conversely, civic engagement refers to mechanisms where the feedback&#13;
is publicly disclosed, which allows for collective action and downwards accountability to also take place.&#13;
Figure 1 below illustrates our conceptual model.&#13;
&#13;
&#13;
Figure 1. Unpacking user feedback and civic action: Difference and overlap&#13;
&#13;
&#13;
&#13;
&#13;
On the left side of Figure 1 (blue) feedback is individual and undisclosed, which we can describe as a&#13;
typical case of governmental user feedback platforms. On the right side (yellow), citizen voice is simul-&#13;
taneously collective and disclosed, meeting the two criteria for our deï¬&#129;nition of civic engagement. At the&#13;
intersection point, however, we ï¬&#129;nd platforms that both collect individually speciï¬&#129;c feedback and make&#13;
those inputs public (sometimes also reporting whether and how the government responds). This overlap&#13;
involves the fact that, while individualised feedback mechanisms are not designed to spur online collective&#13;
action within the platform itself, the fact that the feedback is publicised may inform and facilitate collective&#13;
action â&#128;&#147; ofï¬&#130;ine as well as online. This may be the case, for instance, when the sum of individual feedback&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                      7&#13;
&amp;#12;                                                                2016 World Development Report Background Paper&#13;
&#13;
&#13;
   in a certain platform, such as FixMyStreet, reveals to the public the patterns of failure in a certain service, or&#13;
   in certain locations. In this case, even though the platform is not speciï¬&#129;cally designed to support collective&#13;
   action, the disclosure of evidence of patterns of failure in a given service may support well-targeted collec-&#13;
   tive action to address service delivery problems.&#13;
&#13;
   Figure 2 below presents the diagram populated with the cases we analyse in this study. The platforms that&#13;
   generated a high degree of tangible response from the service delivery agencies are indicated in green (7&#13;
   of 23). High responsiveness to citizen voice is measured here as tangible service delivery agency action,&#13;
   registered in more than half of cases. In eight cases, user uptake was high â&#128;&#147; though only three of these&#13;
   were also among the eight cases of high responsiveness.&#13;
&#13;
&#13;
   Figure 2. Mapping citizen voice platforms and degrees of institutional responsiveness&#13;
&#13;
&#13;
&#13;
&#13;
Maji Voice                                                                               Digital State Participatory Budgeting&#13;
Rio 1746                                                                                 Pressure Pan&#13;
Punjab Proactive                                                                         Change.org&#13;
My Voice                                                                                 U-Report&#13;
Karnataka BVS&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                            Degree of Institutional&#13;
                      Proactive Listening Electricity   Check my School                     Responsiveness&#13;
                      Lungisa                           LAPOR&#13;
                                                                                              High&#13;
                      I Change my City                  Huduma&#13;
                                                                                              Medium&#13;
                      Por Mi Barrio                     IMCO&#13;
                                                                                              Low&#13;
                      Maji Matone                       e-Chautari&#13;
                      I Paid a Bribe                    Barrios Digital&#13;
                      Chemi Kucha                       Sauti Za Wananchi&#13;
&#13;
   As shown in Figure 2, approximately a quarter of the cases are found in the user feedback category, an-&#13;
   other quarter in the civic action category, and 14 of 23 at the intersection between those two, called citizen&#13;
   engagement here. The cases in the user feedback category are mostly web- and mobile-based systems&#13;
   for collecting citizen views on the provision of services in a speciï¬&#129;c sector, such as electricity, water and&#13;
   health. Here the service provider plays either a passive or an active role in the collection of feedback. In&#13;
   the ï¬&#129;rst role, the citizen voluntarily initiates the contact to report an issue with public services via mobile- or&#13;
   web-based systems â&#128;&#147; sometimes in combination with ofï¬&#130;ine, face-to-face citizen attention windows (as in&#13;
   the case of MajiVoice in Kenya). One large-scale example in this category is LAPOR, Indonesiaâ&#128;&#153;s complaint&#13;
   handling system, which allows citizens to submit their reports on issues ranging from teacher absenteeism&#13;
   to damaged roads through a number of channels which include SMS, mobile apps and social media.&#13;
&#13;
                     EVALUATION TEAM | DEET                                                                           8&#13;
&amp;#12;                                                             2016 World Development Report Background Paper&#13;
&#13;
&#13;
The user feedback category also includes a second mechanism by which data is collected, which we call&#13;
â&#128;&#152;proactive listeningâ&#128;&#153; â&#128;&#147; also called â&#128;&#152;proactive feedbackâ&#128;&#153; by its practitioners (Bhatti, Zall Kusek and Verheijen&#13;
2015; Masud 2015). Here, government service providers proactively reach out to citizens in order to gather&#13;
feedback from them on the quality of services received. This mechanism is best illustrated by Punjabâ&#128;&#153;s Citi-&#13;
zen Feedback Model, where a system generates SMS and calls to public service users in order to ask them&#13;
about satisfaction with the services received and potential corruption incidents. The Punjab government&#13;
has deployed this approach on an unprecedentedly massive scale, with more than 6 million outreach calls&#13;
so far. Recent large-scale surveys of service users have found that these outreach efforts actually reached&#13;
and received responses from 15% of citizens called (Bayern 2015; World Bank 2015).&#13;
&#13;
The citizen engagement platforms (those found at the intersection between user feedback and civic action)&#13;
predominately utilize web and mobile-based mechanisms for reporting public service issues, similar to many&#13;
of the user feedback platforms. However, what distinguishes these platforms is that the user feedback pro-&#13;
vided to service providers is also disclosed publicly. For example, the Lungisa website allows Cape Town&#13;
residents to report service delivery problems (e.g. sanitation, electricity) using an online form, which is then&#13;
routed to the relevant government agency and further investigated by Lungisa staff. Unlike many user feed-&#13;
back systems, however, Lungisa allows residents to view all other reports that have been submitted, as well&#13;
as the status of each issue (i.e., in progress, closed). Indeed, if ICT platforms ultimately seek to facilitate dis-&#13;
closure about whether and how governments respond to citizen voice, then the capacity to track both citizen&#13;
feedback and government response are necessary, but not sufï¬&#129;cient, design features.&#13;
&#13;
Citizen engagement platforms also seem to differ from user feedback platforms in terms of their ownership.&#13;
While user feedback platforms tend to be built by service providers, citizen engagement platforms have been&#13;
launched primarily by CSOs or donor organizations (see Table 3). Generally, platforms built by service pro-&#13;
viders tend to generate far more user uptake than those launched by CSOs or donors, with a few exceptions.&#13;
&#13;
Finally, Figure 2 shows that several cases do not involve individualized user feedback and fall entirely with-&#13;
in the civic action category. In these cases, the ICT platformâ&#128;&#153;s primary goal is to support collective action&#13;
through the aggregation of individual citizen inputs. In other words, the role of individual inputs is not sim-&#13;
ply to identify speciï¬&#129;c service delivery problems, but to demonstrate the extent of citizen concern, through&#13;
the process of aggregation. The civic action cases considered here are signiï¬&#129;cantly less numerous and&#13;
more heterogeneous than either the user feedback cases or the citizen engagement cases. They include&#13;
projects as diverse as web-based participatory budgeting in Rio Grande do Sul and the international online&#13;
petitioning platform Change.org. However, if the scope of this research was broadened to include e-par-&#13;
ticipation, crowdsourced political deliberation, or the role of social media in enabling political protest, the&#13;
number of relevant ICT platforms would increase. However, the focus here is on citizen voice platforms that&#13;
speciï¬&#129;cally address public service provision.&#13;
&#13;
&#13;
&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                          9&#13;
&amp;#12;                                                           2016 World Development Report Background Paper&#13;
&#13;
&#13;
Digital engagement initiatives: Categorizing platforms in terms of&#13;
variables of interest&#13;
In this section, we categorize our 23 ICT platform cases by considering a number of factors (i.e., indepen-&#13;
dent variables) that may contribute to our outcome of interest: institutional response. We deï¬&#129;ne â&#128;&#156;institu-&#13;
tional responseâ&#128;&#157; as a clearly identiï¬&#129;able action taken by government/service providers, following individual&#13;
or collective input by citizens. For example, institutional response is evidence in the case of the Proactive&#13;
Listening initiative of EDE Este, an electricity distribution company in the Dominican Republic.. The initiative&#13;
combines a traditional complaint handling mechanism with proactive outreach to users. This online/mobile&#13;
phone platform allows citizens to report problems with electricity services, ranging from malfunctioning&#13;
connections to bribe requests by maintenance crews. Following the handling of the complaint (e.g. re-con-&#13;
nection of electricity), the company proactively re-contacts a random sample of users to gather feedback&#13;
on the quality of services provided. The feedback received is systematically used to inform sanctions (e.g.&#13;
administrative procedures) and rewards (e.g. performance-related wage bonuses for company workers).&#13;
Since its implementation in 2011, the initiative has recorded growing resolution rates of reported issues,&#13;
with close to 100 percent of the feedback provided indicating good or excellent levels of satisfaction.&#13;
 The average of instances of disrespectful treatment of clients registered at the beginning of the project was&#13;
drastically reduced, and reported cases of corruption fell by 70 percent.&#13;
&#13;
Turning next to our independent variables, we have identiï¬&#129;ed eleven factors that may have a relation-&#13;
ship with institutional responsivenessâ&#128;&#148;Disclosure of feedback, Disclosure of response, Proactive listen-&#13;
ing, Voicing modality, Accountability directionality, Uptake, Combined ofï¬&#130;ine action, Driver, Partnerships&#13;
between public service provider and civil society organization(s), Level of government, and Institutional&#13;
responsiveness. Of these, uptakeâ&#128;&#148;the degree to which citizens actually use digital platformsâ&#128;&#148;deserves&#13;
particular attention here:&#13;
&#13;
Uptake is often used as a key outcome for evaluating ICT platforms. Yet, while uptake may be necessary,&#13;
it is far from sufï¬&#129;cient for triggering institutional response (as the data below show). As described above,&#13;
our main outcome of interest here is governmental response. Rather than treating citizen voice as an end&#13;
in and of itself, our analysis treats uptake as an intermediate output that is relevant to the extent that it in-&#13;
forms governmental decisions about whether and how to respond (see Table 2). Making this distinction is&#13;
not intended to diminish the intrinsic value of expressing citizen voice. To the contrary, citizen voice is a so-&#13;
cially valuable practice with the clear potential to encourage learning. Nonetheless, differentiating between&#13;
uptake as an output, and institutional response as an outcome, provides crucial conceptual clarity that&#13;
allows us to disentangle a number of different hypotheses about how a number of factors might inï¬&#130;uence&#13;
institutional responsiveness. Table 2 details this approach further, distinguishing between inputs, outputs,&#13;
outcomes and impacts.&#13;
&#13;
&#13;
&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                      10&#13;
&amp;#12;                                                                 2016 World Development Report Background Paper&#13;
&#13;
&#13;
Table 2: ICT-enabled voice platforms: inputs, outputs and impacts&#13;
&#13;
       INPUT &gt;                  OUTPUT 1 &gt;             OUTPUT 2&gt;            OUTCOME &gt;                  IMPACT&#13;
&#13;
 Platform:                  Expression of citizen   Aggregation of      Institutional response   Tangible change&#13;
 Channel for voice          voice (uptake)          voices              (e.g., breaking          in service delivery&#13;
                                                                        bottlenecks, repairs,    access&#13;
                                                                        resource allocation)&#13;
&#13;
 Publicity:                 Disclosed or not?       Disclosed or not?   Disclosed or not?        Disclosed or not?&#13;
&#13;
&#13;
Considering uptake as an output helps us to better understand the role that it may play in generating the&#13;
outcome of interest, institutional responsiveness. Hypothetically, it should be relatively straightforward to&#13;
ï¬&#129;nd evidence supporting a causal relationship between uptake and responsiveness. All other things being&#13;
equal, governments are more likely to respond when more citizens are engaged. Indeed, the odds of suc-&#13;
cessful collective action increase as the number of participants grow (Lohmann 2000). In a cross-national&#13;
study by the World Bank (2015) of online petitioning, the higher the number of signatories of a petition, the&#13;
more likely governments are to respond. In fact, a number of both traditional and digital citizen participation&#13;
platforms are explicitly designed to trigger governmental response only when citizen participation reach-&#13;
es a pre-set benchmark. This is the case with citizen initiatives, referenda, and the ofï¬&#129;cial e-petitioning&#13;
systems in the United Kingdom and the United States. However, some development practitioners argue&#13;
that sustained uptake itself can be used as a proxy for government responsiveness. Otherwise, the argu-&#13;
ment goes, citizens would not â&#128;&#156;keep coming back.â&#128;&#157; While this assertion is partially supported by empirical&#13;
evidence (e.g., Sjoberg, et al, 2015), there are a number of instances where one ï¬&#129;nds sustained uptake&#13;
despite low levels of institutional responsiveness, perhaps best exempliï¬&#129;ed in Downsâ&#128;&#153; (1957) work on the&#13;
â&#128;&#156;paradox of voting.â&#128;&#157; Thus, treating citizen uptake as an indicator of government responsiveness remains&#13;
problematic (as we shall demonstrate later).&#13;
&#13;
Below, we provide a description of each variable of interest. While this list is by no means exhaustive, the&#13;
selection of these variables is informed by the literature on digital engagement and institutional respon-&#13;
siveness, and reï¬&#130;ects the availability of data across all cases. Further analysis would be necessary to as-&#13;
sess the relative weights of each variable. The main focus of the subsequent discussion will be on broad&#13;
patterns that emerge across all 23 cases. For brevityâ&#128;&#153;s sake, discussion of speciï¬&#129;c cases and the explicit&#13;
rationale used to code them will be limited.&#13;
&#13;
&#13;
&#13;
Description of Variables&#13;
Disclosure of feedback â&#128;&#147; Refers to the extent to which the feedback provided by the citizen is made public or not.&#13;
&#13;
Disclosure of response â&#128;&#147; Refers to whether the ofï¬&#129;cial response to citizen feedback (individual and collective) is&#13;
publicly disclosed or not. This would reveal the extent to which citizen input has led to institutional responsiveness.&#13;
&#13;
Proactive listening â&#128;&#147; Indicates whether at some point the service provider proactively contacts the citizen&#13;
in order to collect feedback on the quality of services provided.&#13;
&#13;
                     EVALUATION TEAM | DEET                                                                            11&#13;
&amp;#12;                                                             2016 World Development Report Background Paper&#13;
&#13;
Voicing modality â&#128;&#147; Whether the feedback provided through the ICT platform is individual or collective.&#13;
This indicates whether ICT-enabled collective action is involved in triggering a response.&#13;
&#13;
Accountability directionality â&#128;&#147; Determines if the causal pathway is more likely to promote accountability&#13;
between service providers and higher authorities (upwards accountability) or between citizens and service&#13;
providers (downwards accountability).&#13;
&#13;
Uptake â&#128;&#147; An essentially quantitative measure of the number of individuals who provide feedback or who join a&#13;
collective action. Uptake was coded in absolute terms of input provided (e.g. number of votes, reports) in a discon-&#13;
tinuous range of low (between 1 and 10,000), medium (between 10,001 and 100,000) and high (above 100,000).&#13;
&#13;
Combined ofï¬&#130;ine action â&#128;&#147; Identiï¬&#129;es whether additional actions are taken ofï¬&#130;ine in order to encourage&#13;
government responsiveness. This could refer to a structured process of citizen follow-up on participatory&#13;
budgeting, or to dedicated DE platform staff that follow up with the relevant authorities (e.g. Lungisa).&#13;
&#13;
Driver â&#128;&#147; Identiï¬&#129;es the main institution driving the initiative, such as government, donors and CSOs.&#13;
&#13;
Partnerships between public service provider and civil society organization(s) â&#128;&#147; This refers to the exis-&#13;
tence of formal and/or informal relationships between government and civil society, where there is some degree&#13;
of coordination towards a common outcome. For example, this is the case for the Por Mi Barrio project, a part-&#13;
nership between the organization DATA and the municipal government of Montevideo. This relationship allows&#13;
for direct communication between the digital platform (developed by DATA) and the governmentsâ&#128;&#153; existing com-&#13;
plaint response mechanism. Another example is the formal partnership between the IPaidaBribe.com project&#13;
and Indian governmental authorities, which facilitates communication and allows for coordinated follow-up of&#13;
bribes reported to the government. Coding options include government-led, CSO-led and donor-led.&#13;
&#13;
Level of government: Describes the level at which services are provided and feedback is provided,&#13;
sub-divided as national, sub-national and local.&#13;
&#13;
Institutional responsiveness: This indicator reï¬&#130;ects the degree to which there is clearly documented ev-&#13;
idence of government response to feedback provided through ICT platforms (including combined online/&#13;
ofï¬&#130;ine action). Whenever possible, coding categories for institutional responsiveness reï¬&#130;ect the share of&#13;
citizensâ&#128;&#153; inputs addressed, ranging from low (less than 20%) to medium (between 20 and 50% of citizen&#13;
issues addressed) and high (50% and above). When that was not possible, researchers compared the&#13;
current and prior status quo with regard to the explicit and implicit goals of the project. Level of respon-&#13;
siveness ratings were based on existing data (e.g. I Change My City), original data analysis (e.g. Change.&#13;
org) and, in some cases, interviews with DE platform staff, who were asked to provide clear evidence of&#13;
responsiveness to feedback provided through the platforms. This approach is limited by dependence on&#13;
self-reported administrative data in cases where veriï¬&#129;able system data and or user surveys are not available.&#13;
 Cases that lacked sufï¬&#129;cient evidence with which to assess degree of institutional responsiveness were&#13;
not included.&#13;
&#13;
Table 3 below presents the ï¬&#129;nal coding of cases, followed by Table 4 with the speciï¬&#129;c evidence for the&#13;
coding of institutional responsiveness outcomes.&#13;
&#13;
&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                         12&#13;
&amp;#12;                                                                                                                                                                                   2016 World Development Report Background Paper&#13;
&#13;
&#13;
Table 4 â&#128;&#147; Mapping uptake and institutional response to ICT-enabled voice platforms                                                                                                                                    High    Medium          Low&#13;
&#13;
&#13;
               CASE                       COUNTRY                                                                                           VARIABLES                                                               OUTPUT      OUTCOME&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                              ACCOUNTABILITY DIRECTION&#13;
                                                                                                                  INDIVIDUAL / COLLECTIVE&#13;
                                                                                            PROACTIVE LISTENING&#13;
                                                                        RESPONSE DISCLOSE&#13;
                                                    FEEDBACK DISCLOSE&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                                                                       GOVT LEVEL&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                                                                                                   RESPONSE&#13;
                                                                                                                                                                                            PARTNER&#13;
                                                                                                                                                                         OFFLINE&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                                                                                     UPTAKE&#13;
                                                                                                                                                                                   DRIVER&#13;
 PROACTIVE LISTENING ELECTRICITY            DO                                                                    IND                                                              GOV                SUB&#13;
&#13;
&#13;
 MAJI VOICE                                 KE                                                                    IND                                                              GOV                LOCAL&#13;
&#13;
&#13;
 LUNGISA                                    ZA                                                                    IND                                                              CSO                LOCAL&#13;
&#13;
&#13;
 RIO 1746                                   BR                                                                    IND                                                              GOV                LOCAL&#13;
&#13;
&#13;
 DIGITAL STATE PB                           BR                                                                    COL                                                              GOV                SUB&#13;
&#13;
&#13;
 I CHANGE MY CITY                           IN                                                                    IND                                                              CSO                LOCAL&#13;
&#13;
&#13;
 POR MI BARRIO                              UY                                                                    IND                                                              CSO                LOCAL&#13;
&#13;
&#13;
 MAJI MATONE                                TZ                                                                    IND                                                              CSO                LOCAL&#13;
&#13;
&#13;
 PRESSURE PAN                               BR                                                                    COL                                                              CSO                 ALL&#13;
&#13;
&#13;
 CHANGE .ORG                                INT                                                                   COL                                                              CSO                 ALL&#13;
&#13;
&#13;
 PUNJAB PROACTIVE                           PK                                                                    IND                                                              GOV                SUB&#13;
&#13;
&#13;
&#13;
&#13;
                 EVALUATION TEAM | DEET                                                                                                                                                                                                        13&#13;
&amp;#12;                                                                                                                                                                                    2016 World Development Report Background Paper&#13;
&#13;
&#13;
&#13;
                 CASE                      COUNTRY                                                                                           VARIABLES                                                               OUTPUT    OUTCOME&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                               ACCOUNTABILITY DIRECTION&#13;
                                                                                                                   INDIVIDUAL / COLLECTIVE&#13;
                                                                                             PROACTIVE LISTENING&#13;
                                                                         RESPONSE DISCLOSE&#13;
                                                     FEEDBACK DISCLOSE&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                                                                        GOVT LEVEL&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                                                                                                 RESPONSE&#13;
                                                                                                                                                                                             PARTNER&#13;
                                                                                                                                                                          OFFLINE&#13;
&#13;
&#13;
&#13;
&#13;
                                                                                                                                                                                                                      UPTAKE&#13;
                                                                                                                                                                                    DRIVER&#13;
I PAID A BRIBE                               IN                                                                    IND                                                              CSO                 ALL&#13;
&#13;
&#13;
U-REPORT                                     UG                                                                    COL                                                              DON                NAT&#13;
&#13;
&#13;
CHEMI KUCHA                                  GE                                                                    IND                                                              CSO                LOCAL&#13;
&#13;
&#13;
CHECK MY SCHOOL                              PH                                                                    IND                                                              CSO                SUB&#13;
&#13;
&#13;
LAPOR                                        ID                                                                    IND                                                              GOV                 ALL&#13;
&#13;
&#13;
MYVOICE                                      NG                                                                    IND                                                              DON                SUB&#13;
&#13;
&#13;
HUDUMA                                       KE                                                                    IND                                                              CSO                 ALL&#13;
&#13;
&#13;
IMCO                                         MX                                                                    IND                                                              CSO                NAT&#13;
&#13;
&#13;
KARNATAKA BVS                                IN                                                                    IND                                                              DON                SUB&#13;
&#13;
&#13;
E-CHAUTARI                                   NP                                                                    IND                                                              DON                SUB&#13;
&#13;
&#13;
BARRIOS DIGITAL                              BO                                                                    IND                                                              DON                SUB&#13;
&#13;
&#13;
SAUTI ZA WANANCHI                            TZ                                                                    IND                                                              CSO                NAT&#13;
&#13;
&#13;
&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                                                                                                                                                    14&#13;
&amp;#12;                                                                                                               2016 World Development Report Background Paper&#13;
&#13;
&#13;
Table 5: Evidence for assessing institutional responsiveness&#13;
&#13;
 CASE                                        RESPONSE   CRITERIA FOR CODING                                     DATA SOURCE&#13;
&#13;
                                                        Reduction of corruption reports by 70%, increased       Interview with distribution company, system reports&#13;
 Proactive Listening Electricity             High&#13;
                                                        levels of service-user satisfaction.                    provided by company.&#13;
&#13;
                                                        Increase in percentage of solved complaints,            System data analysis (n=57,809), customer survey&#13;
                                                        with time of response reduced by half since             (n=1,064).â&#128;&#157; (Belcher &amp; Lopes 2015).&#13;
 Maji Voice                                  High&#13;
                                                        implementation. Survey reveals 60% of satisï¬&#129;ed&#13;
                                                        customers.&#13;
&#13;
 Lungisa                                     High       98% of complaints reported as solved.                   Website (http://www.lungisa.org/, March 28th 2015).&#13;
&#13;
                                                        99% of complaints reported as solved, user              1746 statistical report (http://www.1746.rio.gov.br/,&#13;
 Rio 1746                                    High&#13;
                                                        satisfaction at 74%                                     March 28th 2015)&#13;
&#13;
 Digital State Participatory                            Institutional response based on 100 % of prioritized    World Bank report, â&#128;&#156;Impact of online voting in&#13;
                                             High&#13;
 Budgeting                                              projects submitted to ofï¬&#129;cial budget.                   participatory budgeting in Brazilâ&#128;&#157; (Haikin, 2015)&#13;
&#13;
                                                        51% of complaints resolved.                             Website (http://www.ichangemycity.com/,&#13;
 I Change My City                            HIgh&#13;
                                                                                                                March 28th 2015)&#13;
&#13;
 Por Mi Barrio                               High       50% of complaints resolved.                             Montevideoâ&#128;&#153;s data report, interview with project staff.&#13;
&#13;
                                                        Service provider actions were taken in 40% of           Website (http://blog.daraja.org/2012/02/so-what-&#13;
 Maji Matone                                 Medium&#13;
                                                        reports received.                                       have-we-learnt-summarising.html, March 28th 2015)&#13;
&#13;
                                                        24% of campaigns supported by the organization          System data analysis provided by MeuRio.&#13;
 Meu Rioâ&#128;&#153;s Pressure Pan                      Medium&#13;
                                                        are successful.&#13;
&#13;
                                                        Average individual signature has 25% chance of          Data analysis of 3.9 million usersâ&#128;&#153; data from change.&#13;
 Change.org                                  Medium&#13;
                                                        generating a response.                                  org through open API. World Bank analysis, 2015.&#13;
&#13;
&#13;
&#13;
&#13;
                    EVALUATION TEAM | DEET                                                                                                                              15&#13;
&amp;#12;                                                                                                             2016 World Development Report Background Paper&#13;
&#13;
&#13;
&#13;
CASE                                        RESPONSE   CRITERIA FOR CODING                                    DATA SOURCE&#13;
&#13;
                                                       With nearly one million citizens contacted, the        World Bank Development Report 2016 (draft).&#13;
                                                       government has taken about 6000 administrative&#13;
                                                       actions, mostly warnings but also formal&#13;
                                                       apologies, with limited instances of suspension&#13;
Punjab Proactive                            Medium     and dismissal of civil servants. There is a&#13;
                                                       systematic proportion of fake and incorrect citizen&#13;
                                                       cell phone numbers entered by government&#13;
                                                       ofï¬&#129;cials, indicating constraints on senior manager&#13;
                                                       oversight capactiy&#13;
&#13;
                                                       Reponses to reports sent by IPAB to authorities        Interview with IPAB staff (e-mail Sunil Nair, 19&#13;
I Paid a Bribe                              Low&#13;
                                                       described as â&#128;&#156;very limitedâ&#128;&#157;.                           December 2014).&#13;
&#13;
                                                       Limited to anecdotal data on MPs (rather limited)      Berdeu &amp; Abreu-Lopes, 2015.&#13;
U-Report                                    Low&#13;
                                                       interest on U-Report data.&#13;
&#13;
                                                       4% of reports ï¬&#129;xed within one year of activity         Website (https://www.chemikucha.ge/en/ , March 28&#13;
Chemi Kucha                                 Low&#13;
                                                                                                              2015)&#13;
&#13;
                                                       11% response rate to reported school issues.           Crowdsourcing Citizen Participation: The&#13;
Check My School                             Low&#13;
                                                                                                              CheckMySchool 3G Experience, 2014.&#13;
&#13;
                                                       Government considers the 8% of reports                 System data provided by LAPOR team.&#13;
LAPOR                                       Low&#13;
                                                       received got a response.&#13;
&#13;
                                                       Out of 314 messages sent, only six were responded      Lee, &amp; Schaefer (2014)&#13;
MyVoice                                     Low        using the system, and eighteen were tagged for&#13;
                                                       follow-up.&#13;
&#13;
                                                       Assessment shows that out of the 3,000 reports         Bott &amp; Young (2012)&#13;
Huduma                                      No         submitted via SMS, email, and Twitter, none were&#13;
                                                       resolved.&#13;
&#13;
&#13;
&#13;
&#13;
                   EVALUATION TEAM | DEET                                                                                                                         16&#13;
&amp;#12;                                                                                                            2016 World Development Report Background Paper&#13;
&#13;
&#13;
&#13;
CASE                                       RESPONSE   CRITERIA FOR CODING                                    DATA SOURCE&#13;
&#13;
                                                      There was no evidence of responsiveness on the         Interview with project staff (phone).&#13;
IMCO                                       No         part of education authorities to school issues&#13;
                                                      reported on the platform&#13;
&#13;
                                                      Despite study looking for evidence of                  Georgieva Andonovska, E. (2014), Madon (2014)&#13;
                                                      institutional responsiveness, no clearly&#13;
Karnataka Beneï¬&#129;ciary Feedback              Low&#13;
                                                      documented evidence of government&#13;
                                                      responsiveness on service delivery issues.&#13;
&#13;
                                                      Despite study looking for evidence of                  On Track Evaluation Report.&#13;
                                                      institutional responsiveness, no clearly               Keystone Accountability, 2015.&#13;
e-Chautari                                 Low&#13;
                                                      documented evidence of government&#13;
                                                      responsiveness on service delivery issues.&#13;
&#13;
                                                      Despite study looking for evidence of                  On Track Evaluation Report.&#13;
                                                      institutional responsiveness, no clearly               Keystone Accountability, 2015.&#13;
Barrios Digital                            Low&#13;
                                                      documented evidence of government&#13;
                                                      responsiveness on service delivery issues.&#13;
&#13;
                                                      Despite interview with staff, no clearly documented    Interview with project staff (e-mail).&#13;
Sauti Za Wananchi                          Low        evidence of government responsiveness on&#13;
                                                      service delivery issues.&#13;
&#13;
&#13;
&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                                                                     17&#13;
&amp;#12;                                                                2016 World Development Report Background Paper&#13;
&#13;
&#13;
The majority of platforms make their citizen feedback public (18 of 23). Out of the ï¬&#129;ve that do not disclose&#13;
the feedback, two are governmental and three involve donor agencies in collaboration with governments.&#13;
Conversely, all of the CSO-driven initiatives publicise the input given by citizens. This ï¬&#129;nding makes par-&#13;
ticular sense if one considers the directionality of accountability relations. User-feedback initiatives (i.e. not&#13;
disclosed) are more likely to be implemented by governments or donors, where service providers are held&#13;
accountable to a higher authority (upwards accountability). Conversely, given that CSOs have few means to&#13;
hold providers directly accountable, they rely essentially on downwards accountability mechanisms, where&#13;
the driving force of institutional responsiveness â&#128;&#147; at least hypothetically â&#128;&#147; is the exposure of the behaviour of&#13;
service providers vis-Ã -vis citizens. No pattern seems to emerge when looking at disclosure of feedback and&#13;
institutional responsiveness, however. In user feedback initiatives (where feedback is not disclosed and there&#13;
is no collective action), the four cases are equally split between low and high levels of institutional responsive-&#13;
ness. A similar pattern emerges when examining citizen engagement initiatives: public disclosure of feedback&#13;
does not seem to lead â&#128;&#147; per se â&#128;&#147; to increased responsiveness from providers.&#13;
&#13;
In 14 cases, the provision of input through the dedicated platform is complemented by some type of ofï¬&#130;ine&#13;
action to prompt governments to respond and/or to monitor government responsiveness. This is the case, for&#13;
instance, of the Rio Grande do Sul PB process, in which citizens are periodically elected to monitor the imple-&#13;
mentation of investments prioritised through a voting process (Spada et al. 2015). In MajiVoice, the respon-&#13;
siveness of the water service agency is actively monitored by the members of the Water Services Regulatory&#13;
Board, which can trigger legal actions against service providers when they fail to meet pre-established quality&#13;
standards (Belcher and Lopes 2016). Yet, ofï¬&#130;ine action does not seem to ensure responsiveness by itself, as&#13;
illustrated by the cases of e-Chautari in Nepal and Barrios Digital in Bolivia. However, among the 14 cases,&#13;
the evidence is insufï¬&#129;cient to verify that the intensity and regularity of these ofï¬&#130;ine actions varies.&#13;
&#13;
In the category of civic action initiatives, where response involves online collective action, we ï¬&#129;nd four different cas-&#13;
es, with varying degrees of institutional responsiveness. The Rio Grande do Sul Digital PB process has a high level&#13;
of institutional responsiveness, while the online petition platform Change.org and the Brazilian initiative Pressure&#13;
Pan both have medium levels. A possible explanation of the different responsiveness levels is the difference in&#13;
institutional design. Digital PB in Rio Grande do Sul is a governmental initiative mandated by state legislation. As&#13;
such, all of the citizen-generated social investment proposals that are approved through the participatory process&#13;
are ofï¬&#129;cially included in the Stateâ&#128;&#153;s budget, with a number of them effectively carried out by the state government.&#13;
 The other two initiatives are platforms that allow any citizen to initiate collective action to petition or exert pres-&#13;
sure on the government to take an action towards any public agenda. This open-endedness means that the&#13;
platforms can launch both some actions that trigger extensive uptake and mobilisations, and many that fail to&#13;
generate follow-up. This potential for a large denominator, in terms of the total number of initiatives, would affect&#13;
the overall percentage of petitions that trigger responsiveness. Indeed, some data seems to suggest the im-&#13;
portance of mobilisation capacity: online petitions on Change.org are substantively more likely to be successful&#13;
when sponsored by an organisation (World Bank 2015), and citizen campaigns through Pressure Pan are three&#13;
times more likely to succeed when receiving mobilisation support from Pressure Panâ&#128;&#153;s staff. This evidence reso-&#13;
nates with the proposition that the effectiveness of digital technologies in social mobilisation depends on ofï¬&#130;ine&#13;
structures of organisation and inï¬&#130;uence (Fung, Gilman and Shkabatur 2013). Finally, we ï¬&#129;nd the widely-rec-&#13;
ognised case of U-Report in Uganda, with low level of institutional responsiveness, which we shall discuss later.&#13;
&#13;
&#13;
&#13;
                   EVALUATION TEAM | DEET                                                                             18&#13;
&amp;#12;                                                          2016 World Development Report Background Paper&#13;
&#13;
In terms of the institutional actors that drive the voice initiatives, 12 are led by CSOs, six by governments,&#13;
and ï¬&#129;ve by donors. Out of the seven initiatives with high levels of responsiveness, four are govern-&#13;
ment-led and three CSO-led. Civil society and governments seem equally capable of creating plat-&#13;
forms and processes that engender responsiveness. However, the three CSO high-response initiatives&#13;
all share a common trait in that they involve partnerships with government. In other words, in all of the&#13;
cases of high institutional responsiveness, the government is either leading the process or plays the role&#13;
of a partner. However, not all of the initiatives involving governmentâ&#128;&#147;CSO partnerships led to high levels&#13;
of institutional responsiveness, as illustrated by the cases of I Paid a Bribe and Check My School, both&#13;
of which had low percentages of issues raised by citizens that led to documented agency responses.&#13;
Seen together, these ï¬&#129;ndings seem to suggest that while partnership with government is not a sufï¬&#129;cient&#13;
condition for the responsiveness of CSO-led initiatives, it may well be an enabling one. Finally, while the&#13;
initiatives showing medium and high degrees of institutional responsiveness involve both CSO and gov-&#13;
ernment-driven efforts, we ï¬&#129;nd no donor-driven platforms that led to institutional responsiveness. While&#13;
we do not claim our sample to be representative and the results may be skewed due to the small number&#13;
of donor-driven cases analysed, these patterns suggest future research paths, focusing on the role that&#13;
different drivers may play in institutional responsiveness.&#13;
&#13;
&#13;
   Box 1. Whose voices are they?&#13;
&#13;
   Whose voices are expressing themselves on ICT-enabled governmental service delivery feedback&#13;
   platforms? What kinds of bias may be involved? ICT platforms can potentially select for some kinds&#13;
   of responses over others. This can happen in at least two distinct ways â&#128;&#147; differential access to com-&#13;
   munication of feedback, and categorisation of user input that pre-selects for certain categories.&#13;
&#13;
   First, the subset of citizens who engage with ICT systems may or may not represent the concerns of&#13;
   those citizens who lack ICT access, such as rural women or people without access to formal educa-&#13;
   tion. This is the case with URâ&#128;&#153;s U-Reporters, one quarter of whom are government employees (Mellon&#13;
   et al. 2015), and who under-represent the low-income, rural citizens who are most in need of public&#13;
   services. Indeed, the whole notion of user feedback suggests that the target group is limited to those&#13;
   citizens who ostensibly should have access but have problems in practice â&#128;&#147; such as those who have&#13;
   a water connection, but lack water. This implicit framing excludes those who are not included in water&#13;
   systems, clinics, schools or public security in the ï¬&#129;rst place - and therefore not considered â&#128;&#152;usersâ&#128;&#153;.&#13;
&#13;
   Second, as citizen concerns are input into government agency data systems for aggregation and&#13;
   transmission upwards to senior managers, administrative legibility requires them to be categorised&#13;
   into lists of preexisting categories, which may also select for some kinds of citizen priorities to the&#13;
   exclusion of others â&#128;&#147; as in the case of issues that are priorities for low-income urban women, as&#13;
   Ranganathan found in her study of e-redressal systems in Karnataka (2012).&#13;
&#13;
   To sum up, the framing of the main questions addressed in this study â&#128;&#147; whether or not ICT service&#13;
   delivery feedback platforms lead to uptake, and whether or not such voice in turn leads to service&#13;
   delivery response â&#128;&#147; does not address two relevant questions: whose voice is projected, and how&#13;
   inclusive the feedback agenda is.&#13;
&#13;
&#13;
                 EVALUATION TEAM | DEET                                                                      19&#13;
&amp;#12;                                                           2016 World Development Report Background Paper&#13;
&#13;
&#13;
When examining uptake, the results in Table 4 support our previous argument that citizen use of plat-&#13;
forms (an output) should not be equated with institutional responsiveness (an outcome). This sample&#13;
includes signiï¬&#129;cant cases that combined high uptake with low responsiveness. The case of U-Report (UR),&#13;
UNICEFâ&#128;&#153;s social monitoring system for young Ugandans, provides compelling evidence for this point.&#13;
Created in 2007, this SMS-based platform runs weekly polls with registered users on a broad range of is-&#13;
sues (e.g. child marriage, access to education). To inform public debate, the results of the polls are widely&#13;
disseminated through the projectâ&#128;&#153;s website and diverse mass media outlets, including a variety of formats&#13;
such as newspaper articles, radio shows and even a documentary broadcast on major Ugandan TV chan-&#13;
nels. Members of Parliament (MPs) are URâ&#128;&#153;s main policy audience. Aligned with a vision of real-time data&#13;
collection to inform policymaking that goes beyond sending weekly newsletters with poll results to MPs,&#13;
UNICEF also provides MPs with access to the platform to reach out to their audiences. The number of&#13;
registered users (U-Reporters) has grown steadily since its launch, recently reaching more than 299,000&#13;
(Bayern 2015; World Bank 2015b). UNICEF describes UR as a â&#128;&#156;â&#128;&#152;killer appâ&#128;&#153; for communication towards&#13;
achieving equitable outcomes for children and their familiesâ&#128;&#157; (UNICEF 2012). This enthusiastic view of&#13;
UR has resonated in development circles, with the free SMS-based platform currently being rolled out in&#13;
countries such as Rwanda, Burundi, the Democratic Republic of Congo, South Sudan, Nigeria and Mexico.&#13;
&#13;
Uptake is not a problem for UR in terms of numbers, and it leverages the potential of mobile phones as a&#13;
means to â&#128;&#152;listen at scaleâ&#128;&#153;. However, 47% of UR participants have some university education and one quar-&#13;
ter are government employees, raising questions about whose voices are being projected (see Box 1).&#13;
Furthermore, until recently very little was known about the extent to which U-reportâ&#128;&#153;s take-up was translated&#13;
into any type of institutional responsiveness. A new detailed evaluation of U-Report ï¬&#129;nds no systematic&#13;
evidence of U-Report affecting policy, let alone MPs behaviour in terms of representation, legislation and&#13;
oversight (Berdou and Lopes 2016). U-Report emerges thus as a signiï¬&#129;cant case that illustrates the need&#13;
to separate uptake (as an output), from institutional responsiveness (as an outcome).&#13;
&#13;
To conclude the discussion of these empirical ï¬&#129;ndings, when examining the table above, one of the most&#13;
noticeable patterns is the existence of numerous digital engagement initiatives that meet dead ends despite&#13;
different pathways â&#128;&#147; at least in the relatively short run. The majority of the 23 cases studied led to low levels&#13;
of institutional responsiveness, with 11 reporting medium to high levels (deï¬&#129;ned conservatively as leading to&#13;
at least 20% response rates). Notably, the multiple dead ends do not seem to be motivated by the absence&#13;
of any one speciï¬&#129;c factor. None of these variables appear to be a sufï¬&#129;cient condition for institutional respon-&#13;
siveness, suggesting that none of these factors can be a considered as a â&#128;&#152;magic bulletâ&#128;&#153;. The ï¬&#129;ndings suggest&#13;
multiple pathways to institutional responsiveness â&#128;&#147; involving the convergence of multiple, mutually reinforcing&#13;
factors. If one factor does stand out, however, it is government involvement, insofar as four of the six cases of&#13;
government-led voice platforms were associated with high rates of service delivery responsiveness.&#13;
&#13;
&#13;
&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                      20&#13;
&amp;#12;                                                            2016 World Development Report Background Paper&#13;
&#13;
&#13;
Conclusion&#13;
This study reviewed cases of ICT-enabled voice platforms where evidence of institutional response was&#13;
available. As suggested in our introduction, in the â&#128;&#152;yelpâ&#128;&#153; feedback loop model, proponents tend to as-&#13;
sume that user feedback to identify service delivery problems is sufï¬&#129;cient to induce service providers to&#13;
respond. This review of the evidence from 23 ICT-enabled platforms ï¬&#129;nds that this implicit market model,&#13;
in which (individual) demands for good services produces its own supply, is not sufï¬&#129;cient to leverage&#13;
institutional response. This study organized the data from available empirical research in order to iden-&#13;
tify broad patterns of user uptake, public access to user feedback data, and institutional arrangements,&#13;
and provide an assessment of whether service providers respond to user feedback. This conclusion&#13;
addresses some of the emerging issues that should be addressed in the future. Indeed, as the evidence&#13;
base grows, more systematic explorations of the relationship between ICT-enabled citizen voice and&#13;
institutional response should be possible.&#13;
&#13;
The ï¬&#129;ndings from the 23 cases where both user uptake and institutional response data were available&#13;
indicate mixed results on both counts. In eight cases, user uptake was high. Institutional response was&#13;
high in seven cases, and intermediate in three. For the majority of cases, institutional response was low or&#13;
non-existent. One reason for these mixed results, however, is that the umbrella category â&#128;&#156;ICT-enabled voice&#13;
platformsâ&#128;&#157; may have resulted in the selection of cases that are actually quite different from one another.&#13;
Separating some of these approaches from one another may help to clarify the ï¬&#129;ndings. Indeed, a similar&#13;
approach has been used to unpack outcomes from the diverse initiatives that fall under the conceptual&#13;
umbrella of â&#128;&#156;social accountabilityâ&#128;&#157; (Fox 2014). What looks like â&#128;&#156;mixed resultsâ&#128;&#157; at ï¬&#129;rst glance may simply be&#13;
a case of conï¬&#130;ating apples with oranges. Since this research collected data on a diverse array of indepen-&#13;
dent variables, patterns in citizen uptake and institutional response can be revisited, revealing patterns that&#13;
would not otherwise be visible. This conclusion will highlight several variables that may be especially fruitful&#13;
for future research on broad-based user feedback, civic engagement, and effective institutional response.&#13;
&#13;
&#13;
I) Does the feedback platform contribute to upwards accountability, downwards&#13;
accountability, or both?&#13;
&#13;
The institutional design of ICT-enabled voice platforms determines whether the role of citizen voice is limited&#13;
to informing program managers and policymakers (i.e., upwards accountability), or whether voice is intended&#13;
to contribute to public scrutiny and potential collective action, which in turn would create incentives for insti-&#13;
tutional response (i.e. downwards accountability). Through processes of upwards accountability, ICT-enabled&#13;
user feedback can help senior policy-makers to identify bottlenecks and address front-line service provision&#13;
issues. For example, in one of the cases with the highest uptake â&#128;&#147; Punjab Proactive Feedback â&#128;&#147; citizen&#13;
reports are not disclosed and there is no ofï¬&#130;ine citizen engagement, so institutional response is left to the&#13;
discretion of senior managers. However, there is evidence that many ICT-enabled voice platforms are also&#13;
conducive to downwards accountability as well: User feedback is publicly disclosed in 18 of the 23 cases&#13;
studied. In 12 of the 23 cases, ICT feedback was complemented by ofï¬&#130;ine citizen engagement of some kind.&#13;
&#13;
While platforms that enable upwards accountability (e.g., large-scale opinion surveys) are associated with&#13;
only modest levels of institutional responsiveness, there appears to be a relationship between platforms&#13;
&#13;
                  EVALUATION TEAM | DEET                                                                       21&#13;
&amp;#12;                                                                   2016 World Development Report Background Paper&#13;
&#13;
&#13;
that are conducive to downwards accountability and platforms that produce greater responsiveness: Five&#13;
of the seven high-impact platforms disclosed feedback. Six of the seven high-impact platforms involved&#13;
ofï¬&#130;ine citizen engagement. In all of the high-impact cases, government was present either as a driver (4&#13;
cases) or as a partner (3 cases). This suggests that for downwards accountability to work most effectively,&#13;
both public disclosure of feedback and public collective action may be necessary. In other words, civic&#13;
engagement, in addition to information, is what generates the civic muscle necessary to hold senior poli-&#13;
cymakers and frontline service providers accountable.&#13;
&#13;
&#13;
II) What institutional design features can influence the willingness and capacity of service&#13;
providers to respond to citizen feedback?&#13;
&#13;
Another way to explore the role that citizen voice plays in driving institutional response is to explore the&#13;
issue through the lens of a senior program manager. Their responsiveness to citizen feedback is deter-&#13;
mined both by their willingnessâ&#128;&#148;intent and motivationsâ&#128;&#148;and their capacityâ&#128;&#148;the institutional leverage&#13;
they have to actually change practice. In some cases, institutional design and a strong sense of commit-&#13;
ment to the organisational mission by high-level ofï¬&#129;cials are enough to encourage a program managerâ&#128;&#153;s&#13;
willingness to respond. In these cases, the key role of ICT platforms is to bolster capacity to respondâ&#128;&#147; as&#13;
with MajiVoiceâ&#128;&#153;s water provision in Kenya. 5 Some program managers may have a strong sense of mis-&#13;
sion, while others may be more concerned about the potential political risk associated with dissatisï¬&#129;ed&#13;
citizens. In either case, the systematic collection of citizen feedback can be a useful tool. In other words,&#13;
the motivations for responsiveness do not appear to be directly inï¬&#130;uenced by ICT voice platforms. In&#13;
contrast, the determinants of senior manager capacity to respond to citizen voice are directly affected by&#13;
ICT platformsâ&#128;&#153; institutional and technical design. These features will determine the precision with which&#13;
user problems are identiï¬&#129;ed, which is crucial to identify which service providers are responsible. The&#13;
cases studied suggest that it is crucial for user complaints to be routed to entities within the service pro-&#13;
viding agency that have some incentive and capacity to respond. Speciï¬&#129;cally, experiences with the most&#13;
high-impact platforms, such as the Dominican electricity agency and MajiVoice in Kenya, suggest that&#13;
direct links between governmental feedback reception systems and internal work order systems greatly&#13;
increase policymakersâ&#128;&#153; capacity to determine whether and how complaints have been resolved, which&#13;
appears to be a necessary condition for effective institutional response. Similarly, two of the most suc-&#13;
cessful CSO platforms â&#128;&#147; Por Mi Barrio in Uruguay and I Change My City in India â&#128;&#147; are connected to exist-&#13;
ing governmental service provider complaint systems. These are examples of the institutional questions&#13;
that play crucial roles as intervening variables that shape whether or not voice triggers teeth to act. The&#13;
proposition that emerges here is that regardless of their motivations, policymakers with a commitment&#13;
to bolstering institutional responsiveness should in principle have an incentives to: 1) institute tracking&#13;
systems that directly link complaints to institutional responses and 2) to publicly disclose both citizen&#13;
feedback and data regarding institutional response â&#128;&#147; in order to both inform and validate subsequent&#13;
citizen action, and to potentially â&#128;&#152;name and shameâ&#128;&#153; non-performing units with their agency.&#13;
&#13;
&#13;
&#13;
5 In the case of MajiVoice, degrees of responsiveness can be explained by the modality of contracts between government&#13;
  and service providers (renewable upon performance) as well as the creation of an oversight structure to monitor government&#13;
  response. For details, see Belcher and Lopes (2015).&#13;
&#13;
                    EVALUATION TEAM | DEET                                                                                 22&#13;
&amp;#12;                                                                     2016 World Development Report Background Paper&#13;
&#13;
&#13;
III) How can proactive listening systems broader outreach to citizens and project voice more widely?&#13;
&#13;
One of the relevant ï¬&#129;ndings from this review of the evidence is that proactive listening systems are both rel-&#13;
atively rare and yet quite signiï¬&#129;cant. Two of the most well known cases of ICT enabled citizen voiceâ&#128;&#148;Punjab&#13;
Feedback (which has the most uptake of any cases by far) and U-Reportersâ&#128;&#148;involve proactive listening.&#13;
Yet the evidence available indicates that neither of these platforms has triggered high levels of institutional&#13;
response. While proactive listening in the Punjab Feedback case involves signiï¬&#129;cant willingness by senior&#13;
policymakers to respond to users, their capacity is constrained by both a limited complaint tracking sys-&#13;
temâ&#128;&#148;citizenâ&#128;&#153;s that have ï¬&#129;led complaints often have their phone numbers misreportedâ&#128;&#148; and limited lever-&#13;
age over civil service employeesâ&#128;&#148;their ability to sanction is limited by civil service rules. Indeed, the fact&#13;
that user feedback is not made public could be interpreted as an indicator of the fragility of the systemâ&#128;&#153;s&#13;
constituency within the government. Unlike the Punjab Feedback project, use of the U-Reporter system&#13;
is not limited to users of basic services and its reporting bias towards urban, male, well-educated citizens&#13;
suggests that its voice may not entirely representative of citizens. The most clear-cut case of a proactive lis-&#13;
tening system with high levels of uptake and institutional response is the Dominican electricity system. This&#13;
uneven pattern of uptake and responsiveness in such a diverse set of proactive listening cases suggests&#13;
that more institutional experimentation and innovation is needed, with a strong emphasis on connecting&#13;
the dots between incentives for citizens to express voice and the capacity of service providers to respond.&#13;
&#13;
&#13;
IV) How can lessons from uptake of non-dedicated social media be applied to ICT-enabled&#13;
service delivery platforms?&#13;
&#13;
The majority of cases where social media has enabled collective action concerned broad issues of civic&#13;
concern, like corruption or authoritarian abuse, rather than speciï¬&#129;c service delivery issues. Moreover, these&#13;
viral processes have been enabled by open, multi-purpose social media, rather than through dedicated,&#13;
service-speciï¬&#129;c ICT platforms. The contrast between the track record of ICT-enabled civic engagement&#13;
platforms dedicated to service delivery agencies, and that of much broader non-dedicated social media&#13;
platforms, suggests that some of the lessons from the latter could be applied to the former. Crowdsourcing&#13;
public grievances could, in principle, publicly legitimate citizen service delivery concerns, identify problem&#13;
hotspots, and enable coordination for collective action to encourage service provider responsiveness. Yet,&#13;
in practice, the evidence (especially from CSO-led, crowdsourced citizen feedback platforms) suggests&#13;
that this has actually happened far less often than one might hypothesize.&#13;
&#13;
&#13;
V) How can society-facing â&#128;&#156;targeted transparencyâ&#128;&#157; find synergy with government-facing&#13;
â&#128;&#156;targeted citizen feedback,â&#128;&#157; to stimulate virtuous circles of mutually-reinforcing voice and teeth?&#13;
&#13;
Intuitively, one would expect citizens to be more likely to report problems with service delivery to providers if&#13;
they have reason to believe that those service providers are likely to respond to that feedback. Conversely,&#13;
non-responsiveness is likely to discourage citizen reports.6 This suggests the potential for encouraging vir-&#13;
tuous circles of increased citizen reporting as agenciesâ&#128;&#153; capacity to respond grows. It also underscores one&#13;
&#13;
&#13;
6 For empirical evidence of the effect of government responsiveness on levels of citizen participation, see Sjoberg et al. (2015).&#13;
&#13;
&#13;
                     EVALUATION TEAM | DEET                                                                                     23&#13;
&amp;#12;                                                          2016 World Development Report Background Paper&#13;
&#13;
&#13;
of the lessons from research on â&#128;&#156;targeted transparency,â&#128;&#157; which emphasizes the importance of embedding&#13;
information disclosure and access in potential usersâ&#128;&#153; everyday routines, in order to inform decision-making&#13;
and potential collective action (Fung, Graham &amp; Weil 2007). Yet, the limited institutional responsiveness&#13;
achieved thus far by ICT-enabled citizen voice platforms suggests that perhaps the concept of embedded&#13;
feedback should also be applied at the governmental â&#128;&#156;receiving end.â&#128;&#157; Indeed, while â&#128;&#156;targeted transparen-&#13;
cyâ&#128;&#157; usually refers to disclosure of relevant information to citizens, perhaps â&#128;&#156;targeted citizen feedbackâ&#128;&#157; is&#13;
needed to help deliver information to government program managers in ways that embed it in ofï¬&#129;cial deci-&#13;
sion-making processes (as in the case of MajiVoice, where citizen complaints are immediately attached to&#13;
government work orders that can be tracked through the system).&#13;
&#13;
&#13;
&#13;
Final proposition for discussion&#13;
To conclude, the empirical evidence available so far about the degree to which voice can trigger teeth in-&#13;
dicates that service delivery user feedback has so far been most relevant where it increases the capacity&#13;
of policymakers and senior managers to respond. It appears that dedicated ICT-enabled voice platforms&#13;
â&#128;&#147; with a few exceptions â&#128;&#147; have yet to inï¬&#130;uence their willingness. Where senior managers are already com-&#13;
mitted to learning from feedback and using it to bolster their capacity to get agencies to respond, ICT plat-&#13;
forms can make a big difference. In that sense, ICT can make a technical contribution to a policy problem&#13;
that to some degree has already been addressed.&#13;
&#13;
In summary, ICT platforms can bolster upwards accountability if they link citizen voice to policymaker capacity&#13;
to see and respond to service delivery problems. This matters when policymakers already care. Where the&#13;
challenge is how to get policymakers to care in the ï¬&#129;rst place, then the question is how ICT platforms can&#13;
bolster downwards accountability by enabling the collective action needed to give citizen voice some bite.&#13;
&#13;
&#13;
&#13;
&#13;
                 EVALUATION TEAM | DEET                                                                     24&#13;
&amp;#12;                                                                   2016 World Development Report Background Paper&#13;
&#13;
&#13;
References&#13;
Bayern, J. (2015) Investigating the Impact of Open Data Initiatives: The Cases of Kenya, Uganda and the Philippines,&#13;
Washington: World Bank, January&#13;
Bayern, J. (2015), Citizen Feedback Survey Report, Washington: World Bank, January&#13;
Berdou, E. and Abreu-Lopes, C. (2016) The case of UNICEFâ&#128;&#153;s U-report (Uganda): Final Report to the Evaluation&#13;
Framework for Digital Citizen Engagement, Digital Engagement Evaluation Team document, World Bank&#13;
Belcher, M. and Abreu-Lopes, C. (2016) MajiVoice Kenya: Better Complaint Management at Public Utilities, forthcoming&#13;
Digital Engagement Evaluation Team document, Washington: World Bank&#13;
Bhatti, Z.K., Zall Kuseck, J. and Verheijen, T. (2015) Logged On: Smart Government Solutions from South Asia,&#13;
Washington: World Bank&#13;
Bott, M., &amp; Young, G. (2012). The Role of Crowdsourcing for Better Governance in International Development, Praxis:&#13;
The Fletcher Journal of Human Security 2(1), 47-70&#13;
Brockmyer, B. and Fox, J. (2015) Assessing the Evidence: The Effectiveness and Impact of Public Governance-Oriented&#13;
Multi-Stakeholder Initiatives, London: Transparency and Accountability Initiative, http://www.transparency-initiative.&#13;
org/reports/assessing-the-evidence-the-effectiveness-and-impact-of-public-governance-oriented-multi-stakeholder-&#13;
initiatives (accessed 6 October 2015)&#13;
Carothers, T. and Brechenmacher, S. (2014) Accountability, Transparency, Participation and Inclusion: A New&#13;
Development Consensus? Washington: Carnegie Endowment for International Peace, http://carnegieendowment.org/&#13;
ï¬&#129;les/new_development_consensus.pdf (accessed 6 October 2015)&#13;
Cornwall, A. (2002) Beneï¬&#129;ciary, Consumer, Citizen: Perspectives on Participation for Poverty Reduction, SIDA Studies&#13;
No. 2, Stockholm: Swedish International Development Agency&#13;
Dhiratara, A. and M. M. Gibran Sisunan, LAPOR! Layanan Aspirasi Dan Penguadan Online Rakyat, presentation, n.d.&#13;
Diecker, J. and M. Galan (2014) â&#128;&#156;â&#128;&#153;Creatingâ&#128;&#153; a Public Sphere in Cyberspace: The Case of the EU,â&#128;&#157; in Carayannis, E.G., Campbell,&#13;
D.F. and Efthymiopoulos M.P . (eds) Cyber-Development, Cyber-Democracy and Cyber-Defense, New York: Springer&#13;
Downs, A. (1957) An Economic Theory of Democracy New York: Harper and Row&#13;
Fox, J. (2007) The Uncertain Relationship between Transparency and Accountability, Development in Practice, 17(4), 663-671&#13;
Fox, J. (2014) Social Accountability: What does the Evidence Really Say? GPSA Working Paper No. 1, Washington:&#13;
World Bank Global Partnership for Social Accountability programme&#13;
Fung, A., Graham, M. and Weil, D. (2008) Full Disclosure: The Perils and Promise of Transparency, Cambridge:&#13;
Cambridge University Press&#13;
Fung, A., Gilman, H.R. and Shkabatur, J. (2013) Six Models for the Internet + Politics, International Studies Review&#13;
15(1), 30-47, doi:10.1111/misr.12028&#13;
Gaventa, J. and McGee, R. (2013) The Impact of Transparency and Accountability Initiatives, Development Policy&#13;
Review 31(S1) s3-s28&#13;
Georgieva Andonovska, E. (2014), The Karnataka Beneï¬&#129;ciary Veriï¬&#129;cation System (BVS) â&#128;&#147; A Case Study. World Bank, December&#13;
Gigler, S. and Bailur, S. (eds) (2014) Closing the Feedback Loop: Can Technology Close the Accountability Gap?&#13;
Washington: World Bank&#13;
Grandvoinnet, H., Aslam, G. and Raha, S. (2015) Opening the Black Box: Conceptual Drives of Social Accountability&#13;
Effectiveness, Washington: World Bank&#13;
Haikin, M.(2015). Impact of Online Voting on Participatory Budgeting in Brazil, Digital Engagement Evaluation Team, World Bank.&#13;
Joshi, A. (2014). Reading the Local Context: A Causal Chain Approach to Social Accountability, IDS Bulletin 45(5), 23-35&#13;
&#13;
&#13;
                    EVALUATION TEAM | DEET                                                                                  25&#13;
&amp;#12;                                                                      2016 World Development Report Background Paper&#13;
&#13;
&#13;
Kalla, J., Mellon, J., Peixoto, T., Sjoberg, T. (2015) The Crowd Never Lies? Evaluating the Quality of Crowd-Sourced&#13;
Data in Uganda, Digital Engagement Evaluation Team, World Bank&#13;
LAPOR (2014). Facts Sheet, Jakarta: LAPOR&#13;
Lee, P., &amp; Schaefer, M. (2014). Making Mobile Feedback Programs Work: Lessons from Designing an ICT Tool with&#13;
Local Communities, Washington: World Bank&#13;
Lieberman, E., Posner, D. and Tsai, L. (2014) Does Information Lead to More Active Citizenship? Evidence from an&#13;
Education Intervention in Rural Kenya, World Development 60(1), 69-83&#13;
Lindstedt, C., &amp; Naurin, D. (2010). Transparency is Not Enough: Making Transparency Effective in Reducing Corruption,&#13;
International Political Science Review, 31(3), 301-322.&#13;
Lohmann, S. (2000). Collective Action Cascades: An Informational Rationale for the Power in Numbers. Journal of&#13;
Economic Surveys, 14(5), 655-684&#13;
Madon, S. (2014) â&#128;&#156;Information Tools for Improving Accountability in Primary Health Care: Learning from the Case of&#13;
Karnatakaâ&#128;&#157; in S. Gigler and S. Bailur (Eds.) (2014) Closing the Feedback Loop: Can Technology Close the Accountability&#13;
Gap? Washington: World Bank&#13;
Masud, M.O. (2015) Calling Citizens, Improving the State: Pakistanâ&#128;&#153;s Citizen Feedback Monitoring Program, 2008â&#128;&#147;&#13;
2014, Princeton University, Innovations for Successful Societies http://successfulsocieties.princeton.edu/publications/&#13;
calling-public-empower-state-pakistan (accessed 13 October 2015)&#13;
Mellon, J., Peixoto, T. and Sjoberg, T. (2015) The Crowd Never Lies? Evaluating the Quality of Crowd-Sourced Data in&#13;
Uganda, Digital Engagement Evaluation Team, World Bank, unpublished&#13;
Peixoto, T. (2013) â&#128;&#156;The Uncertain Relationship Between Open Data and Accountability: A Response to Yu and Robinsonâ&#128;&#153;s&#13;
â&#128;&#152;The New Ambiguity of â&#128;&#156;Open Government,â&#128;&#153;â&#128;&#157; UCLA Law Review Discourse 60, 200-248&#13;
Prieto-MartÃ­n, P., de Marcos, L. and MartÃ­nez, J.J. (2011) The e-(R) evolution Will Not Be Funded, European Journal of ePractice 15.&#13;
Ranganathan, M. (2012) â&#128;&#156;Reengineering Citizenship: Municipal Reforms and the Politics of â&#128;&#152;e- Grievance Redressalâ&#128;&#153; in&#13;
Karnatakaâ&#128;&#153;s Cities,â&#128;&#157; in Desai, R and Sanyal, R. (eds) Urbanizing Citizenship: Contested Spaces in Indian Cities, Sage:&#13;
Thousand Oaks and New Delhi&#13;
Sjoberg, J. Mellon, T. Peixoto (2015) The Effect of Government Responsiveness on Future Political Participation, Digital&#13;
Engagement Evaluation Team Working Paper 1. World Bank.&#13;
Spada, P., Mellon J., Peixoto, T. and Sjoberg, F.M. (2015) Effects of the Internet on Participation: Study of a Public Policy&#13;
Referendum in Brazil, World Bank Policy Research Working Paper 7204, Washington: World Bank&#13;
Susha, I. and GrÃ¶nlund, Ã&#133;. (2014) Context Clues for the Stall of the Citizensâ&#128;&#153; Initiative: Lessons for Opening Up&#13;
E-participation Development Practice, Government Information Quarterly, 31(3), 454 465&#13;
UNICEF (2012) U-report Application Revolutionizes Social Mobilization, Empowering Ugandan Youth,&#13;
http://www.unicef.org/infobycountry/uganda_62001.html (accessed 13 October 2015)&#13;
World Bank (2014a) Strategic Framework for Mainstreaming Citizen Engagement in World Bank Group Operations,&#13;
Washington, DC: World Bank. https://openknowledge.worldbank.org/handle/10986/21113 (accessed 13 October 2015)&#13;
World Bank (2014b) Survey Report: Citizen Feedback Monitoring Program, Washington: World Bank&#13;
World Bank (2015) â&#128;&#152;Digital Analysisâ&#128;&#153;, conducted by the World Bankâ&#128;&#153;s Digital Evaluation Team, unpublished&#13;
&#13;
&#13;
&#13;
&#13;
                     EVALUATION TEAM | DEET                                                                                      26&#13;
&amp;#12;</ml:original-txt><ml:search-metadata><doc id="25857860">
        <url>
            http://documents.worldbank.org/curated/en/2016/02/25857860/ict-enabled-citizen-voice-lead-government-responsiveness-digital-dividends-background-paper
        </url>
        <availablein>English</availablein>
        <url_friendly_title>http://documents.worldbank.org/curated/en/2016/02/25857860/ict-enabled-citizen-voice-lead-government-responsiveness-digital-dividends-background-paper</url_friendly_title>
        <new_url>2016/02/25857860/ict-enabled-citizen-voice-lead-government-responsiveness-digital-dividends-background-paper</new_url>
        <disclosure_date>2016-02-02T00:00:00Z</disclosure_date>
        <disclosure_type>NA</disclosure_type>
        <ext_pub_date>2016-02-02T00:00:00Z</ext_pub_date>
        <disclstat>Disclosed</disclstat>
        <docm_id>090224b08412c717</docm_id>
        <chronical_docm_id>090224b08412c717</chronical_docm_id>
        <txturl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2016/02/02/090224b08412c717/1_0/Rendered/INDEX/When0does0ICT00s000background0paper.txt</txturl>
        <pdfurl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2016/02/02/090224b08412c717/1_0/Rendered/PDF/When0does0ICT00s000background0paper.pdf</pdfurl>
        <datestored>2016-02-02T00:00:00Z</datestored>
        <docdt>2016-01-01T00:42:04Z</docdt>
        <totvolnb>1</totvolnb>
        <versiontyp>Final</versiontyp>
        <versiontyp_key>1309935</versiontyp_key>
        <volnb>1</volnb>
        <repnme>
            When does ICT-enabled citizen voice lead to
            government responsiveness? Digital dividends : background paper
        </repnme>
        <abstracts>
            This paper reviews evidence on the use
            of 23 information and communication technology (ICT)
            platforms to project citizen voice to improve public service
            delivery. This meta-analysis focuses on empirical studies of
            initiatives in the global South, highlighting both citizen
            uptake (‘yelp’) and the degree to which public service
            providers respond to expressions of citizen voice (‘teeth’).
            The conceptual framework further distinguishes between two
            trajectories for ICT-enabled citizen voice: Upwards
            accountability occurs when users provide feedback directly
            to decision-makers in real time, allowing policy-makers and
            program managers to identify and address service delivery
            problems, but at their discretion. Downwards accountability,
            in contrast, occurs either through real time user feedback
            or less immediate forms of collective civic action that
            publicly call on service providers to become more
            accountable and depends less exclusively on decision-makers’
            discretion about whether or not to act on the information
            provided. This distinction between the ways in which ICT
            platforms mediate the relationship between citizens and
            service providers allows for a precise analytical focus on
            how different dimensions of such platforms contribute to
            public sector responsiveness. These cases suggest that while
            ICT platforms have been relevant in increasing policymakers’
            and senior managers’ capacity to respond, most of them have
            yet to influence their willingness to do so.
        </abstracts>
        <docna>
            When does ICT-enabled citizen voice lead to
            government responsiveness? Digital dividends : background paper
        </docna>
        <display_title>When does ICT-enabled citizen
            voice lead to government responsiveness? Digital dividends :
            background paper</display_title>
        <listing_relative_url>/research/2016/01/25857860/ict-enabled-citizen-voice-lead-government-responsiveness-digital-dividends-background-paper</listing_relative_url>
        <topic>ICT Data Monitoring m1326604 2355,ICT Infrastructure m1326395 667,ICT Applications m1327329 652</topic>
        <subtopic>E-Business,Public Sector Corruption &amp;
            Anticorruption Measures,E-Government,Information and Communication Technologies</subtopic>
        <docty>World Development Report</docty>
        <teratopic>Governance,Private Sector Development,Public Sector Development</teratopic>
        <count>World</count>
        <authors>
            <author>Peixoto,Tiago Carneiro</author>
            <author>Fox, Jonathan</author>
        </authors>
        <entityids>
            <entityid>090224b08412c717_1_0</entityid>
        </entityids>
        <admreg>The World Region,The World Region</admreg>
        <colti>World Development Report</colti>
        <lang>English</lang>
        <historic_topic>Governance,Private Sector Development,Public Sector Development</historic_topic>
        <topicv3>ICT Data Monitoring m1326604 2355,ICT Infrastructure m1326395 667,ICT Applications m1327329 652</topicv3>
        <majdocty>Publications,Publications &amp; Research</majdocty>
        <keywd>
            newsletters, e-mail, basic services, public
            utilities, quality of services, phone numbers, customer,
            informal relationships, politics, abuse, civil servants,
            bribes, information and communication technology, policy
            framework, interfaces, government, information, services,
            monitoring, sanctions, transmission, conceptual model,
            real-time data, corruption, disclosure, repairs,
            e-government, access to education, educated citizens, link,
            data, information communication technology, document, cell
            phone, citizen participation, civil society, democracy,
            initiative, user information, articles, cases, e-government
            initiatives, organizations, civil society organization,
            service provider, web, links, service provision, civic
            engagement, digital technologies, research, medium,
            standards, data analysis, service delivery, information
            communication, radio, access to information, users, reading,
            phone, technology, transaction, availability of data,
            initiatives, user satisfaction, broadcast, accountability,
            municipal government, government agency, transparency,
            discretion, legibility, open government, state government,
            results, description, bank, electricity, bribe,
            arrangements, accessibility, government employees, online
            petition, online form, researchers, citizen usage, social
            science, participatory process, sanction, online voting,
            benchmark, citizen engagement, policy, case, internet,
            media, governance, tracking systems, concept, public
            transparency, ict, security, complaints, citizen use, user
            feedback, network, phones, id, organization, common
            denominator, performance, government service, complaint,
            innovation, institution, law, mobile phones, governance
            reform, website, communication, ids, tracking system,
            cyberspace, customers, interface, public accountability,
            communication technology, technologies, governments, target,
            service, innovations, user, service providers
        </keywd>
        <owner>Development Data Group (DECDG)</owner>
        <repnb>102967</repnb>
    </doc></ml:search-metadata><ml:annotations><ml:concepts><ml:concept>ICT</ml:concept><ml:concept>ICT for Development</ml:concept><ml:concept>Information Technology</ml:concept><ml:concept>Information and Communication Technologies (ICT)</ml:concept><ml:concept>Social Development &amp; Poverty</ml:concept><ml:concept>Water Resources</ml:concept><ml:concept>Finance and Development</ml:concept><ml:concept>Finance and Financial Sector Development</ml:concept><ml:concept>Teaching and Learning</ml:concept><ml:concept>Environment</ml:concept><ml:concept>General Public Administration Sector</ml:concept><ml:concept>Governance and Public Sector Management</ml:concept><ml:concept>Government</ml:concept><ml:concept>Institutions</ml:concept><ml:concept>Public Administration</ml:concept><ml:concept>Public Sector Development</ml:concept><ml:concept>Public Sector Management and Reform</ml:concept><ml:concept>Public Sector and Governance</ml:concept><ml:concept>Social Protections and Labor</ml:concept><ml:concept>City Development Strategies</ml:concept><ml:concept>Information and Communication Technologies</ml:concept><ml:concept>Social Development</ml:concept><ml:concept>Water</ml:concept><ml:concept>Financial Sector Development</ml:concept><ml:concept>Private Sector Development</ml:concept><ml:concept>Arts and Culture</ml:concept><ml:concept>Education</ml:concept><ml:concept>Environment and Natural Resources</ml:concept><ml:concept>Health, Nutrition and Population</ml:concept><ml:concept>Public Sector Management</ml:concept><ml:concept>Social Protection and Labor</ml:concept><ml:concept>Urban Development</ml:concept><ml:concept>Generic Name List</ml:concept><ml:concept>Generics</ml:concept><ml:concept>List of Generic Drugs</ml:concept><ml:concept>Off patent drugs</ml:concept><ml:concept>Urban Infrastructure (Water and Wastewater)</ml:concept><ml:concept>Urban Water and Small Town Water</ml:concept><ml:concept>Access to Basic Sanitation</ml:concept><ml:concept>On-site Sanitation</ml:concept><ml:concept>Sanitation Marketing</ml:concept><ml:concept>Sanitation Promotion</ml:concept><ml:concept>Access to Information</ml:concept><ml:concept>Freedom of Information</ml:concept><ml:concept>Medium Term Expenditure Frameworks (MTEF)</ml:concept><ml:concept>Participatory Budgeting</ml:concept><ml:concept>Performance Budgeting</ml:concept><ml:concept>Program Budgeting</ml:concept><ml:concept>Spending Reviews</ml:concept><ml:concept>E-Government</ml:concept><ml:concept>ICT and Public Administration</ml:concept><ml:concept>eGovernment</ml:concept><ml:concept>Open Data</ml:concept><ml:concept>Open Government Data</ml:concept><ml:concept>Analysis &amp; Monitoring</ml:concept><ml:concept>Delivery Units</ml:concept><ml:concept>Grievance Redress</ml:concept><ml:concept>Indicators</ml:concept><ml:concept>M&amp;E</ml:concept><ml:concept>Performance Measurement</ml:concept><ml:concept>Performance Reviews</ml:concept><ml:concept>Rapid Results Approaches</ml:concept><ml:concept>Alternative Service Delivery</ml:concept><ml:concept>Arms Length Agencies</ml:concept><ml:concept>Citizen Mapping</ml:concept><ml:concept>Contracting Out</ml:concept><ml:concept>Delivery Chains</ml:concept><ml:concept>Service Delivery Arrangements</ml:concept><ml:concept>Service Standards, Service Fees</ml:concept><ml:concept>Participation, Empowerment and Accountability</ml:concept><ml:concept>Social Accountability and Demand for Good Governance</ml:concept><ml:concept>Governance and Public Accountability (GPA)</ml:concept><ml:concept>Incentives for Good Government</ml:concept><ml:concept>National Governance</ml:concept><ml:concept>Demand for Good Governance</ml:concept><ml:concept>Open Government, Accountability and Transparency</ml:concept><ml:concept>Social Accountability</ml:concept><ml:concept>Checks on Executive Power</ml:concept><ml:concept>Citizen Oversight</ml:concept><ml:concept>Citizen User Satisfaction Survey</ml:concept><ml:concept>Independent Commissions</ml:concept><ml:concept>Ombudsmen</ml:concept><ml:concept>Oversight</ml:concept><ml:concept>Parliament</ml:concept><ml:concept>Procurement Complaints Review Institutions</ml:concept><ml:concept>Supreme Audit Institutions</ml:concept><ml:concept>Civil Society</ml:concept><ml:concept>Banking</ml:concept><ml:concept>Media</ml:concept><ml:concept>Generic Drugs</ml:concept><ml:concept>Urban Water</ml:concept><ml:concept>Teacher Absenteeism</ml:concept><ml:concept>Policy Framework</ml:concept><ml:concept>Women</ml:concept><ml:concept>Sanitation</ml:concept><ml:concept>Right to Information</ml:concept><ml:concept>Budget Preparation and Management Techniques</ml:concept><ml:concept>Crowdsourcing</ml:concept><ml:concept>Social Media</ml:concept><ml:concept>Digital Government</ml:concept><ml:concept>Open Data Policy</ml:concept><ml:concept>Monitoring and Evaluation</ml:concept><ml:concept>Public Service Delivery</ml:concept><ml:concept>Governance</ml:concept><ml:concept>Open Government and Transparency</ml:concept><ml:concept>Public Accountability Mechanisms</ml:concept></ml:concepts><ml:geo-regions/></ml:annotations></ml:doc-envelope>