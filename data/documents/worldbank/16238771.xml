<?xml version="1.0" encoding="UTF-8"?><ml:doc-envelope xmlns:ml="http://marklogic.com/poolparty/worldbank"><ml:original-txt>ï»¿                                                                      68235&#13;
 S A B E R â&#128;&#147; S Y S T E M S A P P R O A C H F O R B E T T E R E D U C AT I O N R E S U LT S&#13;
&#13;
                                                          STUDENT ASSESSMENT&#13;
                                                                                             1&#13;
&#13;
&#13;
&#13;
&#13;
      What Matters&#13;
    Most for Student&#13;
Assessment Systems:&#13;
 A Framework Paper&#13;
                                                 Marguerite Clarke&#13;
&amp;#12;&amp;#12;               WORKING PAPER NO. 1&#13;
&#13;
&#13;
&#13;
&#13;
      What Matters Most for&#13;
Student Assessment Systems:&#13;
         A Framework Paper&#13;
                    Marguerite Clarke&#13;
&amp;#12;Â© 2012 The International Bank for Reconstruction and Development / The World Bank&#13;
1818 H Street NW&#13;
Washington DC 20433&#13;
Telephone: 202 473 1000&#13;
Internet: www.worldbank.org&#13;
&#13;
1234    15 14 13 12&#13;
&#13;
This work is a product of the staff of The World Bank with external contributions. The findings,&#13;
interpretations, and conclusions expressed in this work do not necessarily reflect the views of&#13;
The World Bank, its Board of Executive Directors, or the governments they represent.&#13;
    The World Bank does not guarantee the accuracy of the data included in this work. The&#13;
boundaries, colors, denominations, and other information shown on any map in this work do&#13;
not imply any judgment on the part of The World Bank concerning the legal status of any&#13;
territory or the endorsement or acceptance of such boundaries.&#13;
&#13;
Rights and Permissions&#13;
The material in this work is subject to copyright. Because The World Bank encourages&#13;
dissemination of its knowledge, this work may be reproduced, in whole or in part, for&#13;
noncommercial purposes as long as full attribution to this work is given.&#13;
    Any queries on rights and licenses, including subsidiary rights, should be addressed to the&#13;
Office of the Publisher, The World Bank, 1818 H Street NW, Washington, DC 20433, USA; fax:&#13;
202 522 2422; e mail: pubrights@worldbank.org.&#13;
&#13;
Cover design: Patricia Hord.Graphik Design, Alexandria, VA&#13;
&amp;#12;Contents&#13;
About the Series ...............................................................................................................v&#13;
About the Author.......................................................................................................... vii&#13;
Acknowledgments ..........................................................................................................ix&#13;
Abstract ............................................................................................................................xi&#13;
Introduction ......................................................................................................................1&#13;
Theory and Evidence on Student Assessment.............................................................3&#13;
Framework for Student Assessment Systems..............................................................6&#13;
Fleshing out the Framework......................................................................................... 12&#13;
Levels of Development.................................................................................................. 14&#13;
Conclusions..................................................................................................................... 18&#13;
Appendix 1. Assessment Types and Their Key Differences .................................... 19&#13;
Appendix 2. Rubrics for Judging the Development Level of Different&#13;
    Assessment Types ................................................................................................... 20&#13;
Appendix 3. Example of Using the Rubrics to Evaluate a National Large&#13;
    Scale Assessment Program..................................................................................... 32&#13;
References ....................................................................................................................... 37&#13;
&#13;
Tables&#13;
Table 1. Framework for Building a More Effective Student Assessment&#13;
    System...................................................................................................................... 12&#13;
Table 2. Framework for Building a More Effective Student Assessment&#13;
    System, with Broad Indicator Areas.................................................................... 13&#13;
Table 3. Basic Structure of Rubrics for Evaluating Data Collected on a&#13;
    Student Assessment System ................................................................................. 14&#13;
Table 4. Stylized Profiles of Student Assessment Systems at Different Levels&#13;
    of Development ...................................................................................................... 16&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                                       iii&#13;
&amp;#12;&amp;#12;About the Series&#13;
Building strong education systems that promote learning is fundamental to&#13;
development and economic growth. Over the past few years, as developing&#13;
countries have succeeded in building more classrooms, and getting millions&#13;
more children into school, the education community has begun to actively&#13;
embrace the vision of measurable learning for all children in school. However,&#13;
learning depends not only on resources invested in the school system, but also&#13;
on the quality of the policies and institutions that enable their use and on how&#13;
well the policies are implemented.&#13;
     In 2011, the World Bank Group launched Education Sector Strategy 2020:&#13;
Learning for All, which outlines an agenda for achieving â&#128;&#156;Learning for Allâ&#128;? in&#13;
the developing world over the next decade. To support implementation of the&#13;
strategy, the World Bank commenced a multi year program to support countries&#13;
in systematically examining and strengthening the performance of their&#13;
education systems. This evidence based initiative, called SABER (Systems&#13;
Approach for Better Education Results), is building a toolkit of diagnostics for&#13;
examining education systems and their component policy domains against&#13;
global standards, best practices, and in comparison with the policies and&#13;
practices of countries around the world. By leveraging this global knowledge,&#13;
SABER fills a gap in the availability of data and evidence on what matters most&#13;
to improve the quality of education and achievement of better results.&#13;
     SABER Student Assessment, one of the systems examined within the SABER&#13;
program, has developed tools to analyze and benchmark student assessment&#13;
policies and systems around the world, with the goal of promoting stronger&#13;
assessment systems that contribute to improved education quality and learning&#13;
for all. To help explore the state of knowledge in the area, the SABER Student&#13;
Assessment team invited leading academics, assessment experts, and&#13;
practitioners from developing and industrialized countries to come together to&#13;
discuss assessment issues relevant for improving education quality and learning&#13;
outcomes. The papers and case studies on student assessment in this series are&#13;
the result of those conversations and the underlying research. Prior to&#13;
publication, all of the papers benefited from a rigorous review process, which&#13;
included comments from World Bank staff, academics, development&#13;
practitioners, and country assessment experts.&#13;
     All SABER Student Assessment papers in this series were made possible by&#13;
support from the Russia Education Aid for Development Trust Fund (READ TF).&#13;
READ TF is a collaboration between the Russian Federation and the World Bank&#13;
that supports the improvement of student learning outcomes in low income&#13;
countries through the development of robust student assessment systems.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                v&#13;
&amp;#12;          The SABER working paper series was produced under the general guidance&#13;
     of Elizabeth King, Education Director, and Robin Horn, Education Manager in&#13;
     the Human Development Network of the World Bank. The Student Assessment&#13;
     papers in the series were produced under the technical leadership of Marguerite&#13;
     Clarke, Senior Education Specialist and SABER Student Assessment Team&#13;
     Coordinator in the Human Development Network of the World Bank. Papers in&#13;
     this series represent the independent views of the authors.&#13;
&#13;
&#13;
&#13;
&#13;
vi                                                                   Marguerite Clarke&#13;
&amp;#12;About the Author&#13;
Marguerite Clarke is a Senior Education Specialist in the Human Development&#13;
Network at the World Bank. She leads the Bankâ&#128;&#153;s work on learning assessment,&#13;
including providing support to individual countries to improve their assessment&#13;
activities and uses of assessment information, and heading the global work&#13;
program on student assessment under the Russia Education Aid for&#13;
Development (READ) Trust Fund program. Under READ, she is responsible for&#13;
developing evidence based tools and approaches for evaluating and&#13;
strengthening the quality of student assessment systems. Prior to joining the&#13;
Bank, Marguerite was involved in research, policy, and practice in the areas of&#13;
higher education teaching and learning, higher education quality, and student&#13;
assessment and testing policy at universities in Australia (University of South&#13;
Australia) and the United States (Brown University, Boston College). She also&#13;
worked as a classroom teacher in the Chinese, Irish, Japanese, and U.S. education&#13;
systems and received a national teaching award from the Irish Department of&#13;
Education in 1989. A former Fulbright Scholar, she received her PhD in&#13;
Educational Research, Measurement, and Evaluation from Boston College (2000)&#13;
and is on the advisory board of the UNESCO Institute for Statistics Observatory&#13;
for Learning Outcomes.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                 vii&#13;
&amp;#12;&amp;#12;Acknowledgments&#13;
Many people provided inputs and suggestions for this paper. Thanks in&#13;
particular go to the peer reviewers and meeting chairs: Luis Benveniste, Luis&#13;
Crouch, Deon Filmer, Robin Horn, Elizabeth King, Marlaine Lockheed, Harry&#13;
Patrinos, and Alberto Rodriguez. I am also grateful to the READ Trust Fund&#13;
team, particularly Julia Liberman and MarÃ­a JosÃ© RamÃ­rez, who provided&#13;
valuable support in developing a set of rubrics and questionnaires based on this&#13;
framework paper, as well as Olav Christensen, Emily Gardner, Manorama Gotur,&#13;
Emine Kildirgici, Diana Manevskaya, Cassia Miranda, and Fahma Nur. Thanks&#13;
also to READ Technical Group members, past and present, including Luis&#13;
Benveniste, Cedric Croft, Amber Gove, Vincent Greaney, Anil Kanjee, Thomas&#13;
Kellaghan, Marina Kuznetsova, MarÃ­a JosÃ© RamÃ­rez, and Yulia Tumeneva, as&#13;
well as to the Task Team Leaders and teams in the READ countries. Others who&#13;
provided helpful insights and suggestions along the way include Patricia&#13;
Arregui, Felipe Barrera, Viktor Bolotov, Lester Flockton, Alejandro Ganimian,&#13;
Juliana Guaqueta, Gabrielle Matters, Emilio Porta, Halsey Rogers, Alan Ruby,&#13;
Jee Peng Tan, Igor Valdman, and Emiliana Vegas. Special thanks to the Russian&#13;
government for their support for this work under the READ Trust Fund&#13;
program.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                ix&#13;
&amp;#12;&amp;#12;Abstract&#13;
The purpose of this paper is to provide an overview of what matters most for&#13;
building a more effective student assessment system. The focus is on systems for&#13;
assessing student learning and achievement at the primary and secondary&#13;
levels.1 The paper extracts principles and guidelines from countriesâ&#128;&#153; experiences,&#13;
professional testing standards, and the current research base. The goal is to&#13;
provide national policy makers, education ministry officials, development&#13;
organization staff, and other stakeholders with a framework and key indicators for&#13;
diagnosis, discussion, and consensus building around how to construct a sound and&#13;
sustainable student assessment system that will support improved education quality and&#13;
learning for all.&#13;
&#13;
&#13;
&#13;
&#13;
1 This paper does not discuss psychological or workplace testing; nor does it explicitly discuss&#13;
assessment of student learning and achievement at the tertiary level, although many of the&#13;
issues raised also apply to that level of schooling.&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                xi&#13;
&amp;#12;&amp;#12;What Matters Most for&#13;
Student Assessment Systems:&#13;
A Framework Paper&#13;
Marguerite Clarke&#13;
&#13;
&#13;
        â&#128;&#156;[Assessment] goes to the heart of what matters in education: not just&#13;
        enrollment and completion rates, but the ultimate goal of student&#13;
        learningâ&#128;? (World Bank, 2010, p. 5).&#13;
&#13;
&#13;
Introduction&#13;
Assessment is the process2 of gathering and evaluating information on what&#13;
students know, understand, and can do in order to make an informed decision&#13;
about next steps in the educational process. Methods can be as simple as oral&#13;
questioning and response (for example, â&#128;&#156;What is the capital of Ethiopia?â&#128;?) or as&#13;
complex as computer adaptive testing models based on multifaceted scoring&#13;
algorithms and learning progressions.3 Decisions based on the results may vary&#13;
from how to design system wide programs to improve teaching and learning in&#13;
schools, to identifying next steps in classroom instruction, to determining which&#13;
applicants should be admitted to university.&#13;
     An assessment system is a group of policies, structures, practices, and tools for&#13;
generating and using information on student learning and achievement. Effective&#13;
assessment systems are those that provide information of sufficient quality and&#13;
quantity to meet stakeholder information and decision making needs in support&#13;
of improved education quality and student learning outcomes (Ravela et al.,&#13;
2009).4 Meeting these information and decision making needs in a way that has&#13;
the support of key political and other groups in society will contribute to the&#13;
longer term sustainability and effectiveness of the assessment system.&#13;
     Governments, international organizations, and other stakeholders are&#13;
increasingly recognizing the importance of assessment for monitoring and&#13;
&#13;
&#13;
2 When used as a noun, assessment may refer to a particular tool, such as a test.&#13;
3 A list of computer adaptive testing programs can be found at http://www.psych.umn.edu/&#13;
psylabs/catcentral/.&#13;
4 A student assessment system supports a variety of information needs, such as informing&#13;
&#13;
learning and instruction, determining progress, measuring achievement, and providing&#13;
partial accountability information. All of these purposes, and the decisions based on them,&#13;
should ultimately lead to improved quality and learning levels in the education system.&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                           1&#13;
&amp;#12;    improving student learning and achievement levels, and the concomitant need to&#13;
    develop strong systems for student assessment (IEG, 2006; McKinsey &amp;&#13;
    Company, 2007; UNESCO, 2007). This recognition is linked to growing evidence&#13;
    that many of the benefits of educationâ&#128;&#148;cultural, economic, and socialâ&#128;&#148;accrue to&#13;
    society only when learning occurs (OECD, 2010). For example, an increase of one&#13;
    standard deviation in scores on international assessments of reading and&#13;
    mathematics achievement levels has been linked to a 2 percent increase in annual&#13;
    growth rates of GDP per capita (Hanushek and Woessmann, 2007, 2009).&#13;
         Some people argue that assessments, particularly large scale assessment&#13;
    exercises, are too expensive. In fact, the opposite tends to be true, with testing&#13;
    shown to be among the least expensive innovations in education reform, typically&#13;
    costing far less than increasing teachersâ&#128;&#153; salaries or reducing class size. Hoxby&#13;
    (2002) found that even the most expensive state level, test based accountability&#13;
    programs in the United States cost less than 0.25 percent of per pupil spending.&#13;
    Similarly, in none of the Latin American countries reviewed by Wolff (2007) did&#13;
    testing involve more than 0.3 percent of the national education budget at the&#13;
    level (primary or secondary) tested. While these cost efficiencies are appealing,&#13;
    they should not be allowed to obscure other important factorsâ&#128;&#148;for example,&#13;
    equity and social goalsâ&#128;&#148;that need to be considered in any decision about&#13;
    whether or not to implement a particular assessment program.&#13;
         Over the last 20 years, many countries have started implementing&#13;
    assessment exercises or building on existing assessment systems (UNESCO,&#13;
    2007). In addition, there has been huge growth in the number of countries&#13;
    participating in international comparative assessment exercises such as the&#13;
    Trends in International Mathematics and Science Study (TIMSS) and the&#13;
    Programme for International Student Assessment (PISA).5 Nongovernmental&#13;
    organizations also have increasingly turned to student assessment to draw public&#13;
    attention to poor achievement levels and to create an impetus for change.&#13;
         Despite this interest in student assessment, far too few countries have in&#13;
    place the policies, structures, practices, and tools that constitute an effective&#13;
    assessment system. This is particularly the case for low income countries, which stand&#13;
    to benefit most from systematic efforts to measure learning outcomes. Some of these&#13;
    countries have experimented with large scale or other standardized assessments&#13;
    of student learning and achievement levels, but too often these have been ad hoc&#13;
    experiences that are not part of an education strategy and are not sustained over&#13;
    time. A key difference between one off assessments and a sustained assessment&#13;
    system is that the former only provides a snapshot of student achievement levels&#13;
    while the latter allows for the possibility of monitoring trends in achievement&#13;
&#13;
    5 For example, the number of countries participating in PISA jumped from 43 in 2000 to 66 in&#13;
    2007. A comparatively small number of developing countries have participated in&#13;
    international assessments of student achievement. These countries have consistently&#13;
    performed in the bottom of the distribution, limiting the amount of information they can&#13;
    derive from the data to better understand and improve their own education systems.&#13;
&#13;
&#13;
2                                                                             Marguerite Clarke&#13;
&amp;#12;and learning levels over time (more like a series of photos) and a better&#13;
understanding of the relative contribution of various inputs and educational&#13;
practices to changes in those trends. One off assessments can have shock value&#13;
and create an opening for discussions about education quality, and this can be a&#13;
short term strategy for putting learning on the agenda.6 Ultimately, however,&#13;
governments must deal with the challenging, but necessary, task of putting in&#13;
place systems that allow for regular monitoring of, and support for, student&#13;
learning and achievement. This is the only way to harness the full power of&#13;
assessment.&#13;
&#13;
&#13;
Theory and Evidence on Student Assessment&#13;
A basic premise of the research on student assessment is that the right kinds of&#13;
assessment activities, and the right uses of the data generated by those activities,&#13;
contribute to better outcomes, be those improved learning or improved policy&#13;
decisions (for example, Heubert and Hauser, 1999).7 What constitutes â&#128;&#152;rightâ&#128;&#153; is&#13;
largely driven by a set of theoretical and technical guidelines for test developers&#13;
and users of assessment information (AERA, APA, and NCME, 1999).&#13;
     There also is a sizeable body of empirical research showing the benefits of&#13;
specific types of assessment activities, when implemented and used correctly, on&#13;
student learning. For example, research demonstrates a strong link between&#13;
high quality, formative classroom assessment activities and better student&#13;
learning outcomes as measured by student performance on standardized tests of&#13;
educational achievement. Black and Wiliamâ&#128;&#153;s (1998) synthesis of over 250&#13;
empirical studies from around the world on the impact of high quality,&#13;
formative classroom assessment activities shows student gains of a half to a full&#13;
standard deviation on standardized achievement tests, with the largest gains&#13;
being realized by low achievers.8 Black and Wiliam (1998) conclude:&#13;
&#13;
&#13;
6 One of the more popular of these initiatives is known as EGRA. According to the USAID&#13;
Website (https://www.eddataglobal.org/): â&#128;&#156;The Early Grade Reading Assessment (EGRA) is&#13;
an oral assessment designed to measure the most basic foundation skills for literacy&#13;
acquisition in the early grades â&#128;¦. in order to inform ministries and donors regarding system&#13;
needs for improving instruction.â&#128;?&#13;
7 Ravela et al. (2008) note that student assessment is a necessary, but insufficient, condition for&#13;
&#13;
improving education. There is some evidence that the mere existence and dissemination of&#13;
assessment information has some effect on certain actors. But assessment is only one of&#13;
several key elements of education policy; others include preservice and inservice teacher&#13;
training, teacher working conditions, school management and supervision, curricular design,&#13;
textbooks and educational materials, investment of resources proportional to the needs of&#13;
different populations, and concerted action by those responsible for education to resolve any&#13;
problems uncovered.&#13;
8 Rodriguez (2004) reports effects of similar size in U.S. TIMSS mathematics performance&#13;
&#13;
arising from the effective management of classroom assessment (this finding is based on&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                   3&#13;
&amp;#12;            The gains in achievement appear to be quite considerable,&#13;
            and â&#128;¦ amongst the largest ever reported for educational&#13;
            interventions. As an illustration of just how big these gains are, an&#13;
            effect size of 0.7, if it could be achieved on a nationwide scale,&#13;
            would be equivalent to raising the mathematics attainment score&#13;
            of an â&#128;&#156;averageâ&#128;? country like England, New Zealand or the United&#13;
            States into the â&#128;&#156;top fiveâ&#128;? after the Pacific rim countries of&#13;
            Singapore, Korea, Japan and Hong Kong. (p. 61)&#13;
&#13;
         Bennett (2011), however, notes that more work needs to be done to define&#13;
    and isolate the specific characteristics of formative classroom assessment&#13;
    activities that lead to improved student learning outcomes.9&#13;
         Correlational research on high school or upper secondary exit examinations&#13;
    demonstrates a link between countries that have those policies and higher&#13;
    student performance levels on international assessments, such as PISA or TIMSS&#13;
    (for example, Bishop, Mane and Bishop, 2001). Other studies show a link&#13;
    between specific characteristics of the tests used in these examination programs&#13;
    and student learning outcomes, with curriculum or subject based examinations&#13;
    (as opposed to more general ability or aptitude tests) viewed as most effective in&#13;
    promoting better student learning outcomes (Au, 2007; Hill, 2010).&#13;
         At the same time, these kinds of high stakes examinations have been shown&#13;
    to have a negative impact on students from disadvantaged groups by&#13;
    disproportionately limiting their opportunities to proceed to the next level of the&#13;
    education system or to avail themselves of certain kinds of educational&#13;
    opportunities (Greaney and Kellaghan, 1995; Madaus and Clarke, 2001). Because&#13;
    of these kinds of equity issues, the uses and outcomes of examinations must be&#13;
    carefully monitored at the system, group, and individual levels, and efforts&#13;
    should be made to reduce or mitigate any unintended negative consequences.&#13;
         Results from large scale, system level assessments of overall student&#13;
    achievement levels increasingly provide the foundation for test based&#13;
    accountability programs in many countries. Research shows an overall weak, but&#13;
    positive, link between the uses of data from these assessments to hold schools&#13;
    and educators accountable (through, for example, league tables, monetary&#13;
    rewards, or staffing decisions) and better student learning outcomes (for&#13;
    example, Carnoy and Loeb, 2002). At the same time, findings suggest that simply&#13;
    reporting information about average school scores on these assessments also can&#13;
&#13;
&#13;
    analysis of the responses of teachers from TIMSS participating countries to questions on the&#13;
    topic of management of classroom assessment).&#13;
    9 One meta analysis of 21 controlled studies (Fuchs and Fuchs, 1986) that looked at the&#13;
&#13;
    frequency of classroom assessment activities found that systematic use of formative classroom&#13;
    assessment activitiesâ&#128;&#148;weekly or even more oftenâ&#128;&#148;can have a strong positive effect on&#13;
    student achievement (for example, two assessments per week results in an effect size of 0.85,&#13;
    or a percentile gain of 30 points).&#13;
&#13;
&#13;
4                                                                              Marguerite Clarke&#13;
&amp;#12;lead to increased student performance (Hanushek and Raymond, 2003),&#13;
suggesting that there still is much to learn about the optimal mix of incentives for&#13;
test based accountability models that will produce the best outcomes with the&#13;
fewest negative side effects. To date, research suggests that key determinants of&#13;
whether the effects of test based accountability exercises are more positive than&#13;
negative include the technical quality of the tests themselves, the alignment&#13;
between the test design and the way test results are used, and the extent to which&#13;
supports are in place to help schools or teachers identified as underperforming&#13;
(Ravela, 2005).10&#13;
     Research is increasingly focusing on the characteristics of effective&#13;
assessment systems that encompass the aforementioned types of assessment&#13;
activities and uses (that is, classroom assessment, examinations, and large scale,&#13;
system level assessments). This research draws on principles and best practices in&#13;
the assessment literature as well as analyses of the assessment systems of high&#13;
achieving nations. Darling Hammond and Wentworth (2010) reviewed the&#13;
practices of high performing education systems around the world (for example,&#13;
Australia, Finland, Singapore, Sweden, and the United Kingdom) and noted that&#13;
student assessment activities in these systems:&#13;
     x illustrate the importance of assessment of, for, and as student learning,&#13;
       rather than as a separate disjointed element of the education enterprise&#13;
     x provide feedback to students, teachers and schools about what has been&#13;
       learned, and â&#128;&#152;feed forwardâ&#128;&#153; information that can shape future learning as&#13;
       well as guide college and career related decision making&#13;
     x closely align curriculum expectations, subject and performance criteria&#13;
       and desired learning outcomes&#13;
     x engage teachers in assessment development and scoring as a way to&#13;
       improve their professional practice and their capacity to support student&#13;
       learning and achievement&#13;
     x engage students in authentic assessments to improve their motivation and&#13;
       learning&#13;
     x seek to advance student learning in higher order thinking skills and problem&#13;
       solving by using a wider range of instructional and assessment strategies&#13;
     x privilege quality over quantity of standardized testing11&#13;
&#13;
&#13;
&#13;
10 Ravela (2005) describes the use of large scale national assessment results in Uruguay to help&#13;
teachers improve their teaching. The emphasis on formative uses at the classroom level&#13;
helped enhance teacher acceptance of the results; it also influenced the assessment design in&#13;
terms of the need to use a census based approach to data collection and the use of&#13;
background factors to control for non school factors affecting achievement.&#13;
11 That is to say, some countries have good outcomes on international assessment exercises,&#13;
&#13;
but donâ&#128;&#153;t use a lot of standardized testing in their own education systems (for example,&#13;
Finland). Other countries place a lot of emphasis on standardized testing (for example, the&#13;
United States), but donâ&#128;&#153;t do so well on the same international assessment exercises.&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                5&#13;
&amp;#12;         x as a large and increasing part of their examination systems, use open&#13;
           ended performance tasks and school based assessments that require students to&#13;
           write extensively and give them opportunities to develop â&#128;&#152;twenty first&#13;
           centuryâ&#128;&#153; skills.12&#13;
         While Darling Hammond and Wentworthâ&#128;&#153;s research provides a broad&#13;
    vision of what an effective assessment system looks like, it does not tell us what&#13;
    it takes to get there. Other studies delve into these planning, process, and&#13;
    implementation issues. For example, Ferrer (2006) provides advice on designing&#13;
    sustainable and sound assessment systems based on his analysis of existing&#13;
    systems in Latin America. Bray and Steward (1998) carry out a similar analysis for&#13;
    secondary school examinations. Others (for example, Lockheed, 2009) evaluate the&#13;
    status of donor activity in the area of assessment and discuss how to improve the&#13;
    effectiveness of this support to countries. Still others delve into the politics of&#13;
    creating sustainable and effective assessment systems (McDermott, 2011).&#13;
         This paper draws together all of the above streams of evidence, organizing&#13;
    the key issues and factors into a unified framework for understanding what an&#13;
    effective student assessment system looks like and how countries can begin to&#13;
    build such systems.&#13;
&#13;
&#13;
    Framework for Student Assessment Systems&#13;
    In order to approach the framework in a strategic way, we need to identify some&#13;
    key dimensions of assessment systems. Two main dimensions are discussed&#13;
    here: (i) types/purposes of assessment activities and (ii) the quality of those&#13;
    activities.&#13;
&#13;
    Dimension 1. Assessment Types/Purposes&#13;
    Assessment systems tend to comprise three main kinds of assessment activities,&#13;
    corresponding to three main information needs or purposes (see also appendix&#13;
    1). These kinds and the concomitant information needs are:&#13;
         x classroom assessments for providing real time information to support&#13;
           teaching and learning in individual classrooms&#13;
         x examinations for making decisions about an individual studentâ&#128;&#153;s progress&#13;
           through the education system (for example, certification or selection&#13;
           decisions), including the allocation of â&#128;&#152;scarceâ&#128;&#153; educational opportunities&#13;
&#13;
&#13;
    12Results from standardized performance tasks are incorporated into studentsâ&#128;&#153; examination&#13;
    scores in systems as wide ranging as the GCSE in the United Kingdom; the Singapore&#13;
    examinations system; the certification systems in Victoria and Queensland, Australia; and the&#13;
    International Baccalaureate, which operates in more than 100 countries around the world.&#13;
    Because these assessments are embedded in the curriculum, they influence the day to day&#13;
    work of teaching and learning, focusing it on the use of knowledge to solve problems.&#13;
&#13;
&#13;
6                                                                              Marguerite Clarke&#13;
&amp;#12;     x large scale, system level assessments for monitoring and providing policy&#13;
       maker and practitioner relevant information on overall performance&#13;
       levels in the system, changes in those levels, and related or contributing&#13;
       factors.&#13;
     To be sure, these assessment types are not completely independent of each&#13;
other; nor are they all encompassing (that is, there are some assessment activities&#13;
that donâ&#128;&#153;t quite fit under these labels). At the same time, they represent the main&#13;
kinds of assessment activities carried out in the majority of education systems&#13;
around the world.&#13;
     Classroom assessments, also referred to as continuous or formative&#13;
assessments, are those carried out by teachers and students in the course of daily&#13;
activity (Airasian and Russell, 2007). They encompass a variety of standardized&#13;
and nonstandardized instruments and procedures for collecting and interpreting&#13;
written, oral, and other forms of evidence on student learning or achievement.&#13;
Examples of classroom assessment activities include oral questioning and&#13;
feedback, homework assignments, student presentations, diagnostic tests, and&#13;
end of unit quizzes. The main purpose of these assessments is to provide â&#128;&#152;real&#13;
timeâ&#128;&#153; information to support teaching and learning.&#13;
     Examinations, variously modified by the terms â&#128;&#152;public,â&#128;&#153; â&#128;&#152;external,â&#128;&#153; or â&#128;&#152;end of&#13;
cycle,â&#128;&#153; provide information for high stakes decision making about individual&#13;
studentsâ&#128;&#148;for example, whether they should be assigned to a particular type of&#13;
school or academic program, graduate from high school, or gain admission to&#13;
university (Greaney and Kellaghan, 1995; Heubert and Hauser, 1999). Whether&#13;
externally administered or (increasingly) school based, their typically&#13;
standardized nature is meant to ensure that all students are given an equal&#13;
opportunity to show what they know and can do in relation to an official&#13;
curriculum or other identified body of knowledge and skills (Madaus and&#13;
Clarke, 2001). The leaving certificate or exit examinations at the end of&#13;
compulsory education in many education systems are a good example. As&#13;
discussed earlier, the high stakes nature of most examinations means they can&#13;
exert a backwash effect on the education system in terms of what is taught and&#13;
learned, having an impact, for better or worse, on the skills and knowledge&#13;
profile of graduates (West and Crighton, 1999). Such consequences must be&#13;
considered when determining whether the use of such tests is appropriate13 and&#13;
&#13;
13Greaney and Kellaghan (1995) note that because of the high stakes attached to examination&#13;
performance, teachers often teach to the examination, with the result that inadequate&#13;
opportunities to acquire relevant knowledge and skills are provided for students who will&#13;
leave school at an early stage. Practices associated with examinations that may create&#13;
inequities for some students include scoring practices, the requirement that candidates pay&#13;
fees, private tutoring, examination in a language with which students are not familiar, and a&#13;
variety of malpractices. The use of quota systems to deal with differences in performance&#13;
associated with location, ethnicity, or language group membership also creates inequities for&#13;
some students.&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                             7&#13;
&amp;#12;    whether or how they should be combined with other sources of information in&#13;
    order to ensure that the results are used in a way that is as fair as possible to&#13;
    individuals, groups, and society as a whole. It is important to emphasize that&#13;
    there are very specific professional and technical standards regarding the&#13;
    appropriate and inappropriate uses of examinations (and tests in general) for&#13;
    making high stakes decisions about individual students (AERA, APA, and&#13;
    NCME, 1999).&#13;
          Large scale, system level assessments are designed to provide information on&#13;
    system performance levels and related or contributing factors (Greaney and&#13;
    Kellaghan, 2008; Kifer, 2001), typically in relation to an agreed upon set of&#13;
    standards or learning goals, in order to inform education policy and practice.&#13;
    Examples include international assessments of student achievement levels, such&#13;
    as TIMSS, PIRLS, and PISA; regional assessments, such as PASEC in&#13;
    Francophone Africa, SACMEQ in Anglophone Africa, and LLECE in South&#13;
    America; national level assessments, such as SIMCE in Chile; and subnational&#13;
    assessments, such as the state level tests in the United States or Canada.14 These&#13;
    assessments vary in the grades or age levels tested, coverage of the target&#13;
    population (sample or census), internal or external focus (for example, national&#13;
    versus international benchmarks), subjects or skill areas covered, types of&#13;
    background data gathered, and the frequency with which they are administered.&#13;
    They also vary in how the results are reported and used. For example, as&#13;
    discussed earlier, while some stop at the reporting of results to policy makers or&#13;
    the general public, others use the results to hold accountable specific groups in&#13;
    the education system (Clarke, 2007).15&#13;
          One way to differentiate among the above three types of assessment&#13;
    activities is that classroom assessment is mainly about assessment as learning or&#13;
    for learning (and hence is primarily formative in nature) while examinations and&#13;
    surveys are mainly about assessment of learning (and hence are primarily&#13;
    summative in nature). These distinctions do not always hold up neatly in&#13;
    practice and hybrid approaches are becoming more common. For example,&#13;
    Singapore has an assessment system structured around public examinations, but&#13;
    has built a whole infrastructure of support for learning around it (L. Benveniste,&#13;
    personal communication, March 2010). Other hybrid activities involve the&#13;
    adaptation of tools designed for one type of assessment activity (for example,&#13;
&#13;
    14 TIMSSâ&#128;&#148;Trends in International Mathematics and Science Study; PIRLSâ&#128;&#148;Progress in&#13;
    International Reading Literacy Study; PISAâ&#128;&#148;Program for International Student Assessment;&#13;
    PASECâ&#128;&#148;Programme d Analyse des SystÃ¨mes Educatifs (Program on the Analysis of&#13;
    Education Systems); SACMEQâ&#128;&#148;Southern and Eastern Africa Consortium for Monitoring&#13;
    Educational Quality; LLECEâ&#128;&#148;Latin American Laboratory for Assessment of the Quality of&#13;
    Education; Sistema de MediciÃ³n de Calidad de la EducaciÃ³n.&#13;
    15 World Bank support for assessment activity over the last 20 years (Larch and Lockheed,&#13;
&#13;
    1992; Liberman and Clarke, 2012) has shifted from an emphasis on examination reform to an&#13;
    emphasis on the implementation of large scale, system level assessment exercises for&#13;
    monitoring achievement trends and informing policy and practice.&#13;
&#13;
&#13;
8                                                                           Marguerite Clarke&#13;
&amp;#12;classroom instruments for informing instruction) for another purpose (for&#13;
example, documenting performance at the system level). One of the best known&#13;
of these initiatives is the Early Grade Reading Assessment (EGRA), an&#13;
instrument developed with the support of donor agencies and experts for use in&#13;
developing countries (https://www.eddataglobal.org/). Based on a tool originally&#13;
designed for classroom use, EGRA has been used to collect system level data on&#13;
student performance on early reading skills in order to inform ministries and&#13;
donors regarding system needs for improving instruction (Gove and Cvelich,&#13;
2011).&#13;
     Education systems can have quite different profiles in terms of the emphasis&#13;
placed on the different types of assessment activities. For example, Finlandâ&#128;&#153;s&#13;
education system emphasizes classroom assessment as the key source of&#13;
information on student learning and achievement and draws far less on&#13;
examinations or large scale, system level assessment. China has traditionally&#13;
placed considerable emphasis on examinations as a means to sort and select from&#13;
its large student population, and relatively less on classroom assessment or&#13;
large scale surveys (although this is changing).16 Factors contributing to these&#13;
different assessment system profiles vary from the official vision and goals of the&#13;
education system (and the role of assessment in achieving that vision) to the&#13;
economic structures and opportunities in a country and the related information&#13;
needs of key stakeholders. It is not clear that there exists one ideal profile for an&#13;
assessment system that works equally well in all contexts.&#13;
&#13;
Dimension 2. Quality Drivers&#13;
Instead of being able to reference one ideal profile for a student assessment&#13;
system, the key consideration is the individual and combined quality of the&#13;
assessment activities in terms of the adequacy of the information generated to&#13;
support decision making (Messick, 1989; Shepard, 2000).&#13;
     There are three main drivers of information quality in an assessment system&#13;
(AERA, APA, and NCME, 1999; Darling Hammond and Wentworth, 2010):&#13;
     x enabling context&#13;
     x system alignment&#13;
     x assessment quality.&#13;
     Although closely related, these dimensions are presented here separately for&#13;
the purposes of discussion.&#13;
     The enabling context refers to the broader context in which an assessment&#13;
activity takes place and the extent to which that context is conducive to, or&#13;
&#13;
&#13;
16 Other contributing factors include the historical legacy of assessment in a particular&#13;
education system, which can create a pull toward a particular type of assessment activity&#13;
(Madaus, Clarke, and Oâ&#128;&#153;Leary, 2003); the capacity of various stakeholders in the system to&#13;
effectively carry out different types of assessment activities (Greaney and Kellaghan, 2008);&#13;
and the cost, perceived or real, of assessment activities (Wolff, 2007).&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                             9&#13;
&amp;#12;     supportive of, the assessment. It covers such areas as the legislative or policy&#13;
     framework for assessment activities; leadership surrounding the assessment&#13;
     activity (including the political will to implement an assessment in spite of the&#13;
     knowledge that results might reveal serious issues or inequities in student&#13;
     learning); public engagement with the assessment activity; the institutional&#13;
     arrangements for designing, carrying out, or using the results from the&#13;
     assessment activity;17 the availability of sufficient and stable sources of funding&#13;
     and the presence of competent assessment unit staff and classroom teachers.&#13;
          The enabling context is important to get right because it is a key driver of the&#13;
     long term quality and effectiveness of an assessment system andâ&#128;&#148;like the soil,&#13;
     water, and air that a plant needs to growâ&#128;&#148;no assessment system is sustainable in&#13;
     its absence (World Bank, 2010). In most instances, the onus is on the government&#13;
     to at least provide the vision, leadership, and policy framework toward&#13;
     establishing this enabling context (at the same time, keeping in mind that relative&#13;
     autonomy from political influence is one of the hallmarks of a more mature&#13;
     assessment system), which may subsequently be implemented via public private&#13;
     partnerships (for example, contracting administration of an assessment program&#13;
     to an outside firm). Some education systems, particularly in federal contexts,&#13;
     combine forces to create an enabling context in terms of pooling resources or&#13;
     institutional arrangements for developing, implementing, analyzing, or reporting&#13;
     on tests (for example, when states or systems come together to design a common&#13;
     test item bank that each can use for their own purposes, hence reducing the cost&#13;
     for individual states or systems). Regional assessment exercises, such as&#13;
     SACMEQ, PASEC, and LLECE, represent another form of collaboration toward&#13;
     creating an enabling context. The efficiencies of scale achieved by these&#13;
     collaborations make it more cost effective to develop higher quality tests and to&#13;
     incorporate technological advances into the testing process.&#13;
          System alignment refers to the extent to which the assessment is aligned or&#13;
     coherent with other components of the education system. This includes the&#13;
     connection between assessment activities and system learning goals, standards,&#13;
     curriculum, and pre and in service teacher training opportunities (Fuhrman and&#13;
     Elmore, 1994; Smith and Oâ&#128;&#153;Day, 1991). It is important for assessment activities to&#13;
     align with the rest of the education system so that the information they provide&#13;
     is of use to improving the quality of education in the system, and so that&#13;
     synergies can be created.&#13;
          Alignment involves more than a simple match between what is tested and&#13;
     what is in the official standards or intended curriculum (at the same time, it is&#13;
&#13;
     17There is much debate over whether examination or large scale assessment units should be&#13;
     located within or outside of education ministries. In fact, the institutional location is not as&#13;
     important as the culture of continuity and transparency created around the assessment&#13;
     (Ravela et al., 2008). Such a culture is achieved when an assessment has a clear mandate and&#13;
     solid structure, which necessitates that the assessment system be underpinned by some kind&#13;
     of legal statute.&#13;
&#13;
&#13;
10                                                                                 Marguerite Clarke&#13;
&amp;#12;important that most assessment activities provide at least some information on&#13;
student learning and achievement in relation to official standards or curriculum).&#13;
Hence, while the correspondence between a countryâ&#128;&#153;s curriculum and what is&#13;
tested on international assessments such as PISA and TIMSS may be low, the&#13;
assessment might still be aligned with (and useful for informing) the overall&#13;
goals and aspirations for the education system and related reforms. Under such a&#13;
scenario, assessment can actually lead quality improvements in the education&#13;
system rather than simply passively monitor them (notwithstanding that the use&#13;
of data from TIMSS, PIRLS, and PISA to monitor the impact of national reforms&#13;
on performance over time has been key to the improvement of achievement&#13;
levels in countries as diverse as Brazil, Jordan, and Poland).&#13;
     Assessment quality refers to the psychometric quality of the instruments,&#13;
processes, and procedures used for the assessment activity (AERA, APA, and&#13;
NCME, 1999). It is important to note that assessment quality is a concern for any&#13;
kind of assessment activityâ&#128;&#148; that is, classroom assessment; examinations; or large&#13;
scale, system level assessment. It covers such issues as the design and&#13;
implementation of assessment activities, examination questions, or survey items;&#13;
the analysis and interpretation of student responses to those assessment activities,&#13;
questions, or items; and the appropriateness of how the assessment, examination,&#13;
or survey results are reported and used (Heubert and Hauser, 1999; Shepard, 2000).&#13;
Depending on the assessment activity, the exact criteria used to make those&#13;
judgments differ. Assessment quality is important because if an assessment is not&#13;
sound in terms of its design, implementation, analysis, interpretation, reporting,&#13;
or use, it may contribute to poor decision making in regards to student learning&#13;
and system quality (Messick, 1989; Wolff, 2007). In fact, poor assessment quality&#13;
could undermine the entire assessment exercise if it causes distrust in the&#13;
approach.&#13;
     Two technical issues that need to be considered in any review of assessment&#13;
quality are reliability and validity. Reliability refers to whether the assessment&#13;
produces accurate information, and is a particularly important consideration for&#13;
high stakes examinations and for monitoring trends over time. Validity pertains&#13;
to whether the test scores represent what they are supposed to represent and&#13;
whether they can be used in the intended ways. One common threat to test score&#13;
validity is a difference between the language of instruction and the language of&#13;
testing, which may make it difficult for a child to show what they know and can&#13;
do. Use is a very important concept in relation to validity, and requires a careful&#13;
consideration of the consequences of test score use, including the social,&#13;
economic, and other impacts on different groups in the population.&#13;
     Crossing these quality drivers with the different assessment types/purposes,&#13;
we arrive at the framework diagramed in table 1.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                    11&#13;
&amp;#12;     Table 1. Framework for Building a More Effective Student Assessment System&#13;
                                             Assessment types/purposes&#13;
                                Classroom                              Large-scale, system-&#13;
                               assessment           Examinations        level assessment&#13;
&#13;
&#13;
     Enabling context&#13;
&#13;
&#13;
&#13;
     System alignment&#13;
&#13;
&#13;
&#13;
     Assessment quality&#13;
&#13;
&#13;
     Source: World Bank.&#13;
&#13;
&#13;
         The rest of this paper fleshes out and discusses the use of this framework for&#13;
     building a more effective assessment system. The framework can be applied to&#13;
     any countryâ&#128;&#153;s assessment system as a way to begin a discussion about where the&#13;
     system appears strong and where more work may be needed.&#13;
&#13;
&#13;
     Fleshing out the Framework&#13;
     The framework in table 1 is a starting point for identifying indicators that can be&#13;
     used to review assessment systems and plan for their improvement. Indicators&#13;
     can be identified based on a combination of criteria, including:&#13;
          x professional standards for assessment&#13;
          x empirical research on the characteristics of effective assessment systems,&#13;
            including analysis of the characteristics that differentiate between the&#13;
            assessment systems of low versus high performing nations&#13;
          x theoryâ&#128;&#148;that is, general consensus among experts that it contributes to&#13;
            effective assessment.&#13;
         The evidence base is stronger in some areas than in others. For example,&#13;
     there are many professional standards for assessment quality (APA, AERA, and&#13;
     NCME, 1999),18 but far fewer for the enabling context. In addition, some of the&#13;
     empirical research is limited by its correlational nature and hence we must be&#13;
     cautious about inappropriate attribution or over interpreting the association&#13;
     between characteristics. Despite such limitations, evidence from a variety of&#13;
     sources converges quite convincingly to make clear what better assessment is&#13;
     (and what it is not).&#13;
&#13;
&#13;
&#13;
     18There also is a sizeable research base on system alignment (for example, Fuhrman and&#13;
     Elmore, 1994; Hamilton, Stecher, and Klein, 2002).&#13;
&#13;
&#13;
12                                                                         Marguerite Clarke&#13;
&amp;#12;    The above criteria and considerations were used to expand the three quality&#13;
drivers into the broad indicator areas shown in table 2. These indicator areas are&#13;
most relevant to examinations and large scale, system level assessment activities,&#13;
but also can be applied to classroom assessment.&#13;
&#13;
Table 2. Framework for Building a More Effective Student Assessment System, with&#13;
Broad Indicator Areas&#13;
&#13;
                                           Assessment types/purposes&#13;
&#13;
                            Classroom                                     Large-scale, system-&#13;
                           assessment              Examinations            level assessment&#13;
&#13;
                                                        Policies&#13;
                                         Leadership and public engagement&#13;
Enabling context                                       Funding&#13;
                                             Institutional arrangements&#13;
                                                  Human resources&#13;
&#13;
                                               Learning/quality goals&#13;
System alignment                                     Curriculum&#13;
                                  Pre- and in-service teacher training opportunities&#13;
&#13;
                                  Ensuring quality (design, administration, analysis)&#13;
Assessment quality&#13;
                                              Ensuring effective uses&#13;
&#13;
Source: World Bank.&#13;
&#13;
&#13;
     Data pertaining to some of these indicator areas can be found in official&#13;
documents, published reports (for example, Ferrer, 2006), research articles (for&#13;
example, Braun and Kanjee, 2006), and online databases.19 For the most part,&#13;
however, the relevant data have not been gathered in any comprehensive or&#13;
systematic fashion.20 Those wishing to review this type of information for a&#13;
particular assessment system most likely will need to collect the data themselves.&#13;
In response to this need, the World Bank has developed a set of standardized&#13;
questionnaires and rubrics for collecting and evaluating data on the three&#13;
assessment types (classroom assessments, examinations, and large scale, system&#13;
level assessment) and related quality drivers (enabling context, system&#13;
alignment, assessment quality). The tools, which are regularly updated on the&#13;
basis of new evidence and country experiences, are available at&#13;
http://www.worldbank.org/education/saber. Countries can use these tools,&#13;
which build on the framework and broad indicator areas shown in table 2, to&#13;
&#13;
&#13;
19Two of the more useful online databases are http://www.inca.org.uk/ and http://epdc.org/.&#13;
20Brinkley, Guthrie, and Wyatt (1991) surveyed large scale, system level assessment and&#13;
examination practices in OECD countries. Larach and Lockheed (1992) did a similar survey of&#13;
assessments supported by the World Bank. Macintosh (1994) did a study in 10 countries&#13;
(Australia, Bahrain, England and Wales, Guatemala, Israel, Malaysia, Namibia, Poland,&#13;
Scotland, and Slovenia).&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                              13&#13;
&amp;#12;     systematically examine and gain a better understanding of the strengths and&#13;
     weaknesses of their student assessment system and to plan for where to go next.&#13;
     It is important to point out that the tools primarily focus on benchmarking a countryâ&#128;&#153;s&#13;
     policies, practices, and arrangements for classroom assessment, examinations, and&#13;
     large scale, system level assessment activities at the system level. Additional tools&#13;
     would be needed to determine actual, on the ground practices by teachers and&#13;
     students in schools.&#13;
&#13;
&#13;
     Levels of Development&#13;
     The basic structure of the rubrics for evaluating data collected using the&#13;
     standardized questionnaires is summarized in table 3. The full set of rubrics is&#13;
     provided in appendix 2. The goal of the rubrics is to provide a country with some&#13;
     sense of the development level of its assessment activities compared to best or&#13;
     recommended practice in the area.&#13;
&#13;
     Table 3. Basic Structure of Rubrics for Evaluating Data Collected on a Student&#13;
     Assessment System&#13;
                                                               Development Level&#13;
&#13;
                                  LATENT          EMERGING&#13;
                                (Absence of,      (On way to      ESTABLISHED&#13;
                                or deviation        meeting        (Acceptable     ADVANCED&#13;
                                    from,          minimum          minimum           (Best&#13;
           Dimension              attribute)       standard)        standard)       practice)   Justification&#13;
                                               ECâ&#128;&#148;ENABLING CONTEXT&#13;
     EC1â&#128;&#148;Policies&#13;
     EC2â&#128;&#148;Leadership,&#13;
     public engagement&#13;
     EC3â&#128;&#148;Funding&#13;
     EC4â&#128;&#148;Institutional&#13;
     arrangements&#13;
     EC5â&#128;&#148;Human&#13;
     resources&#13;
                                               SAâ&#128;&#148;SYSTEM ALIGNMENT&#13;
     SA1â&#128;&#148;Learning/quality&#13;
     goals&#13;
     SA2â&#128;&#148;Curriculum&#13;
     SA3â&#128;&#148;Pre-, in-service&#13;
     teacher training&#13;
                                          AQâ&#128;&#148;ASSESSMENT QUALITY&#13;
     AQ1â&#128;&#148;Ensuring quality&#13;
     (design, administration,&#13;
     analysis)&#13;
     AQ2â&#128;&#148;Ensuring&#13;
     effective uses&#13;
     Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
14                                                                                       Marguerite Clarke&#13;
&amp;#12;     For each indicator, the rubric displays four development levelsâ&#128;&#148;Latent,&#13;
Emerging, Established, and Advanced.21 These levels are artificially constructed&#13;
categories chosen to represent key stages on the underlying continuum for each&#13;
indicator. Each level is accompanied by a description of what performance on the&#13;
indicator looks like at that level. Latent is the lowest level of performance; it&#13;
represents absence of, or deviation from, the attribute. Emerging is the next level;&#13;
it represents partial presence of the attribute. Established represents the acceptable&#13;
minimum standard on the indicator and Advanced represents the ideal or current&#13;
best practice. Not all questions from the questionnaires are represented in the&#13;
rubrics; this is because not all of the questions are underpinned by an evidence base&#13;
that demonstrates a relationship between increasing performance levels on the&#13;
attribute/indicator and improved quality or effectiveness of assessment activities.&#13;
     It is important to recognize that many of the issues that we are trying to get&#13;
at with the indicators and associated development levels can be difficult to&#13;
measure. In some instances, explicit technical standards exist and can be drawn&#13;
on to aid these measurement efforts (for example, international standards for&#13;
determining whether a countryâ&#128;&#153;s TIMSS results are sufficiently robust to be&#13;
included in the international report). In others, judgment calls need to be made&#13;
(for example, measuring the degree of public support for a particular assessment&#13;
activity). In order to enhance the overall reliability and cross system&#13;
comparability of the indicators and development levels, the questionnaires and&#13;
rubrics rely, as much as possible, on objective measures.&#13;
     In addition to evaluating performance on individual indicators, it can be&#13;
useful to qualitatively compare an assessment systemâ&#128;&#153;s overall characteristics&#13;
against profiles of assessment systems as they might look at different levels of&#13;
development. Table 4 outlines generic profilesâ&#128;&#148;drawing on the information&#13;
provided in table 2 and appendix 2â&#128;&#148;for assessment systems at Emerging,&#13;
Established, and Advanced levels of development (Latent is omitted because it&#13;
basically represents the absence of any assessment activity).&#13;
     Assessment systems that are at an Emerging level can be characterized as&#13;
having enabling contexts, as well as levels of system alignment and assessment&#13;
quality, that are just taking shape. These systems are characterized by instability&#13;
and uncertainty about the choice, frequency, and use of assessment activities,&#13;
indicative of an unclear vision for assessment at the system level and uncertain&#13;
or insufficient funding for assessment activities. In this context, assessment is&#13;
more likely to function as an â&#128;&#152;add onâ&#128;&#153; to the system, without much systematic&#13;
effort to align it with standards, curricula, or teacher training opportunities.&#13;
&#13;
&#13;
&#13;
&#13;
21The Latent label could be applied to countries where there is no formal assessment activity&#13;
or where the education system has been suspended due to war or other conflict.&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                             15&#13;
&amp;#12;     Table 4. Stylized Profiles of Student Assessment Systems at Different Levels of&#13;
     Development&#13;
                                 Emerging                          Established                       Advanced&#13;
                       x No or limited policy             x Presence of clear policy         The same as for&#13;
                         framework or guidelines            framework or guidelines          Established&#13;
                       x Weak leadership/public           x Strong leadership/public&#13;
                         engagement                         engagement                       + strong focus on:&#13;
     Enabling&#13;
                       x Few trained staff; high          x Training programs/trained&#13;
     context&#13;
                         turnover                           staff with low turnover           x Assessment for&#13;
                       x Unreliable/irregular funding     x Stable/regular funding              learning&#13;
                       x Unclear or unstable              x Clear and stable institutional    x School-based and&#13;
                         institutional arrangements         arrangements                        classroom assessment&#13;
                       x Assessments not fully            x Assessments aligned with          x Role of teachers&#13;
                         aligned with learning/quality      learning/quality goals,           x Innovation and&#13;
                         goals, standards, curriculum       standards, curriculum               research-based&#13;
     System&#13;
                       x Assessments not aligned          x Assessments aligned with            practices&#13;
     alignment&#13;
                         with pre- and in-service           pre- and in-service teacher&#13;
                         teacher training                   training opportunities&#13;
                         opportunities&#13;
                       x Limited awareness or             x Awareness and application&#13;
                         application of technical or        of technical or professional&#13;
     Assessment&#13;
                         professional standards for         standards for ensuring&#13;
     quality&#13;
                         ensuring assessment quality        assessment quality effective&#13;
                         and effective uses                 uses&#13;
     Source: World Bank.&#13;
     Note: The Latent level is omitted because it basically represents the absence of any assessment activity.&#13;
&#13;
&#13;
&#13;
&#13;
     Capacity building tends to be nonsystematic and of limited effectiveness as&#13;
     individuals disperse to other parts of the organization or to the private sector&#13;
     after they have been trained. Assessment activities tend to be of low quality due&#13;
     to a lack of awareness of, or attention to, professional standards.&#13;
          Assessment systems that are at an Established level can be characterized as&#13;
     having enabling contexts, as well as levels of system alignment and assessment&#13;
     quality, that are stable, assured, or consolidated in nature. These systems are&#13;
     characterized by continuity and certainty about the choice, frequency, and use of&#13;
     assessment activities, as well as stable and sufficient sources of funding,&#13;
     indicative of a vision and â&#128;&#152;buy inâ&#128;&#153; for assessment at the system level. In this&#13;
     environment, assessment functions more as an integral part of the system, with&#13;
     systematic efforts to align it with standards, curricula, or teacher training&#13;
     opportunities. Capacity building tends to be focused, sustained, and effective&#13;
     and there is low staff turnover. Assessment activities tend to be of good quality&#13;
     due to awareness of, and attention to, professional standards. This level may be&#13;
     viewed as the acceptable minimum standard in order for an assessment system&#13;
     to be effective.&#13;
          Assessment systems that are at an Advanced level can be characterized as&#13;
     having enabling contexts, as well as levels of system alignment and assessment&#13;
     quality that are highly developed in nature. In addition to having the best&#13;
     features of Established systems, Advanced systems are characterized by high levels&#13;
     of innovation and research based practices. In this environment, assessment&#13;
&#13;
&#13;
16                                                                                                 Marguerite Clarke&#13;
&amp;#12;functions as a highly integral part of the system. Capacity building tends to be&#13;
very much focused on teachers, in addition to â&#128;&#152;technicians,â&#128;&#153; testimony to a strong&#13;
emphasis on school based and classroom assessment (and reminiscent of the key&#13;
features of high performing systems highlighted by Darling Hammond and&#13;
Wentworth in their work).&#13;
      In reality, assessment systems are likely to be at different levels of&#13;
development in different areas. For example, a system may be Established in the&#13;
area of examinations, but Emerging in the area of large scale, system level&#13;
assessment, and vice versa. While intuition suggests that it is probably better to&#13;
be further along in as many areas as possible, the evidence is unclear as to&#13;
whether it is necessary to be functioning at Advanced levels in all areas.&#13;
Therefore, one might view the Established level as a desirable minimum outcome&#13;
to achieve in all areas (which is what we see in the assessment systems of&#13;
countries like Finland and Australia), but only aspire beyond that in those areas&#13;
that most contribute to the national vision or priorities for education. In line with&#13;
these considerations, the ratings generated by the rubrics in appendix 2 are not&#13;
meant to be additive across assessment types (that is, they are not meant to be&#13;
added to create an overall rating for an assessment system; they are only meant&#13;
to produce an overall rating for each assessment type).&#13;
      While it is useful to have an idea of what assessment systems and different&#13;
assessment types look like at different development levels, it is equally, if not&#13;
more, useful to know how to progress through those levels. Thus, we also need to&#13;
understand some of the key reforms or inputs that countries have used to&#13;
develop more effective assessment systems. Unfortunately, the evidence becomes&#13;
sparser in this area and further research is definitely needed to flesh out the&#13;
concrete strategies involved.&#13;
      Based on the small amount of available evidence, the main factor that seems&#13;
to characterize systems that make the shift from Emerging to Established (overall&#13;
or in a specific assessment area) is a concerted focus on reforms, inputs, and&#13;
practices that strengthen the enabling context for assessment (Ferrer, 2006).22 For&#13;
example, in their review of World Bank support for assessment projects in client&#13;
countries, Larach and Lockheed (1992) found that projects that first focused on&#13;
improving institutional arrangements were more likely to succeedâ&#128;&#148;in terms of&#13;
leading to a sustainable assessment program in the countryâ&#128;&#148;than projects that&#13;
first tried to improve the technical quality of existing assessment activities. In line&#13;
with this finding, in their review of assessment reform efforts in Central and&#13;
Eastern European countries, West and Crighton (1999) noted that reforms had a&#13;
better chance of being sustained when there was public consensus that change&#13;
was needed, clear and consistent political support for change, and sufficient&#13;
allocation of resources.&#13;
&#13;
22While it may benefit a system, for a short time, to focus resources around making progress&#13;
on one specific quality driver (for example, enabling context), this is not a long term strategy&#13;
as each quality driver is a necessary contributor to an effective assessment system.&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                17&#13;
&amp;#12;           The main factor that seems to characterize systems that make the shift from&#13;
     Established to Advanced is a focus on reforms, inputs, and practices that prioritize&#13;
     the classroom, and teachers and students as the key actors in assessment&#13;
     (Darling Hammond and Wentworth, 2010; Shepard, 2000). This relates to the fact&#13;
     that the most powerful form of assessment, when done correctly, is that carried&#13;
     out by teachers and students in the course of their daily classroom activities (that&#13;
     is, classroom assessment). Doing this type of assessment correctly requires a lot&#13;
     of capacity building and focused attention on teacher quality issues.&#13;
&#13;
&#13;
&#13;
     Conclusions&#13;
     Assessment is key to knowing whether an education system is producing the&#13;
     desired outcomes for students, the economy, and society at large. Without&#13;
     effective assessment, it is impossible to know whether students are learning and&#13;
     whether reforms are working in the intended ways.&#13;
          This paper extracted principles and guidelines from countriesâ&#128;&#153; experiences&#13;
     and the current research base to outline a framework for developing a more&#13;
     effective student assessment system. The framework provides policy makers and&#13;
     others with an evidence based structure for discussion and consensus building&#13;
     around priorities and key inputs for their assessment system.&#13;
          An important contribution of the framework is to help countries identify the&#13;
     key quality drivers that need to be addressed in order to strengthen the quality&#13;
     and utility of the information produced by the various activities in their&#13;
     assessment system. This is critical because the main purpose of any assessment&#13;
     system is to provide valid and timely information to a set of usersâ&#128;&#148;the student,&#13;
     the teacher, the community, and the policy makerâ&#128;&#148;so that they can make better&#13;
     decisions in support of improved quality and learning outcomes. Choices about&#13;
     the assessment system need to be consistent with serving these users and their&#13;
     information and decision making needs.&#13;
          The framework also has a dynamic dimension that illustrates the trajectory&#13;
     of moving from one level of development to the next in each assessment area. It&#13;
     is important to keep in mind that it takes time to progress from level to level.&#13;
     Case studies on countriesâ&#128;&#153; experiences in strengthening their student assessment&#13;
     systems reveal that it often takes a decade or more for a set of reforms and inputs&#13;
     to really take hold and produce tangible results. Therefore, country teams must&#13;
     plan from the outset to have a long term commitment to, and investment in, the&#13;
     policies, inputs, and actions that will be required to transform their assessment&#13;
     system. The payoff will be an assessment system that can support better decision&#13;
     making and contribute to higher levels of education quality and learning for all.&#13;
&#13;
&#13;
&#13;
&#13;
18                                                                       Marguerite Clarke&#13;
&amp;#12;Appendix 1. Assessment Types and Their Key&#13;
Differences&#13;
                                             Large-scale, system-level&#13;
                                                   assessment&#13;
                       Classroom            National         International        Examinations&#13;
Purpose               To provide        To provide          To provide         To select or certify&#13;
                      immediate         feedback on the     feedback on the    students as they&#13;
                      feedback to       overall health of   comparative        move from one level&#13;
                      inform            the system at       performance of     of the education&#13;
                      classroom         particular          the education      system to the next (or&#13;
                      instruction       grade/age           system at          into the workforce)&#13;
                                        level(s), and to    particular&#13;
                                        monitor trends      grade/age&#13;
                                        in learning         level(s)&#13;
Frequency             Daily             For individual      For individual     Annually and more&#13;
                                        subjects offered    subjects offered   often where the&#13;
                                        on a regular        on a regular       system allows for&#13;
                                        basis (such as      basis (such as     repeats&#13;
                                        every 3-5 years)    every 3-5 years)&#13;
Who is                All students      Sample or           A sample of        All eligible students&#13;
tested?                                 census of           students at a&#13;
                                        students at a       particular grade&#13;
                                        particular grade    or age level(s)&#13;
                                        or age level(s)&#13;
Format                Varies from       Usually multiple    Usually multiple   Usually essay and&#13;
                      observation to    choice and short    choice and short   multiple choice&#13;
                      questioning to    answer              answer&#13;
                      paper-and-&#13;
                      pencil tests to&#13;
                      student&#13;
                      performances&#13;
Coverage of           All subject       Generally           Generally          Covers main subject&#13;
curriculum            areas             confined to a       confined to one    areas&#13;
                                        few subjects        or two subjects&#13;
&#13;
&#13;
Additional            Yes, as part of   Frequently          Yes                Seldom&#13;
information           the teaching&#13;
collected             process&#13;
from&#13;
students?&#13;
Scoring               Usually           Varies from         Usually involves   Varies from simple to&#13;
                      informal and      simple to more      statistically      more statistically&#13;
                      simple            statistically       sophisticated      sophisticated&#13;
                                        sophisticated       techniques         techniques&#13;
                                        techniques&#13;
Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                     19&#13;
&amp;#12; Appendix 2. Rubrics for Judging the Development Level of&#13;
 Different Assessment Types&#13;
                                                     Classroom Assessment&#13;
       LATENT                          EMERGING                   ESTABLISHED&#13;
 Absence of, or deviation           On way to meeting           Acceptable minimum                ADVANCED&#13;
   from, the attribute              minimum standard                 standard                     Best practice          Justification&#13;
&#13;
                                Enabling Context &amp; System Alignment (EC &amp; SA)&#13;
   Overall policy and resource framework within which classroom assessment activity takes place in an education&#13;
 system, and the degree to which classroom assessment activity is coherent with other components of the education&#13;
                                                     system.&#13;
&#13;
                             EC&amp;SA1â&#128;&#148;Setting clear guidelines for classroom assessment&#13;
&#13;
 (Q1) There is no system-         (Q1) There is an informal   (Q1) There is a formal         This option does not&#13;
 level document that              system-level document       system-level document that     apply to this dimension.&#13;
 provides guidelines for          that provides guidelines    provides guidelines for&#13;
 classroom assessment.            for classroom               classroom assessment.&#13;
                                  assessment.&#13;
&#13;
 This option does not apply       This option does not        (Q3, Q4) The availability of   (Q3, Q4) The document&#13;
 to this dimension.               apply to this dimension.    the document is restricted.    is widely available.&#13;
&#13;
                      EC&amp;SA2â&#128;&#148;Aligning classroom assessment with system learning goals&#13;
&#13;
 (Q5) There are no system-        (Q5) There are scarce       (Q5) There are some            (Q5) There are a variety&#13;
 wide resources for teachers      system-wide resources       system-wide resources for      of system-wide&#13;
 for classroom assessment.        for teachers for            teachers for classroom         resources available for&#13;
                                  classroom assessment.       assessment.                    teachers for classroom&#13;
                                                                                             assessment.&#13;
&#13;
 (Q6) There is no official        (Q6) There is an official   (Q6) There is an official      (Q6) There is an official&#13;
 curriculum or standards          curriculum or standards     curriculum or standards        curriculum or standards&#13;
 document.                        document, but it is not     document that specifies        document that specifies&#13;
                                  clear what students are     what students are expected     what students are&#13;
                                  expected to learn or to     to learn, but the level of     expected to learn and&#13;
                                  what level of               performance required is not    to what level of&#13;
                                  performance.                clear.                         performance.&#13;
&#13;
          EC&amp;SA3â&#128;&#148;Having effective human resources to carry out classroom assessment activities&#13;
&#13;
 (Q7, Q8) There are no            This option does not        (Q7, Q8) There are some        (Q7, Q8) There are a&#13;
 system-level mechanisms          apply to this dimension.    system-level mechanisms        variety of system-level&#13;
 to ensure that teachers                                      to ensure that teachers        mechanisms to ensure&#13;
 develop skills and expertise                                 develop skills and expertise   that teachers develop&#13;
 in classroom assessment.                                     in classroom assessment.       skills and expertise in&#13;
                                                                                             classroom assessment.&#13;
&#13;
&#13;
&#13;
&#13;
20                                                                                                              Marguerite Clarke&#13;
&amp;#12;      LATENT                          EMERGING                   ESTABLISHED&#13;
Absence of, or deviation           On way to meeting           Acceptable minimum                 ADVANCED&#13;
  from, the attribute              minimum standard                 standard                      Best practice      Justification&#13;
&#13;
                                           Assessment Quality (AQ)&#13;
                      Quality of classroom assessment design, administration, analysis, and use&#13;
&#13;
                              AQ1â&#128;&#148;Ensuring the quality of classroom assessment&#13;
&#13;
(Q11) Classroom                 (Q11) Classroom             (Q11) Classroom                (Q11) Classroom&#13;
assessment practices suffer     assessment practices are    assessment practices are       assessment practices&#13;
from widespread                 known to be weak.           known to be of moderate        are known to be&#13;
weaknesses, or there is no                                  quality.                       generally of high&#13;
information available on                                                                   quality.&#13;
classroom assessment&#13;
practices.&#13;
&#13;
(Q12) There are no              (Q12) There are ad hoc      (Q12) There are limited        (Q12) There are varied&#13;
mechanisms to monitor the       mechanisms to monitor       systematic mechanisms to       and systematic&#13;
quality of classroom            the quality of classroom    monitor the quality of         mechanisms in place to&#13;
assessment practices.           assessment practices.       classroom assessment           monitor the quality of&#13;
                                                            practices.                     classroom assessment&#13;
                                                                                           practices.&#13;
&#13;
                             AQ2â&#128;&#148;Ensuring effective uses of classroom assessment&#13;
&#13;
(Q14) Classroom                 This option does not        (Q14) Classroom                (Q14) Classroom&#13;
assessment information is       apply to this dimension.    assessment information is      assessment information&#13;
not required to be                                          required to be disseminated    is required to be&#13;
disseminated to key                                         to some key stakeholders.      disseminated to all key&#13;
stakeholders.                                                                              stakeholders.&#13;
&#13;
(Q15) There are no              (Q15) There are limited     (Q15) There are adequate       (Q15) There are&#13;
required uses of classroom      required uses of            required uses of classroom     adequate required uses&#13;
assessment to support           classroom assessment to     assessment to support          of classroom&#13;
student learning.               support student learning.   student learning, excluding    assessment to support&#13;
                                                            its use as an input for        student learning,&#13;
                                                            external examination           including its use as an&#13;
                                                            results.                       input for external&#13;
                                                                                           examination results.&#13;
&#13;
Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                            21&#13;
&amp;#12;                                                           Examinations&#13;
       LATENT                        EMERGING                    ESTABLISHED&#13;
 Absence of, or deviation         On way to meeting            Acceptable minimum                ADVANCED&#13;
   from, the attribute            minimum standard                  standard                     Best practice         Justification&#13;
&#13;
                                             Enabling Context (EC)&#13;
     Overall framework of policies, leadership, organizational structures, fiscal, and human resources in which&#13;
 assessment activity takes place in an education system and the extent to which that framework is conducive to, or&#13;
                                       supportive of, the assessment activity.&#13;
&#13;
                                            EC1â&#128;&#148;Setting clear policies&#13;
&#13;
 (Q3_III) No standardized      (Q3_III) The standardized     (Q3_III) The examination is    This option does not&#13;
 examination has taken         examination has been          a stable program that has      apply to this dimension.&#13;
 place.                        operating on an irregular     been operating regularly.&#13;
                               basis.&#13;
&#13;
 (Q3) There is no policy       (Q3) There is an informal     (Q3) There is a formal         This option does not&#13;
 document that authorizes      or draft policy document      policy document that           apply to this dimension.&#13;
 the examination.              that authorizes the           authorizes the&#13;
                               examination.                  examination.&#13;
&#13;
 This option does not apply    (Q5) The policy document      (Q5) The policy document       This option does not&#13;
 to this dimension.            is not available to the       is available to the public.    apply to this dimension.&#13;
                               public.&#13;
&#13;
 This option does not apply    This option does not apply    (Q6) The policy document       (Q6) The policy&#13;
 to this dimension.            to this dimension.            addresses some key             document addresses all&#13;
                                                             aspects of the                 key aspects of the&#13;
                                                             examination.                   examination.&#13;
&#13;
                                          EC2â&#128;&#148;Having strong leadership&#13;
&#13;
 (Q8) All stakeholder          (Q8) Most stakeholder         (Q8) Most stakeholders         (Q8) All stakeholder&#13;
 groups strongly oppose        groups oppose the             groups support the             groups support the&#13;
 the examination.              examination.                  examination.                   examination.&#13;
&#13;
 (Q9) There are no             This option does not apply    (Q9) There are                 (Q9) There are&#13;
 attempts to improve the       to this dimension.            independent attempts to        coordinated attempts to&#13;
 examination by                                              improve the examination        improve the&#13;
 stakeholder groups.                                         by stakeholder groups.         examination by&#13;
                                                                                            stakeholder groups.&#13;
&#13;
 (Q10) Efforts to improve      This option does not apply    (Q10) Efforts to improve       This option does not&#13;
 the examination are not       to this dimension.            the examination are            apply to this dimension.&#13;
 welcomed by the                                             generally welcomed by the&#13;
 leadership in charge of the                                 leadership in charge of the&#13;
 examination.                                                examination.&#13;
&#13;
                                           EC3â&#128;&#148;Having regular funding&#13;
&#13;
 (Q11) There is no funding     (Q11) There is irregular      (Q11) There is regular         This option does not&#13;
 allocated for the             funding allocated for the     funding allocated for the      apply to this dimension.&#13;
 examination.                  examination.                  examination.&#13;
&#13;
 This option does not apply    (Q12) Funding covers          (Q12) Funding covers all       This option does not&#13;
 to this dimension.            some core examination         core examination activities:   apply to this dimension.&#13;
                               activities: design,           design, administration,&#13;
                               administration, data          data processing, and&#13;
                               processing or reporting.      reporting.&#13;
&#13;
 This option does not apply    (Q12) Funding does not        Does not apply.                (Q12) Funding covers&#13;
 to this dimension.            cover research and                                           research and&#13;
                               development.                                                 development.&#13;
&#13;
&#13;
&#13;
&#13;
22                                                                                                             Marguerite Clarke&#13;
&amp;#12;      LATENT                         EMERGING                     ESTABLISHED&#13;
Absence of, or deviation          On way to meeting             Acceptable minimum                ADVANCED&#13;
  from, the attribute             minimum standard                   standard                     Best practice            Justification&#13;
&#13;
                                  EC4â&#128;&#148;Having strong organizational structures&#13;
&#13;
(Q14) The examination          (Q14) The examination          (Q14) The examination          This option does not&#13;
office does not exist or is    office is newly established.   office is a stable             apply to this dimension.&#13;
newly established.                                            organization.&#13;
&#13;
(Q15) The examination          This option does not apply     (Q15) The examination          This option does not&#13;
office is not accountable to   to this dimension.             office is accountable to an    apply to this dimension.&#13;
an external board or                                          external board or agency.&#13;
agency.&#13;
&#13;
(Q16) Examination results      (Q16) Examination results      (Q16) Examination results      (Q16) Examination&#13;
are not recognized by any      are recognized by the          are recognized by one          results are recognized&#13;
certification or selection     certification or selection     certification or selection     by two or more&#13;
system.                        system in the country.         system in another country.     certification or selection&#13;
                                                                                             systems in another&#13;
                                                                                             country.&#13;
&#13;
(Q17) The examination          (Q17) The examination          (Q17) The examination          (Q17) The examination&#13;
office does not have the       office has some of the         office has all of the          office has state-of-the-&#13;
required facilities to carry   required facilities to carry   required facilities to carry   art facilities to carry out&#13;
out the examination.           out the examination.           out the examination.           the examination.&#13;
&#13;
                                     EC5â&#128;&#148;Having effective human resources&#13;
&#13;
(Q18) There is no staff to     (Q18, Q19) The                 (Q18, Q19) The                 (Q18, Q19) The&#13;
carry out the examination.     examination office is          examination office is          examination office is&#13;
                               inadequately staffed to        adequately staffed to carry    adequately staffed to&#13;
                               effectively carry out the      out the examination            carry out the&#13;
                               examination; issues are        effectively, with minimal      assessment effectively,&#13;
                               pervasive.                     issues.                        with no issues.&#13;
&#13;
(Q20) The country/system       This option does not apply     (Q20) The country/system       (Q20) The&#13;
does not offer                 to this dimension.             offers some opportunities      country/system offers a&#13;
opportunities that prepare                                    that prepare for work on       wide range of&#13;
for work on the                                               the examination.               opportunities that&#13;
examination.                                                                                 prepare for work on the&#13;
                                                                                             examination.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                                  23&#13;
&amp;#12;       LATENT                         EMERGING                      ESTABLISHED&#13;
 Absence of, or deviation          On way to meeting              Acceptable minimum               ADVANCED&#13;
   from, the attribute             minimum standard                    standard                    Best practice          Justification&#13;
&#13;
                                              System Alignment (SA)&#13;
             Degree to which the assessment is coherent with other components of the education system.&#13;
&#13;
                   SA1â&#128;&#148;Aligning examinations with learning goals and opportunities to learn&#13;
&#13;
 (Q21) It is not clear what     This option does not apply      (Q21) There is a clear        This option does not&#13;
 the examination                to this dimension.              understanding of what the     apply to this dimension.&#13;
 measures.                                                      examination measures.&#13;
&#13;
 (Q22) What the                 This option does not apply      (Q22) What is measured        This option does not&#13;
 examination measures is        to this dimension.              by the examination is         apply to this dimension.&#13;
 questioned by some                                             largely accepted by&#13;
 stakeholder groups.                                            stakeholder groups.&#13;
&#13;
 (Q23, Q24) Material to         (Q23, Q24) There is some        (Q23, Q24) There is           (Q23, Q24) There is&#13;
 prepare for the                material to prepare for the     comprehensive material to     comprehensive material&#13;
 examination is minimal         examination that is             prepare for the               to prepare for the&#13;
 and it is accessible to very   accessible to some              examinations that is          examination that is&#13;
 few students.                  students.                       accessible to most            accessible to all&#13;
                                                                students.                     students.&#13;
&#13;
                   SA2â&#128;&#148;Providing teachers with opportunities to learn about the examination&#13;
&#13;
 (Q25) There are no             (Q25) There are no up-to-       (Q25) There are up-to-date    (Q25) There are up-to-&#13;
 courses or workshops on        date courses or                 voluntary courses or          date compulsory&#13;
 examinations available to      workshops on                    workshops on                  courses or workshops&#13;
 teachers.                      examinations available to       examinations available to     on examinations for&#13;
                                teachers.                       teachers.                     teachers.&#13;
&#13;
 (Q26) Teachers are             (Q26) Teachers are              (Q26) Teachers are            (Q26) Teachers are&#13;
 excluded from all              involved in very few            involved in some              involved in most&#13;
 examination-related tasks.     examination-related tasks.      examination-related tasks.    examination-related&#13;
                                                                                              tasks.&#13;
&#13;
                                             Assessment Quality (AQ)&#13;
           Degree to which the assessment meets quality standards, is fair, and is used in an effective way.&#13;
&#13;
                                                AQ1â&#128;&#148;Ensuring quality&#13;
&#13;
 (Q27) There is no              (Q27) There is some             (Q27) There is a              (Q27) There is a&#13;
 technical report or other      documentation on the            comprehensive technical       comprehensive, high-&#13;
 documentation.                 examination, but it is not in   report but with restricted    quality technical report&#13;
                                a formal report format.         circulation.                  available to the general&#13;
                                                                                              public.&#13;
&#13;
 (Q28) There are no             This option does not apply      (Q28) There are limited       (Q28) There are varied&#13;
 mechanisms in place to         to this dimension.              systematic mechanisms in      and systematic&#13;
 ensure the quality of the                                      place to ensure the quality   mechanisms in place to&#13;
 examination.                                                   of the examination.           ensure the quality of the&#13;
                                                                                              examination.&#13;
&#13;
&#13;
&#13;
&#13;
24                                                                                                               Marguerite Clarke&#13;
&amp;#12;      LATENT                            EMERGING                     ESTABLISHED&#13;
Absence of, or deviation             On way to meeting             Acceptable minimum                ADVANCED&#13;
  from, the attribute                minimum standard                   standard                     Best practice         Justification&#13;
&#13;
                                                 AQ2â&#128;&#148;Ensuring fairness&#13;
&#13;
(Q29) Inappropiate                (Q29) Inappropiate             (Q29) Inappropiate             (Q29) Inappropiate&#13;
behavior surrounding the          behavior surrounding the       behavior surrounding the       behavior surrounding&#13;
examination process is            examination process is         examination process is         the examination&#13;
high.                             moderate.                      low.                           process is marginal.&#13;
&#13;
(Q30) The examination             (Q30) The examination          (Q30) The examination          This option does not&#13;
results lack credibility for      results are credible for       results are credible for all   apply to this dimension.&#13;
all stakeholder groups.           some stakeholder groups.       stakeholder groups.&#13;
&#13;
(Q31, Q32) The majority of        (Q31, Q32) A significant       (Q31, Q32) A small             (Q31) All students can&#13;
students (over 50%) may           proportion of students         proportion of students (less   take the examination;&#13;
not take the examination          (10%-50%) may not take         than 10%) may not take         there are no language,&#13;
because of language,              the examination because        the examination because        gender, or other&#13;
gender or other equivalent        of language, gender or         of language, gender or         equivalent barriers.&#13;
barriers.                         other equivalent barriers.     other equivalent barriers.&#13;
&#13;
                                  AQ3â&#128;&#148;Using examination information in a fair way&#13;
&#13;
(Q33) Examination results         (Q33) Examination results      (Q33) Examination results      (Q33) Examination&#13;
are not used in an                are used by some               are used by most               results are used by all&#13;
appropriate way by all            stakeholder groups in an       stakeholder groups in an       stakeholder groups in&#13;
stakeholder groups.               appropriate way.               appropriate way.               an appropriate way.&#13;
&#13;
(Q34) Student names and           This option does not apply     (Q34) Student results are      This option does not&#13;
results are made public.          to this dimension.             confidential.                  apply to this dimension.&#13;
&#13;
                               AQ4â&#128;&#148;Ensuring positive consequences of the examination&#13;
&#13;
(Q35) There are no                (Q35) There are very           (Q35) There are some           (Q35) There are a&#13;
options for students who          limited options for students   options for students who       variety of options for&#13;
do not perform well on the        who do not perform well        do not perform well on the     students who do not&#13;
examination, or students          on the examination.            examination.                   perform well on the&#13;
must leave the education                                                                        examination.&#13;
system.&#13;
&#13;
(Q36) There are no                This option does not apply     (Q36) There are some           (Q36) There are a&#13;
mechanisms in place to            to this dimension.             mechanisms in place to         variety of mechanisms&#13;
monitor the consequences                                         monitor the consequences       in place to monitor the&#13;
of the examination.                                              of the examination.            consequences of the&#13;
                                                                                                examination.&#13;
&#13;
Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                                  25&#13;
&amp;#12;                                      National Large Scale Assessment (NLSA)&#13;
          LATENT&#13;
       Absence of, or              EMERGING                   ESTABLISHED&#13;
     deviation from, the        On way to meeting           Acceptable minimum                  ADVANCED&#13;
          attribute             minimum standard                 standard                       Best practice            Justification&#13;
&#13;
                                              Enabling Context (EC)&#13;
   Overall framework of policies, leadership, organizational structures, fiscal, and human resources in which NLSA&#13;
 activity takes place in an education system and the extent to which that framework is conducive to, or supportive of,&#13;
                                                  the NLSA activity.&#13;
&#13;
                                       EC1â&#128;&#148;Setting clear policies for NLSA&#13;
&#13;
 (Q3_III) No NLSA             (Q3_III) The NLSA has       (Q3_III) The NLSA is a         This option does not apply&#13;
 exercise has taken place.    been operating on an        stable program that has        to this dimension.&#13;
                              irregular basis.            been operating regularly.&#13;
&#13;
 (Q5) There is no policy      (Q5) There is an            (Q5) There is a formal         This option does not apply&#13;
 document pertaining to       informal or draft policy    policy document that           to this dimension.&#13;
 NLSA.                        document that               authorizes the NLSA.&#13;
                              authorizes the NLSA.&#13;
&#13;
 Does not apply.              (Q7) The policy             (Q7) The policy document       This option does not apply&#13;
                              document is not             is available to the public.    to this dimension.&#13;
                              available to the public.&#13;
&#13;
 (Q8) There is no plan for    This option does not        (Q8, Q9) There is a general    (Q8, Q9) There is a written&#13;
 NLSA activity.               apply to this dimension.    understanding that the         NLSA plan for the coming&#13;
                                                          NLSA will take place.          years.&#13;
&#13;
                                EC2â&#128;&#148;Having strong public engagement for NLSA&#13;
&#13;
 (Q11, Q12) All               (Q11, Q12) Some             (Q11, Q12) Most                (Q11, Q12) All stakeholder&#13;
 stakeholder groups           stakeholder groups          stakeholders groups            groups support the NLSA.&#13;
 strongly oppose the          oppose the NLSA.            support the NLSA.&#13;
 NLSA.&#13;
&#13;
                                      EC3â&#128;&#148;Having regular funding for NLSA&#13;
&#13;
 (Q13) There is no funding    (Q13) There is irregular    (Q13) There is regular         This option does not apply&#13;
 allocated to the NLSA.       funding allocated to the    funding allocated to the       to this dimension.&#13;
                              NLSA.                       NLSA.&#13;
&#13;
 Does not apply.              (Q14) Funding covers        (Q14) Funding covers all       This option does not apply&#13;
                              some core NLSA              core NLSA activities:          to this dimension.&#13;
                              activities: design,         design, administration,&#13;
                              administration, analysis    analysis and reporting.&#13;
                              or reporting.&#13;
&#13;
 Does not apply.              (Q14) Funding does not      This option does not apply     (Q14) Funding covers&#13;
                              cover research and          to this dimension.             research and development&#13;
                              development activities.                                    activities.&#13;
&#13;
&#13;
&#13;
&#13;
26                                                                                                              Marguerite Clarke&#13;
&amp;#12;        LATENT&#13;
     Absence of, or                 EMERGING                   ESTABLISHED&#13;
   deviation from, the           On way to meeting           Acceptable minimum                  ADVANCED&#13;
        attribute                minimum standard                 standard                       Best practice           Justification&#13;
&#13;
                               EC4â&#128;&#148;Having strong organizational structures for NLSA&#13;
&#13;
(Q15) There is no NLSA          (Q15) The NLSA office      (Q15) The NLSA office is a     This option does not apply&#13;
office, ad hoc unit or          is a temporary agency      permanent agency,              to this dimension.&#13;
team.                           or group of people.        institution, or unit.&#13;
&#13;
This option does not             (Q16, Q17) Political      (Q16, Q17) Political           (Q16, Q17) Political&#13;
apply to this dimension.        considerations regularly   considerations sometimes       considerations never&#13;
                                hamper technical           hamper technical               hamper technical&#13;
                                considerations.            considerations.                considerations.&#13;
&#13;
This option does not            (Q18, Q19) The NLSA        (Q18, Q19) The NLSA            This option does not apply&#13;
apply to this dimension.        office is not              office is accountable to a     to this dimension.&#13;
                                accountable to a clearly   clearly recognized body.&#13;
                                recognized body.&#13;
&#13;
                                 EC5â&#128;&#148;Having effective human resources for NLSA&#13;
&#13;
(Q20) ) There is no staff       (Q20, Q21) The NLSA        (Q20, Q21) The NLSA            (Q20, Q21) The NLSA&#13;
allocated for running a         office is inadequately     office is adequately staffed   office is adequately staffed&#13;
NLSA.                           staffed to effectively     to carry out the NLSA          to carry out the NLSA&#13;
                                carry out the              effectively, with minimal      effectively, with no issues.&#13;
                                assessment.                issues.&#13;
&#13;
(Q22) The                       This option does not       (Q22) The country/system       (Q22) The country/system&#13;
country/system does not         apply to this dimension.   offers some opportunities to   offers a wide range of&#13;
offer opportunities that                                   prepare individuals for work   opportunities to prepare&#13;
prepare individuals for                                    on the NLSA.                   individuals for work on the&#13;
work on NLSA.                                                                             NLSA.&#13;
&#13;
                                              System Alignment (SA)&#13;
                Degree to which the NLSA is coherent with other components of the education system.&#13;
&#13;
                                    SA1â&#128;&#148;Aligning the NLSA with learning goals&#13;
&#13;
(Q23) It is not clear if the    This option does not       (Q23) The NLSA measures        This option does not apply&#13;
NLSA is based on                apply to this dimension.   performance against            to this dimension.&#13;
curriculum or learning                                     curriculum or learning&#13;
standards.                                                 standards.&#13;
&#13;
(Q24) What the NLSA             This option does not       (Q24) What the NLSA            (Q24) What the NLSA&#13;
measures is generally           apply to this dimension.   measures is questioned by      measures is largely&#13;
questioned by                                              some stakeholder groups.       accepted by stakeholder&#13;
stakeholder groups.                                                                       groups.&#13;
&#13;
(Q25) There are no              (Q25, Q26) There are       (Q25, Q26) There are           This option does not apply&#13;
mechanisms in place to          ad hoc reviews of the      regular internal reviews of    to this dimension.&#13;
ensure that the NLSA            NLSA to ensure that it     the NLSA to ensure that it&#13;
accurately measures             measures what it is        measures what it is&#13;
what it is supposed to          intended to measure.       intended to measure.&#13;
measure.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                                27&#13;
&amp;#12;          LATENT&#13;
       Absence of, or              EMERGING                  ESTABLISHED&#13;
     deviation from, the        On way to meeting          Acceptable minimum                   ADVANCED&#13;
          attribute             minimum standard                standard                        Best practice            Justification&#13;
&#13;
                       SA2â&#128;&#148;Providing teachers with opportunities to learn about the NLSA&#13;
&#13;
 (Q27) There are no           (Q27, Q28) There are       (Q27, Q28) There are some       (Q27, Q28) There are&#13;
 courses or workshops on      occassional courses or     courses or workshops on         widely available high-&#13;
 the NLSA.                    workshops on the           the NLSA offered on a           quality courses or&#13;
                              NLSA.                      regular basis.                  workshops on the NLSA&#13;
                                                                                         offered on a regular basis.&#13;
&#13;
                                           Assessment Quality (AQ)&#13;
            Degree to which the NLSA meets technical standards, is fair, and is used in an effective way.&#13;
&#13;
                                     AQ1â&#128;&#148;Ensuring the quality of the NLSA&#13;
&#13;
 (Q29) No options are         This option does not       (Q29) At least one option is    (Q29) Different options are&#13;
 offered to include all       apply to this dimension.   offered to include all groups   offered to include all groups&#13;
 groups of students in the                               of students in the NLSA.        of students in the NLSA.&#13;
 NLSA.&#13;
&#13;
 (Q30) There are no           This option does not       (Q30) There are some            (Q30) There are a variety&#13;
 mechanisms in place to       apply to this dimension.   mechanisms in place to          of mechanisms in place to&#13;
 ensure the quality of the                               ensure the quality of the       ensure the quality of the&#13;
 NLSA.                                                   NLSA.                           NLSA.&#13;
&#13;
 (Q31) There is no            (Q31) There is some        (Q31) There is a                (Q31) There is a&#13;
 technical report or other    documentation about        comprehensive technical         comprehensive, high-&#13;
 documentation about the      the technical aspects of   report, but with restricted     quality technical report&#13;
 NLSA.                        the NLSA, but it is not    circulation.                    available to the general&#13;
                              in a formal report                                         public.&#13;
                              format.&#13;
&#13;
                                   AQ2â&#128;&#148;Ensuring effective uses of the NLSA&#13;
&#13;
 (Q32) NLSA results are       (Q32) NLSA results are     (Q32) NLSA results are          This option does not apply&#13;
 not disseminated.            poorly disseminated.       disseminated in an effective    to this dimension.&#13;
                                                         way.&#13;
&#13;
 (Q33) NLSA information       This option does not       (Q33) NLSA results are          (Q33) NLSA information is&#13;
 is not used or is used in    apply to this dimension.   used by some stakeholder        used by all stakeholder&#13;
 ways inconsistent with                                  groups in a way that is         groups in a way that is&#13;
 the purposes or the                                     consistent with the             consistent with the&#13;
 technical characteristics                               purposes and technical          purposes and technical&#13;
 of the assessment.                                      characteristics of the          characteristics of the&#13;
                                                         assessment.                     assessment.&#13;
&#13;
 (Q34) There are no           This option does not       (Q34) There are some            (Q34) There are a variety&#13;
 mechanisms in place to       apply to this dimension.   mechanisms in place to          of mechanisms in place to&#13;
 monitor the                                             monitor the consequences        monitor the consequences&#13;
 consequences of the                                     of the NLSA.                    of the NLSA.&#13;
 NLSA.&#13;
&#13;
 Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
28                                                                                                              Marguerite Clarke&#13;
&amp;#12;                                  International Large Scale Assessment (ILSA)&#13;
       LATENT&#13;
    Absence of, or                EMERGING                    ESTABLISHED&#13;
  deviation from, the          On way to meeting            Acceptable minimum                 ADVANCED&#13;
       attribute               minimum standard                  standard                      Best practice          Justification&#13;
&#13;
                                             Enabling Context (EC)&#13;
   Overall framework of policies, leadership, organizational structures, fiscal and human resources in which ILSA&#13;
  takes place in an education system and the extent to which that framework is conducive to, or supportive of, the&#13;
                                                    ILSA activity.&#13;
&#13;
                                       EC1â&#128;&#148;Setting clear policies for ILSA&#13;
&#13;
(Q1, Q2) The                 This option does not        (Q1, Q2) The                   (Q1, Q2) The&#13;
country/system has not       apply to this dimension.    country/system has             country/system has&#13;
participated in an ILSA in                               participated in at least one   participated in two or more&#13;
the last 10 years.                                       ILSA in the last 10 years.     ILSA in the last 10 years.&#13;
&#13;
(Q3) The country/system      This option does not        (Q3) The country/system        This option does not apply&#13;
has not taken concrete       apply to this dimension.    has taken concrete steps       to this dimension.&#13;
steps to participate in an                               to participate in at least&#13;
ILSA in the next 5 years.                                one ILSA in the next 5&#13;
                                                         years.&#13;
&#13;
(Q5) There is no policy      (Q5) There is an informal   (Q5) There is a formal         This option does not apply&#13;
document that addresses      or draft policy document    policy document that           to this dimension.&#13;
participation in ILSA.       that addresses              addresses participation in&#13;
                             participation in ILSA.      ILSA.&#13;
&#13;
Does not apply.              (Q7) The policy             (Q7) The policy document       This option does not apply&#13;
                             document is not             is available to the public.    to this dimension.&#13;
                             available to the public.&#13;
&#13;
                                     EC2â&#128;&#148;Having regular funding for ILSA&#13;
&#13;
(Q8) There is no funding     (Q9) There is funding       (Q9) There is regular          (Q9) There is regular&#13;
for participation in ILSA.   from loans or external      funding allocated at           funding approved by law,&#13;
                             donors.                     discretion.                    decree or norm.&#13;
&#13;
This option does not         (Q10) Funding covers        (Q10) Funding covers all       This option does not apply&#13;
apply to this dimension.     some core activities of     core activities of the ILSA.   to this dimension.&#13;
                             the ILSA.&#13;
&#13;
(Q10) Funding does not       This option does not        This option does not apply     (Q10) Funding covers&#13;
cover research and           apply to this dimension.    to this dimension.             research and development&#13;
development activities.                                                                 activities.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                             29&#13;
&amp;#12;          LATENT&#13;
       Absence of, or              EMERGING                  ESTABLISHED&#13;
     deviation from, the        On way to meeting          Acceptable minimum                 ADVANCED&#13;
          attribute             minimum standard                standard                      Best practice            Justification&#13;
&#13;
                                EC3â&#128;&#148;Having effective human resources for ILSA&#13;
&#13;
 (Q11, Q12) There is no       (Q11, Q12) There is a      (Q11, Q12) There is a          This option does not apply&#13;
 team or national/system      team or national/system    team and national/system       to this dimension.&#13;
 coordinator to carry out     coordinator to carry out   coordinator to carry out the&#13;
 the ILSA activities.         the ILSA activities.       ILSA activities.&#13;
&#13;
 This option does not         (Q13) The                  (Q13) The national/system      This option does not apply&#13;
 apply to this dimension.     national/system            coordinator is fluent in the   to this dimension.&#13;
                              coordinator or other       official language of the&#13;
                              designated team            ILSA exercise.&#13;
                              member is not fluent in&#13;
                              the official language of&#13;
                              the ILSA exercise.&#13;
&#13;
 This option does not         (Q13, Q14, Q15) The        (Q13, Q14, Q15) The ILSA       (Q13, Q14, Q15) The ILSA&#13;
 apply to this dimension.     ILSA office is             office is adequately staffed   office is adequately staffed&#13;
                              inadequately staffed or    or trained to carry out the    and trained to carry out the&#13;
                              trained to carry out the   ILSA effectively, with         ILSA effectively, with no&#13;
                              assessment effectively.    minimal issues.                issues.&#13;
&#13;
                                             System Alignment (SA)&#13;
                Degree to which the ILSA is coherent with other components of the education system.&#13;
&#13;
                                SA1â&#128;&#148;Providing opportunities to learn about ILSA&#13;
&#13;
 (Q14) The ILSA team has      (Q14) The ILSA team        (Q14) The ILSA team            This option does not apply&#13;
 not attended international   attended some              attended all international     to this dimension.&#13;
 workshops or meetings.       international workshops    workshops or meetings.&#13;
                              or meetings.&#13;
&#13;
 (Q16) The                    This option does not       (Q16, Q17) The                 (Q16,Q17) The&#13;
 country/system offers no     apply to this dimension.   country/system offers          country/system offers a&#13;
 opportunities to learn                                  some opportunities to learn    wide range of opportunities&#13;
 about ILSA.                                             about ILSA.                    to learn about ILSA.&#13;
&#13;
 This option does not         This option does not       (Q18) Opportunities to         (Q18) Opportunities to&#13;
 apply to this dimension.     apply to this dimension.   learn about ILSA are           learn about ILSA are&#13;
                                                         available to the               available to a wide&#13;
                                                         country's/system's ILSA        audience, in addition to the&#13;
                                                         team members only.             country's/system's ILSA&#13;
                                                                                        team members.&#13;
&#13;
&#13;
&#13;
&#13;
30                                                                                                            Marguerite Clarke&#13;
&amp;#12;       LATENT&#13;
    Absence of, or                EMERGING                    ESTABLISHED&#13;
  deviation from, the          On way to meeting            Acceptable minimum                  ADVANCED&#13;
       attribute               minimum standard                  standard                       Best practice           Justification&#13;
&#13;
                                          Assessment Quality (AQ)&#13;
        Degree to which the ILSA meets technical quality standards, is fair, and is used in an effective way.&#13;
&#13;
                                       AQ1â&#128;&#148;Ensuring the quality of ILSA&#13;
&#13;
(Q19) Data from the ILSA     (Q19) The                    (Q19) The country/system        This option does not apply&#13;
has not been published.      country/system met           met all technical standards     to this dimension.&#13;
                             sufficient standards to      required to have its data&#13;
                             have its data presented      presented in the main&#13;
                             beneath the main display     displays of the international&#13;
                             of the                       report.&#13;
                             international report or in&#13;
                             an annex.&#13;
&#13;
(Q20) The                    This option does not         This option does not apply      (Q20) The country/system&#13;
country/system has not       apply to this dimension.     to this dimension.              has contributed new&#13;
contributed new                                                                           knowledge on ILSA.&#13;
knowledge on ILSA.&#13;
&#13;
                                     AQ2â&#128;&#148;Ensuring effective uses of ILSA&#13;
&#13;
(Q21, Q22) If any,           (Q21, Q22)                   (Q21, Q22)                      (Q21, Q22)&#13;
country/system-specific      Country/system-specific      Country/system-specific         Country/system-specific&#13;
results and information      results and information      results and information are     results and information are&#13;
are not disseminated in      are disseminated             regularly disseminated in       regularly and widely&#13;
the country/system.          irregularly in the           the country/system.             disseminated in the&#13;
                             country/system.                                              country/system.&#13;
&#13;
(Q21, Q23) Products to       This option does not         (Q21, Q23) Products to          (Q21, Q23) Products to&#13;
provide feedback to          apply to this dimension.     provide feedback to             provide feedback to&#13;
schools and educators                                     schools and educators           schools and educators&#13;
about the ILSA results                                    about the ILSA results are      about ILSA results are&#13;
are not made available.                                   sometimes made available.       systematically made&#13;
                                                                                          available.&#13;
&#13;
(Q24) There is no media      (Q24) There is limited       (Q24) There is some media       (Q24) There is wide media&#13;
coverage of the ILSA         media coverage of the        coverage of the ILSA            coverage of the ILSA&#13;
results.                     ILSA results.                results.                        results.&#13;
&#13;
(Q25, Q26) If any,           (Q26) Results from the       (Q26) Results from the          (Q26) Results from the&#13;
country/system-specific      ILSA are used in a           ILSA are used in some           ILSA are used in a variety&#13;
results and information      limited way to inform        ways to inform decision         of ways to inform decision&#13;
from the ILSA are not        decision making in the       making in the                   making in the&#13;
used to inform decision      country/system.              country/system.                 country/system.&#13;
making in the&#13;
country/system.&#13;
&#13;
(Q27) It is not clear that   This option does not         This option does not apply      (Q27) Decisions based on&#13;
decisions based on ILSA      apply to this dimension.     to this dimension.              the ILSA results have had&#13;
results have had a                                                                        a positive impact on&#13;
positive impact on                                                                        students' achievement&#13;
students' achievement                                                                     levels.&#13;
levels.&#13;
&#13;
Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                               31&#13;
&amp;#12;Appendix 3. Example of Using the Rubrics to Evaluate a&#13;
National Large Scale Assessment Program&#13;
                                                                                                                                       Preliminary&#13;
                                       COUNTRY X                                                                                         Level of&#13;
                                                                                                                                      Development&#13;
                         National Large-Scale Assessment (NLSA)                                                Adjusted                 (based on&#13;
                                          Rubric                                                              Score (with   Default      Adjusted&#13;
                                                                                                      Score   Constraint)   Weight        Score)      Notes&#13;
&#13;
                       EMERGING&#13;
   LATENT               On way to       ESTABLISHED&#13;
Absence of, or           meeting         Acceptable                                                   2.32       2.11         1       EMERGING&#13;
deviation from,         minimum           minimum           ADVANCED&#13;
 the attribute          standard          standard          Best practice       JUSTIFICATION&#13;
                        Enabling Context (EC)&#13;
Overall framework of policies, leadership, organizational structures, fiscal,&#13;
and human resources in which NLSA activity takes place in an education                                2.63        2          0.33      Emerging&#13;
   system and the extent to which that framework is conducive to, or&#13;
                    supportive of, the NLSA activity.&#13;
                   EC1â&#128;&#148;Setting clear policies for NLSA                                                 2          2           0.2&#13;
&#13;
(Q3_III) No NLSA   (Q3_III) The   (Q3_III) The  This option does                    In 2009, the&#13;
  exercise has   NLSA has been NLSA is a stable not apply to this               NLSA program in&#13;
  taken place.   operating on an  program that    dimension.                      Country X was&#13;
                 irregular basis.   has been                                      operating on a&#13;
                                    operating                                      regular basis.&#13;
                                    regularly.                                  However, funding&#13;
                                                                                  for the various&#13;
                                                                                 NLSA exercises&#13;
                                                                                                       3                     0.25                    Constraint&#13;
                                                                                     was being&#13;
                                                                                   sourced from&#13;
                                                                                 different donors,&#13;
                                                                                      and the&#13;
                                                                                   assessments&#13;
                                                                                were taking place&#13;
                                                                                roughly every 3 to&#13;
                                                                                      4 years.&#13;
(Q5) There is no      (Q5) There is     (Q5) There is a    This option does     In 2009, Country&#13;
policy document       an informal or      formal policy    not apply to this      X did not have&#13;
  pertaining to        draft policy      document that       dimension.         any kind (formal,&#13;
                                                                                                       1                     0.25                    Constraint&#13;
     NLSA.            document that      authorizes the                         informal, draft) of&#13;
                      authorizes the         NLSA.                               policy document&#13;
                          NLSA.                                                 on NLSA activity.&#13;
 Does not apply.     (Q7) The policy    (Q7) The policy    This option does       There was no&#13;
                     document is not     document is       not apply to this    policy document&#13;
                                                                                                       1                     0.25&#13;
                     available to the   available to the     dimension.         available in 2009.&#13;
                         public.            public.&#13;
(Q8) There is no       This option      (Q8, Q9) There      (Q8, Q9) There       Although there&#13;
 plan for NLSA        does not apply      is a general        is a written       was no formal&#13;
    activity.            to this         understanding       NLSA plan for      policy document&#13;
                       dimension.        that the NLSA        the coming        underpinning the&#13;
                                        will take place.         years.          NLSA in 2009,&#13;
                                                                                  there was a&#13;
                                                                                                       3                     0.25&#13;
                                                                                     general&#13;
                                                                                 understanding&#13;
                                                                                 that the NLSA&#13;
                                                                                would take place&#13;
                                                                                  every 3 to 4&#13;
                                                                                      years.&#13;
&#13;
&#13;
&#13;
&#13;
32                                                                                                                                     Marguerite Clarke&#13;
&amp;#12;                                                                                                                                      Preliminary&#13;
                                      COUNTRY X                                                                                         Level of&#13;
                                                                                                                                     Development&#13;
                        National Large-Scale Assessment (NLSA)                                                Adjusted                 (based on&#13;
                                         Rubric                                                              Score (with   Default      Adjusted&#13;
                                                                                                     Score   Constraint)   Weight        Score)      Notes&#13;
&#13;
                     EMERGING&#13;
   LATENT             On way to       ESTABLISHED&#13;
Absence of, or         meeting         Acceptable                                                    2.32       2.11         1       EMERGING&#13;
deviation from,       minimum           minimum            ADVANCED&#13;
 the attribute        standard          standard           Best practice      JUSTIFICATION&#13;
         EC2â&#128;&#148;Having strong public engagement for NLSA                                                 4                      0.2&#13;
&#13;
 (Q11, Q12) All       (Q11, Q12)        (Q11, Q12)        (Q11, Q12) All         Based on our&#13;
   stakeholder           Some               Most            stakeholder        information, there&#13;
 groups strongly     stakeholder       stakeholders       groups support      is no opposition to     4                      1&#13;
   oppose the       groups oppose     groups support         the NLSA.             the NLSA.&#13;
      NLSA.            the NLSA.         the NLSA.&#13;
               EC3â&#128;&#148;Having regular funding for NLSA                                                    2          2           0.2&#13;
&#13;
(Q13) There is no (Q13) There is      (Q13) There is      This option does    NLSA activity is&#13;
funding allocated irregular funding   regular funding     not apply to this partially funded by&#13;
  to the NLSA.     allocated to the   allocated to the      dimension.         the MOE and&#13;
                        NLSA.              NLSA.                                 partially by         2                     0.33                    Constraint&#13;
                                                                                donors. The&#13;
                                                                             funding is still ad&#13;
                                                                                    hoc.&#13;
Does not apply.     (Q14) Funding     (Q14) Funding       This option does       Funding has&#13;
                     covers some      covers all core     not apply to this    tended to cover&#13;
                      core NLSA       NLSA activities:      dimension.             only basic&#13;
                       activities:       design,                              aspects of NLSA&#13;
                        design,       administration,                              activities.&#13;
                                                                                                      2                     0.33&#13;
                    administration,    analysis and                           Sometimes, there&#13;
                      analysis or       reporting.                                 has been&#13;
                       reporting.                                                 insufficient&#13;
                                                                               funding to cover&#13;
                                                                              all core activities.&#13;
Does not apply.     (Q14) Funding     This option does     (Q14) Funding         Funding has&#13;
                    does not cover    not apply to this   covers research     primarily focused&#13;
                     research and       dimension.              and           on supporting the&#13;
                     development                            development        actual carrying&#13;
                       activities.                           activities.         out of NLSA          2                     0.33&#13;
                                                                              activities and not&#13;
                                                                                  on R&amp;D or&#13;
                                                                                  secondary&#13;
                                                                                   analysis.&#13;
      EC4â&#128;&#148;Having strong organizational structures for NLSA                                           2.67        2           0.2&#13;
&#13;
(Q15) There is no    (Q15) The      (Q15) The             This option does         In 2009, the&#13;
 NLSA office, ad NLSA office is a NLSA office is a        not apply to this     NLSA team was&#13;
 hoc unit or team.   temporary      permanent               dimension.           comprised of a&#13;
                   agency or group   agency,                                    small number of&#13;
                      of people.   institution or                              staff (4), some of&#13;
                                        unit.                                     whom had no&#13;
                                                                                 background or&#13;
                                                                                                      2                     0.33                    Constraint&#13;
                                                                               training in NLSA.&#13;
                                                                                 There was no&#13;
                                                                                permanent unit,&#13;
                                                                                      and an&#13;
                                                                              institutional home&#13;
                                                                                 was still being&#13;
                                                                                   worked out.&#13;
This option does      (Q16, Q17)        (Q16, Q17)          (Q16, Q17)           There is no&#13;
not apply to this       Political         Political           Political        precedence of&#13;
  dimension.        considerations    considerations      considerations           political&#13;
                       regularly        sometimes          never hamper        considerations         4                     0.33&#13;
                        hamper            hamper             technical           hampering&#13;
                       technical         technical        considerations.         technical&#13;
                    considerations.   considerations.                          considerations.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                                                        33&#13;
&amp;#12;                                                                                                                                         Preliminary&#13;
                                       COUNTRY X                                                                                           Level of&#13;
                                                                                                                                        Development&#13;
                         National Large-Scale Assessment (NLSA)                                                  Adjusted                 (based on&#13;
                                          Rubric                                                                Score (with   Default      Adjusted&#13;
                                                                                                        Score   Constraint)   Weight        Score)     Notes&#13;
&#13;
                      EMERGING&#13;
   LATENT              On way to         ESTABLISHED&#13;
Absence of, or          meeting           Acceptable                                                    2.32       2.11         1       EMERGING&#13;
deviation from,        minimum             minimum            ADVANCED&#13;
 the attribute         standard            standard           Best practice      JUSTIFICATION&#13;
This option does     (Q18, Q19) The (Q18, Q19) The This option does                 In 2009, the&#13;
not apply to this     NLSA office is  NLSA office is  not apply to this           NLSA office was&#13;
  dimension.         not accountable accountable to a   dimension.                not accountable&#13;
                       to a clearly      clearly                                     to a clearly&#13;
                       recognized      recognized                                recognized body.&#13;
                                                                                                         2                     0.33&#13;
                          body.           body.                                  This is because it&#13;
                                                                                  was in transition&#13;
                                                                                      from one&#13;
                                                                                 institutional home&#13;
                                                                                     to another.&#13;
          EC5â&#128;&#148;Having effective human resources for NLSA                                                  2.5                    0.2&#13;
&#13;
(Q20) ) There is     (Q20, Q21) The      (Q20, Q21) The      (Q20, Q21) The         In 2009, the&#13;
no staff allocated    NLSA office is      NLSA office is      NLSA office is      NLSA office did&#13;
  for running a       inadequately          adequately          adequately       not have sufficient&#13;
      NLSA.              staffed to       staffed to carry    staffed to carry   staff to effectively    2                      0.5&#13;
                     effectively carry     out the NLSA        out the NLSA       carry out NLSA&#13;
                          out the        effectively, with   effectively, with        activities.&#13;
                      assessment.        minimal issues.        no issues.&#13;
    (Q22) The         This option           (Q22) The           (Q22) The        There were some&#13;
 country/system      does not apply      country/system      country/system         large-scale&#13;
  does not offer        to this            offers some         offers a wide     assessment- and&#13;
opportunities that    dimension.         opportunities to         range of         measurement-&#13;
     prepare                                 prepare         opportunities to     related courses        3                      0.5&#13;
  individuals for                         individuals for         prepare          offered by the&#13;
 work on NLSA.                             work on the        individuals for    main university in&#13;
                                              NLSA.            work on the           Country X.&#13;
                                                                   NLSA.&#13;
                       System Alignment (SA)&#13;
  Degree to which the NLSA is coherent with other components of the                                      2                     0.33      Emerging&#13;
                         education system.&#13;
             SA1â&#128;&#148;Aligning the NLSA with learning goals                                                   3                      0.5&#13;
&#13;
  (Q23) It is not     This option          (Q23) The    This option does          The NLSA was&#13;
clear if the NLSA    does not apply      NLSA measures not apply to this           aligned with&#13;
   is based on          to this           performance     dimension.                  existing&#13;
  curriculum or       dimension.             against                              curriculum and         3                     0.33&#13;
     learning                             curriculum or                             standards.&#13;
    standards.                              learning&#13;
                                           standards.&#13;
(Q24) What the        This option         (Q24) What the     (Q24) What the   The MOE and&#13;
NLSA measures        does not apply      NLSA measures       NLSA measures        other&#13;
  is generally          to this          is questioned by       is largely  stakeholders have&#13;
                                                                                                         4                     0.33&#13;
 questioned by        dimension.               some           accepted by      accepted the&#13;
  stakeholder                               stakeholder        stakeholder        NLSA.&#13;
    groups.                                   groups.            groups.&#13;
 (Q25) There are         (Q25, Q26)         (Q25, Q26)       This option does       In 2009, there&#13;
 no mechanisms         There are ad          There are       not apply to this        were some&#13;
in place to ensure    hoc reviews of      regular internal     dimension.           procedures in&#13;
  that the NLSA         the NLSA to        reviews of the                              place for&#13;
     accurately        ensure that it    NLSA to ensure                             reviewing the&#13;
 measures what it    measures what       that it measures                         alignment of the&#13;
  is supposed to     it is intended to        what it is                           NLSA test with&#13;
     measure.             measure.          intended to                                   the            2                     0.33&#13;
                                             measure.                            constructs/content&#13;
                                                                                 it was intended to&#13;
                                                                                     measure, but&#13;
                                                                                 these procedures&#13;
                                                                                       were not&#13;
                                                                                     formalized or&#13;
                                                                                    standardized.&#13;
&#13;
&#13;
&#13;
&#13;
34                                                                                                                                       Marguerite Clarke&#13;
&amp;#12;                                                                                                                                       Preliminary&#13;
                                        COUNTRY X                                                                                        Level of&#13;
                                                                                                                                      Development&#13;
                          National Large-Scale Assessment (NLSA)                                               Adjusted                 (based on&#13;
                                           Rubric                                                             Score (with   Default      Adjusted&#13;
                                                                                                      Score   Constraint)   Weight        Score)     Notes&#13;
&#13;
                       EMERGING&#13;
   LATENT               On way to       ESTABLISHED&#13;
Absence of, or           meeting         Acceptable                                                   2.32       2.11         1       EMERGING&#13;
deviation from,         minimum           minimum            ADVANCED&#13;
 the attribute          standard          standard           Best practice      JUSTIFICATION&#13;
SA2â&#128;&#148;Providing teachers with opportunities to learn about the NLSA                                      1                      0.5&#13;
&#13;
(Q27) There are        (Q27, Q28)         (Q27, Q28)           (Q27, Q28)       The only courses&#13;
 no courses or          There are       There are some      There are widely      or workshops&#13;
workshops on the       occassional         courses or        available high-     associated with&#13;
     NLSA.              courses or       workshops on        quality courses     previous NLSA&#13;
                      workshops on         the NLSA         or workshops on      exercises have&#13;
                        the NLSA.         offered on a          the NLSA              been for         1                      1&#13;
                                         regular basis.        offered on a     policymakers and&#13;
                                                              regular basis.        high-level&#13;
                                                                                 educators, and&#13;
                                                                                not for classroom&#13;
                                                                                     teachers.&#13;
                      Assessment Quality (AQ)&#13;
                                                                                                                                      Emerging or&#13;
Degree to which the NLSA meets technical standards, is fair and is used                               2.33                   0.33&#13;
                                                                                                                                      Established&#13;
                        in an effective way.&#13;
                AQ1â&#128;&#148;Ensuring the quality of the NLSA                                                  2.67                    0.5&#13;
&#13;
(Q29) No options       This option      (Q29) At least      (Q29) Different         The NLSA is&#13;
  are offered to      does not apply     one option is        options are       translated into the&#13;
include all groups       to this           offered to          offered to           language of&#13;
of students in the     dimension.         include all         include all          instruction for     3                     0.33&#13;
      NLSA.                                groups of           groups of            each region.&#13;
                                        students in the     students in the&#13;
                                            NLSA.               NLSA.&#13;
 (Q30) There are       This option      (Q30) There are (Q30) There are            In 2009, there&#13;
  no mechanisms       does not apply          some            a variety of           were some&#13;
in place to ensure       to this         mechanisms in      mechanisms in          procedures in&#13;
 the quality of the    dimension.        place to ensure place to ensure              place for&#13;
      NLSA.                             the quality of the the quality of the      reviewing the&#13;
                                             NLSA.              NLSA.            alignment of the&#13;
                                                                                  NLSA test with&#13;
                                                                                         the&#13;
                                                                                constructs/content&#13;
                                                                                                       3                     0.33&#13;
                                                                                it was intended to&#13;
                                                                                   measure. This&#13;
                                                                                would allow us to&#13;
                                                                                   say that there&#13;
                                                                                    were 'some&#13;
                                                                                  mechanisms in&#13;
                                                                                  place to ensure&#13;
                                                                                 the quality of the&#13;
                                                                                       NLSA.'&#13;
(Q31) There is no     (Q31) There is    (Q31) There is a    (Q31) There is a In 2009, no formal&#13;
 technical report          some          comprehensive      comprehensive, technical reports&#13;
     or other         documentation     technical report,      high-quality   were available for&#13;
  documentation          about the           but with        technical report    the NLSA.&#13;
 about the NLSA.         technical          restricted       available to the                          2                     0.33&#13;
                      aspects of the       circulation.       general public.&#13;
                      NLSA, but it is&#13;
                      not in a formal&#13;
                       report format.&#13;
              AQ2â&#128;&#148;Ensuring effective uses of the NLSA                                                  2                      0.5&#13;
&#13;
  (Q32) NLSA           (Q32) NLSA         (Q32) NLSA        This option does      In 2009, NLSA&#13;
 results are not        results are        results are      not apply to this    results were not&#13;
 disseminated.            poorly        disseminated in       dimension.           being widely&#13;
                      disseminated.        an effective                          disseminated to&#13;
                                                                                                       2                     0.33&#13;
                                              way.                              key stakeholders.&#13;
                                                                                Few copies of the&#13;
                                                                                    report were&#13;
                                                                                     available.&#13;
&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                                                                                      35&#13;
&amp;#12;                                                                                                                                  Preliminary&#13;
                                      COUNTRY X                                                                                     Level of&#13;
                                                                                                                                 Development&#13;
                        National Large-Scale Assessment (NLSA)                                            Adjusted                 (based on&#13;
                                         Rubric                                                          Score (with   Default      Adjusted&#13;
                                                                                                 Score   Constraint)   Weight        Score)     Notes&#13;
&#13;
                      EMERGING&#13;
   LATENT              On way to      ESTABLISHED&#13;
Absence of, or          meeting        Acceptable                                                2.32       2.11         1       EMERGING&#13;
deviation from,        minimum          minimum          ADVANCED&#13;
 the attribute         standard         standard         Best practice      JUSTIFICATION&#13;
   (Q33) NLSA         This option        (Q33) NLSA       (Q33) NLSA           In 2009, the&#13;
information is not   does not apply   results are used   information is       NLSA results&#13;
used or is used in      to this            by some         used by all      were, to a certain&#13;
ways inconsistent     dimension.         stakeholder      stakeholder        extent, used for&#13;
with the purposes                     groups in a way groups in a way           curriculum&#13;
  or the technical                          that is    that is consistent   development and&#13;
                                                                                                  3                     0.33&#13;
characteristics of                     consistent with       with the       teacher training.&#13;
 the assessment.                        the purposes     purposes and&#13;
                                        and technical       technical&#13;
                                       characteristics characteristics of&#13;
                                            of the     the assessment.&#13;
                                        assessment.&#13;
(Q34) There are       This option     (Q34) There are    (Q34) There are      In 2009, there&#13;
 no mechanisms       does not apply         some            a variety of          were no&#13;
   in place to          to this        mechanisms in      mechanisms in       mechanisms in&#13;
   monitor the        dimension.      place to monitor   place to monitor    place to monitor     1                     0.33&#13;
consequences of                              the                the         the consequences&#13;
   the NLSA.                           consequences       consequences         of the NLSA.&#13;
                                        of the NLSA.       of the NLSA.&#13;
&#13;
Source: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
36                                                                                                                                Marguerite Clarke&#13;
&amp;#12;References&#13;
Airasian, P., and M. Russell. 2007. Classroom Assessment: Concepts and Applications&#13;
     (6th ed.). New York: McGrath Hill.&#13;
Au, W. 2007. â&#128;&#156;High Stakes Testing and Curricular Control: A Qualitative&#13;
    Metasynthesis.â&#128;? Educational Researcher 36(5): 258â&#128;&#147;67.&#13;
American Educational Research Association (AERA), American Psychological&#13;
    Association (APA), and National Council on Measurement in Education&#13;
    (NCME). 1999. Standards for Educational and Psychological Testing.&#13;
    Washington, DC: AERA.&#13;
Bennett, R. E. 2011. â&#128;&#156;Formative Assessment: A Critical Review.â&#128;? Assessment in&#13;
    Education: Principles, Policy and Practice 18(1): 5â&#128;&#147;25.&#13;
Bishop, J., F. Mane, and M. Bishop. 2001. â&#128;&#156;Secondary Education in the United&#13;
     States: What Can Others Learn from Our Mistakes?â&#128;? CAHRS Working&#13;
     Paper Series. Cornell Center for Advanced Human Resource Studies&#13;
     (CAHRS).&#13;
Black, P., and D. Wiliam. 1998. â&#128;&#156;Assessment and Classroom Learning.â&#128;?&#13;
     Assessment in Education: Principles, Policy and Practice 5(1): 7â&#128;&#147;73.&#13;
Braun, H., and A. Kanjee. 2006. â&#128;&#156;Using Assessment to Improve Education in&#13;
     Developing Nations.â&#128;? In J. Cohen, D. Bloom, and M. Malin, eds., Educating&#13;
     All Children: A Global Agenda. Cambridge, MA: American Academy of Arts&#13;
     and Sciences.&#13;
Bray, M., and L. Steward, eds. 1998. Examination Systems in Small States:&#13;
     Comparative Perspectives on Policies, Models and Operations. London: The&#13;
     Commonwealth Secretariat.&#13;
Brinkley, M., J. Guthrie, and T. Wyatt. 1991. A Survey of National Assessment and&#13;
     Examination Practices in OECD Countries. Lugano, Switzerland: OECD.&#13;
Carnoy, M., and S. Loeb. 2002. â&#128;&#156;Does External Accountability Affect Student&#13;
     Outcomes? A Cross State Analysis.â&#128;? Educational Evaluation and Policy&#13;
     Analysis 24(4): 305â&#128;&#147;331.&#13;
Clarke, M. 2007. â&#128;&#156;State Responses to the No Child Left Behind Act: The&#13;
     Uncertain Link between Implementation and â&#128;&#152;Proficiency for Allâ&#128;&#153;.â&#128;? In C.&#13;
     Kaestle and A. Lodewick, eds., To Educate a Nation: Federal and National&#13;
     Strategies of School Reform (pp. 144â&#128;&#147;174). Lawrence: University of Kansas&#13;
     Press.&#13;
Darling Hammond, L., and L. Wentworth. 2010. Benchmarking Learning Systems:&#13;
     Student Performance Assessment in International Context. Stanford, CA:&#13;
     Stanford University, Stanford Center for Opportunity Policy in Education.&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                   37&#13;
&amp;#12;     Ferrer, G. 2006. Educational Assessment Systems in Latin America: Current Practice&#13;
          and Future Challenges. Washington, DC: Partnership for Educational&#13;
          Revitalization in the Americas.&#13;
     Fuchs, L. S., and D. Fuchs. 1986. â&#128;&#156;Effects of Systematic Formative Evaluation on&#13;
          Student Achievement: A Meta Analysis.â&#128;? Exceptional Children 53: 199â&#128;&#147;208.&#13;
     Fuhrman, S., and D. Elmore, eds. 1994. Governing Curriculum. Alexandria, VA:&#13;
         ASCD.&#13;
     Gove, A., and P. Cvelich. 2011. Early Reading: Igniting Education for All. A Report&#13;
          by the Early Grade Learning Community of Practice. Revised Edition. Research&#13;
          Triangle Park, NC: Research Triangle Institute.&#13;
     Greaney, V., and T. Kellaghan. 2008. Assessing National Achievement Levels in&#13;
          Education. Washington, DC: World Bank.&#13;
     â&#128;&#148;â&#128;&#148;â&#128;&#148;. 1995. Equity Issues in Public Examinations in Developing Countries.&#13;
       Washington, DC: World Bank.&#13;
     Hamilton, L., B. Stecher, and S. Klein., eds. 2002. Making Sense of Test Based&#13;
         Accountability in Education. Santa Monica, CA: RAND Corporation.&#13;
     Hanushek, E., and M. Raymond. 2003. â&#128;&#156;Lessons about the Design of State&#13;
         Accountability Systems.â&#128;? In P. Peterson and M. West, eds., No Child Left&#13;
         Behind? The Politics and Practice of Accountability (pp. 127â&#128;&#147;151). Washington,&#13;
         DC: Brookings Institution Press.&#13;
     Hanushek, E., and L. Woessmann. 2009. â&#128;&#156;Schooling, Cognitive Skills, and the&#13;
         Latin American Growth Puzzle.â&#128;? Working Paper 15066. Cambridge, MA:&#13;
         National Bureau of Economic Research.&#13;
     â&#128;&#148;â&#128;&#148;â&#128;&#148;. 2007. Education Quality and Economic Growth. Washington, DC: World&#13;
       Bank.&#13;
     Heubert, J., and R. Hauser. 1999. High Stakes: Testing for Tracking, Promotion, and&#13;
         Graduation. Washington, DC: National Academy Press.&#13;
     Hill, P. 2010. Examination Systems. Asia Pacific Secondary Education System&#13;
           Review Series. Bangkok: UNESCO.&#13;
     Hoxby, C. 2002. â&#128;&#156;The Cost of Accountability.â&#128;? NBER Working Paper Series No.&#13;
         w8855. Cambridge, MA: National Bureau of Economic Research. Available&#13;
         at SSRN: http://ssrn.com/abstract=305599.&#13;
     Independent Evaluation Group (IEG). 2006. From Schooling Access to Learning&#13;
          Outcomes: An Unfinished Agenda. Washington, DC: World Bank.&#13;
     Kifer, E. 2001. Large Scale Assessment: Dimensions, Dilemmas, and Policy. Thousand&#13;
           Oaks, CA: Corwin Press, Inc.&#13;
&#13;
&#13;
&#13;
&#13;
38                                                                      Marguerite Clarke&#13;
&amp;#12;Larach, L., and M. Lockheed. 1992. â&#128;&#156;World Bank Lending for Educational&#13;
     Testing.â&#128;? PHREE Background Paper, 92/62R. Population and Human&#13;
     Resources Department. Washington, DC: World Bank.&#13;
Liberman, J., and M. Clarke. 2012. Review of World Bank Support for Assessment&#13;
     Activities in Client Countries. Unpublished manuscript. Washington, DC:&#13;
     World Bank.&#13;
Lockheed, M. 2009. Review of Donor Support for Assessment Capacity Building in&#13;
     Developing Countries. Unpublished manuscript. Washington, DC: World&#13;
     Bank.&#13;
Macintosh, H. 1994. A Comparative Study of Current Theories and Practices in&#13;
     Assessing Studentsâ&#128;&#153; Achievements at Primary and Secondary Level. IBE&#13;
     Document Series, Number 4. Geneva, Switzerland: International Bureau of&#13;
     Education.&#13;
Madaus, G., and M. Clarke. 2001. â&#128;&#156;The Impact of High Stakes Testing on&#13;
    Minority Students.â&#128;? In M. Kornhaber and G. Orfield, eds., Raising Standards&#13;
    or Raising Barriers: Inequality and High Stakes Testing in Public Education (pp.&#13;
    85â&#128;&#147;106). New York: Century Foundation.&#13;
Madaus G., M. Clarke, and M. Oâ&#128;&#153;Leary. 2003. â&#128;&#156;A Century of Standardized&#13;
    Mathematics Testing.â&#128;? In G. M.A. Stanic and J. Kilpatrick, eds., A History of&#13;
    School Mathematics (pp. 1311â&#128;&#147;1434). Reston, VA: NCTM.&#13;
McDermott, K. A. 2011. High Stakes Reform: The Politics of Educational&#13;
    Accountability. Washington, DC: Georgetown University Press.&#13;
McKinsey &amp; Company. 2007. How the Worldâ&#128;&#153;s Best Performing School Systems Come&#13;
    Out On Top. London: McKinsey &amp; Company.&#13;
Messick, S. 1989. â&#128;&#156;Validity.â&#128;? In R. Linn, ed., Educational Measurement (3rd ed.) (pp.&#13;
     13â&#128;&#147;103). New York: American Council on Education/Macmillan.&#13;
Organisation for Economic Co operation and Development (OECD). 2010. The&#13;
    High Cost of Low Educational Performance. The Long Run Economic Impact of&#13;
    Improving PISA Outcomes. Paris: OECD.&#13;
Ravela, P. 2005. â&#128;&#156;A Formative Approach to National Assessments: The Case of&#13;
     Uruguay.â&#128;? Prospects 35(1): 21â&#128;&#147;43.&#13;
Ravela, P., P. Arregui, G. Valverde, R. Wolfe, G. Ferrer, F. Martinez, M. Aylwin,&#13;
     and L. Wolff. 2008. â&#128;&#156;The Educational Assessments that Latin America&#13;
     Needs.â&#128;? Working Paper Series No. 40. Washington, DC: Partnership for&#13;
     Educational Revitalization in the Americas (PREAL).&#13;
Ravela, P., P. Arregui, G. Valverde, R. Wolfe, G. Ferrer, F. M. Rizo, M. Aylwin,&#13;
     and L. Wolff. 2009. â&#128;&#156;The Educational Assessments that Latin America&#13;
     Needs.â&#128;? Washington, DC: PREAL.&#13;
&#13;
&#13;
&#13;
What Matters Most for Student Assessment Systems: A Framework Paper                     39&#13;
&amp;#12;     Rodriguez, M. C. 2004. â&#128;&#156;The Role of Classroom Assessment in Student&#13;
          Performance on TIMSS.â&#128;? Applied Measurement in Education 17(1): 1â&#128;&#147;24.&#13;
     Shepard, L. 2000. â&#128;&#156;The Role of Assessment in a Learning Culture.â&#128;? Educational&#13;
          Researcher 29(7): 4â&#128;&#147;14.&#13;
     Smith, M. S., and J. Oâ&#128;&#153;Day. 1991. â&#128;&#156;Systemic School Reform.â&#128;? In S. H. Fuhrman&#13;
          and B. Malen, eds., The Politics of Curriculum and Testing, 1990 Yearbook of the&#13;
          Politics of Education Association (pp. 233â&#128;&#147;267). London and Washington, DC:&#13;
          Falmer Press.&#13;
     United Nations Educational, Scientific, and Cultural Organization (UNESCO).&#13;
          2007. Education for All Global Monitoring Report 2008: Education for All by&#13;
          2015. Will We Make It? Paris: UNESCO/Oxford University Press.&#13;
     West, R., and J. Crighton. 1999. â&#128;&#156;Examination Reform in Central and Eastern&#13;
          Europe: Issues and Trends.â&#128;? Assessment in Education 6(2): 271â&#128;&#147;280.&#13;
     Wolff, L. 2007. The Costs of Student Assessment in Latin America. Washington, DC:&#13;
          PREAL.&#13;
     World Bank. 2010. Russia Education Aid for Development (READ) Trust Fund&#13;
         Annual Report 2009. Washington, DC: World Bank.&#13;
&#13;
&#13;
&#13;
&#13;
40                                                                        Marguerite Clarke&#13;
&amp;#12;&amp;#12;The purpose of this paper is to provide an overview of what matters most&#13;
for building a more effective student assessment system. The focus is on&#13;
systems for assessing student learning and achievement at the primary&#13;
and secondary levels. The paper extracts principles and guidelines from&#13;
countriesâ&#128;&#153; experiences, professional testing standards, and the current&#13;
research base. The goal is to provide national policy makers, education&#13;
PLQLVWU\ RIÃ&#128;FLDOV&amp;#15; GHYHORSPHQW RUJDQL]DWLRQ VWDII&amp;#15; DQG RWKHU VWDNHKROGHUV&#13;
with a framework and key indicators for diagnosis, discussion, and&#13;
consensus-building around how to construct a sound and sustainable&#13;
student assessment system that will support improved education quality&#13;
and learning for all.&#13;
&#13;
Marguerite Clarke, Senior Education Specialist, Human Development&#13;
Network, the World Bank&#13;
&#13;
&#13;
&#13;
&#13;
The Russia Education Aid for Development Trust Fund is a collaboration between the Russian Federation&#13;
and the World Bank that supports the improvement of student learning outcomes in low-income countries&#13;
through the development of robust student assessment systems. Visit the READ website at&#13;
www.worldbank.org/readtf for additional information.&#13;
&amp;#12;</ml:original-txt><ml:search-metadata><doc id="16238771">
        <url>
            http://documents.worldbank.org/curated/en/2012/04/16238771/matters-most-student-assessment-systems-framework-paper
        </url>
        <availablein>Russian,French,English</availablein>
        <fullavailablein>
            <available_in lang="Russian" entityid="000333038_20121025002822" node_id="16238771"/>
            <available_in lang="French" entityid="000442464_20140714121424" node_id="16238771"/>
        </fullavailablein>
        <url_friendly_title>http://documents.worldbank.org/curated/en/2012/04/16238771/matters-most-student-assessment-systems-framework-paper</url_friendly_title>
        <new_url>2012/04/16238771/matters-most-student-assessment-systems-framework-paper</new_url>
        <disclosure_date>2012-04-23T00:00:00Z</disclosure_date>
        <disclosure_type>NA</disclosure_type>
        <ext_pub_date>2012-04-23T00:00:00Z</ext_pub_date>
        <disclstat>Disclosed</disclstat>
        <docm_id>090224b0828c15b3</docm_id>
        <chronical_docm_id>090224b0828c15b3</chronical_docm_id>
        <txturl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2012/04/24/000386194_20120424010525/Rendered/INDEX/682350WP00PUBL0WP10READ0web04019012.txt</txturl>
        <pdfurl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2012/04/24/000386194_20120424010525/Rendered/PDF/682350WP00PUBL0WP10READ0web04019012.pdf</pdfurl>
        <datestored>2012-04-24T00:00:00Z</datestored>
        <docdt>2012-04-19T00:00:00Z</docdt>
        <totvolnb>1</totvolnb>
        <versiontyp>Final</versiontyp>
        <versiontyp_key>1309935</versiontyp_key>
        <volnb>1</volnb>
        <repnme>
            What matters most for student assessment
            systems : a framework paper
        </repnme>
        <abstracts>
            The purpose of this paper is to provide
            an overview of what matters most for building a more
            effective student assessment system. The focus is on systems
            for assessing student learning and achievement at the
            primary and secondary levels. The paper extracts principles
            and guidelines from countries' experiences,
            professional testing standards, and the current research
            base. The goal is to provide national policy makers,
            education ministry officials, development organization
            staff, and other stakeholders with a framework and key
            indicators for diagnosis, discussion, and consensus building
            around how to construct a sound and sustainable student
            assessment system that will support improved education
            quality and learning for all.
        </abstracts>
        <docna>
            What matters most for student assessment
            systems : a framework paper
        </docna>
        <display_title>What matters most for student
            assessment systems : a framework paper</display_title>
        <listing_relative_url>/research/2012/04/16238771/matters-most-student-assessment-systems-framework-paper</listing_relative_url>
        <docty>Working Paper (Numbered Series)</docty>
        <subtopic>Public Examination System,Education For All,Primary Education,Secondary Education,Tertiary Education</subtopic>
        <teratopic>Education</teratopic>
        <count>World</count>
        <authors>
            <author>Clarke,Margaret M.</author>
        </authors>
        <entityids>
            <entityid>000386194_20120424010525</entityid>
        </entityids>
        <admreg>The World Region,The World Region</admreg>
        <colti>Systems Approach for Better Education
            Results (SABER) student assessment working paper,no. 1</colti>
        <lang>English</lang>
        <historic_topic>Education</historic_topic>
        <majdocty>Publications &amp; Research</majdocty>
        <keywd>
            achievement tests, aptitude, assessment
            activity, assessment exercise, assessment strategies,
            Assessment System, backwash effect, benefits of education,
            candidates, Capacity building, career, certificate,
            certification, class size, classroom, classroom activities,
            classroom instruction, classroom level, classroom teacher,
            classroom teachers, classrooms, completion rates, compulsory
            education, curricula, curriculum, data processing, decision
            making, disadvantaged groups, early grades, early reading,
            economic growth, Education Aid, education budget, education
            community, education ministries, education policy, education
            reform, Education Sector, education strategy, education
            system, education systems, educational achievement,
            educational interventions, educational materials,
            educational opportunities, educational practices,
            Educational Quality, educators, effect on student
            achievement, elements, eligible students, enrollment, equal
            opportunity, examination office, examination performance,
            examination process, examination questions, examination
            results, examination scores, examination systems,
            examinations, external examination, foundation skills,
            global knowledge, high school, high stakes examinations,
            higher education, higher education quality, higher levels of
            education, Human Development, Human resources, individual
            students, instruction, International Student Assessment,
            interventions, item bank, language group, language of
            instruction, leadership, learning, learning outcomes,
            learning standards, levels of education, literacy,
            literature, mathematics, multiple choice, national
            assessment, national education, national education budget,
            national policy makers, Nongovernmental organizations,
            official curriculum, papers, political influence, private
            partnerships, private tutoring, problem solving,
            professional standards, public examinations, pupil spending,
            quality of education, quality standards, quota systems,
            reading, reading skills, reliability, school management,
            school system, schooling, schools, Science Study, scores,
            secondary school, secondary school examinations, student
            achievement, STUDENT ASSESSMENT, Student Assessment Systems,
            student learning, student learning outcomes, student
            performance, student population, student responses, subject
            areas, subjects, teacher, teacher training, teachers,
            teaching, technical quality, technological advances,
            tertiary level, test design, test item, test results, test
            score, test scores, textbooks, training opportunities,
            transparency, universities, upper secondary, validity
        </keywd>
        <owner>Education Team (HDNED)</owner>
        <repnb>68235</repnb>
        <alt_title>
            L'essentiel en matiere de systeme
            d'evaluation des eleves : document-cadre
            Os pontos mais relevantes para os
            Sistemas de Avaliação de Estudantes : um documento-quadro
        </alt_title>
    </doc></ml:search-metadata><ml:annotations><ml:concepts><ml:concept>Finance and Development</ml:concept><ml:concept>Finance and Financial Sector Development</ml:concept><ml:concept>Teaching and Learning</ml:concept><ml:concept>General Public Administration Sector</ml:concept><ml:concept>Governance and Public Sector Management</ml:concept><ml:concept>Government</ml:concept><ml:concept>Institutions</ml:concept><ml:concept>Public Administration</ml:concept><ml:concept>Public Sector Development</ml:concept><ml:concept>Public Sector Management and Reform</ml:concept><ml:concept>Public Sector and Governance</ml:concept><ml:concept>Social Protections and Labor</ml:concept><ml:concept>Financial Sector Development</ml:concept><ml:concept>Private Sector Development</ml:concept><ml:concept>Education</ml:concept><ml:concept>Health, Nutrition and Population</ml:concept><ml:concept>Public Sector Management</ml:concept><ml:concept>Social Protection and Labor</ml:concept><ml:concept>Human Resource Management Capacities</ml:concept><ml:concept>Human Resource Management Systems</ml:concept><ml:concept>Staffing Needs Assessments</ml:concept><ml:concept>Education Reform and Management</ml:concept><ml:concept>Teacher Professional Development</ml:concept><ml:concept>Student Learning Assessment</ml:concept><ml:concept>Textbooks</ml:concept><ml:concept>Higher Education</ml:concept><ml:concept>Tertiary Education – Enhancing Access, Equity and Quality</ml:concept><ml:concept>Education Quality</ml:concept><ml:concept>Quality and Education</ml:concept><ml:concept>Demographics</ml:concept><ml:concept>Longevity</ml:concept><ml:concept>Analysis &amp; Monitoring</ml:concept><ml:concept>Delivery Units</ml:concept><ml:concept>Grievance Redress</ml:concept><ml:concept>Indicators</ml:concept><ml:concept>M&amp;E</ml:concept><ml:concept>Performance Measurement</ml:concept><ml:concept>Performance Reviews</ml:concept><ml:concept>Rapid Results Approaches</ml:concept><ml:concept>Income</ml:concept><ml:concept>Public Examination System</ml:concept><ml:concept>Banking</ml:concept><ml:concept>Boundaries</ml:concept><ml:concept>Copyright</ml:concept><ml:concept>Human Resources</ml:concept><ml:concept>Education Reform</ml:concept><ml:concept>Examinations</ml:concept><ml:concept>Teacher Training</ml:concept><ml:concept>Learning Assessment</ml:concept><ml:concept>Teaching and Learning Materials</ml:concept><ml:concept>Language of Instruction</ml:concept><ml:concept>Policy Framework</ml:concept><ml:concept>Infrastructure</ml:concept><ml:concept>Tertiary Education</ml:concept><ml:concept>Quality of Education</ml:concept><ml:concept>Population</ml:concept><ml:concept>Aging</ml:concept><ml:concept>Monitoring and Evaluation</ml:concept></ml:concepts><ml:geo-regions/></ml:annotations></ml:doc-envelope>