<?xml version="1.0" encoding="UTF-8"?><ml:doc-envelope xmlns:ml="http://marklogic.com/poolparty/worldbank"><ml:original-txt>                             43155&#13;
What Can WBI Learn from&#13;
the Participants, Task&#13;
Team Leaders, and Systems&#13;
Records of its Learning&#13;
Activities? A Review of&#13;
Client Learning&#13;
&#13;
Jaime B. Quizon&#13;
Joy Behrens&#13;
Basab Dasgupta&#13;
Cristina Ling&#13;
Oliver Rajakaruna&#13;
Dawn Roberts&#13;
&amp;#12;&#13;
&amp;#12;&#13;
What Can WBI Learn&#13;
from the Participants,&#13;
Task Team Leaders, and&#13;
Systems Records of its&#13;
Learning Activities? A&#13;
Review of Client&#13;
Learning&#13;
&#13;
Jaime Quizon&#13;
&#13;
Joy Behrens&#13;
&#13;
Basab Dasgupta&#13;
&#13;
Cristina Ling&#13;
&#13;
Oliver Rajakaruna&#13;
&#13;
Dawn Roberts&#13;
&#13;
&#13;
&#13;
&#13;
WBI Evaluation Studies&#13;
No. EG08-138&#13;
&#13;
The World Bank Institute&#13;
The World Bank&#13;
Washington, D.C.&#13;
&#13;
January 2008&#13;
&amp;#12;&#13;
                                 Acknowledgments&#13;
&#13;
       The World Bank Institute Evaluation Group (WBIEG) prepared this report under&#13;
the direction of Richard Tobin (manager until June 2007). Jaime Quizon served as the&#13;
task team leader.&#13;
&#13;
       The authors wish to thank the WBI Task Team Leaders (TTLs) who gave&#13;
generously of their time to participate in interviews for this analysis. Much appreciation&#13;
also goes to the staff of the World Bank Institute's Office of the Chief Administrative&#13;
Officer (WBICA), including Bernard Harragan and Manar Eliriqsousi, for help with&#13;
extracting systems data.&#13;
&#13;
       The authors thank Hnin Hnin Pyne and Marian S. Delos Angeles who peer&#13;
reviewed this study. Nidhi Khattri and Violaine le Rouzic also offered valuable&#13;
suggestions for its improvement. Finally, the authors thank Humberto S. Diaz for his&#13;
assistance with formatting and graphics.&#13;
&#13;
       WBIEG evaluates learning by staff of the World Bank and activities of the World&#13;
Bank Institute (WBI). The Institute supports the World Bank's learning and knowledge&#13;
agenda by providing learning programs and policy services in the areas of governance,&#13;
knowledge for development, human development, environment and sustainable&#13;
development, poverty reduction and economic management, and finance and private&#13;
sector development. The findings, interpretations, and conclusions expressed in WBI&#13;
Evaluation Studies are entirely those of the authors and do not necessarily represent the&#13;
views of the World Bank Group, including WBI.&#13;
&#13;
       WBI Evaluation Studies are available at http://www.worldbank.org/wbi/evaluation&#13;
&#13;
       Suggested citation: Quizon, Jaime, Joy Behrens, Basab Dasgupta, Cristina Ling,&#13;
Oliver Rajakaruna, and Dawn Roberts (2008). What Can WBI Learn from its WBICRS&#13;
Records and Participant Assessments? A Review of Client Learning. Report No. EG08-&#13;
138. Washington, DC: World Bank Institute.&#13;
&#13;
&#13;
&#13;
&#13;
Vice President, World Bank Institute                             Rakesh Nangia, Acting&#13;
&#13;
Manager, Institute Evaluation Group                              Nidhi Khattri, Acting&#13;
&#13;
Task Team Leader                                                 Jaime B. Quizon&#13;
&#13;
&#13;
&#13;
&#13;
                                              ii&#13;
&amp;#12;&#13;
                                                   Contents&#13;
&#13;
EXECUTIVE SUMMARY ....................................................................................................... v&#13;
&#13;
   Participants.................................................................................................................... v&#13;
&#13;
   Program design and delivery ....................................................................................... vi&#13;
&#13;
   Partnerships.................................................................................................................. vi&#13;
&#13;
   Performance within the World Bank Institute ............................................................. vi&#13;
&#13;
   Recommendations.......................................................................................................vii&#13;
&#13;
1. INTRODUCTION............................................................................................................. 1&#13;
&#13;
2. PARTICIPANTS .............................................................................................................. 5&#13;
&#13;
   Regression results ......................................................................................................... 5&#13;
&#13;
   Reflections from task team leaders............................................................................... 7&#13;
&#13;
3. PROGRAM DESIGN AND DELIVERY............................................................................... 9&#13;
&#13;
   Regression results ......................................................................................................... 9&#13;
&#13;
   Reflections from task team leaders............................................................................. 11&#13;
&#13;
4. PARTNERSHIPS............................................................................................................ 12&#13;
&#13;
   Regression results ....................................................................................................... 12&#13;
&#13;
   Reflections from task team leaders............................................................................. 12&#13;
&#13;
5. PERFORMANCE WITHIN THE WORLD BANK INSTITUTE ........................................... 15&#13;
&#13;
   Regression results ....................................................................................................... 15&#13;
&#13;
   Reflections from task team leaders............................................................................. 16&#13;
&#13;
6. RECOMMENDATIONS.................................................................................................. 18&#13;
&#13;
APPENDIXES&#13;
&#13;
   Appendix A: WBICRS and Level 1 evaluation variables .......................................... 21&#13;
&#13;
   Appendix B: Data and methods................................................................................. 24&#13;
&#13;
   Appendix C: Topic guide and questions for TTL interviews ..................................... 28&#13;
&#13;
   Appendix D: List of variables used for regression analysis ....................................... 30&#13;
&#13;
&#13;
&#13;
&#13;
                                                            iii&#13;
&amp;#12;&#13;
                 Acronyms and abbreviations&#13;
&#13;
AIS     Activity Initiation Summary&#13;
&#13;
OLS     Ordinary least squares&#13;
&#13;
Plato   WBI's electronic Planning Tool&#13;
&#13;
PTDs    Participant training days&#13;
&#13;
SAP     The Bank's cost accounting system&#13;
&#13;
TTL     Task team leader&#13;
&#13;
WBI     World Bank Institute&#13;
&#13;
WBICRS  World Bank Institute Client Registration System&#13;
&#13;
WBIEG   World Bank Institute Evaluation Group&#13;
&#13;
WBIEN   World Bank Institute Environment and Natural Resource Management&#13;
        Division, former name of World Bank Institute Sustainable Development&#13;
        Division&#13;
&#13;
WBIES   World Bank Institute Evaluation and Scholarships Unit, former name of&#13;
        World Bank Institute Evaluation Group&#13;
&#13;
WBIFP   World Bank Institute Finance and Private Sector Development Division&#13;
&#13;
WBIHD   World Bank Institute Human Development Division&#13;
&#13;
WBIKL   World Bank Institute Knowledge and Learning Services&#13;
&#13;
WBIMO   World Bank Institute office in Moscow&#13;
&#13;
WBIPR   World Bank Institute Poverty Reduction and Economic Management&#13;
        Division&#13;
&#13;
WBIRC   World Bank Institute Regional Coordination Unit&#13;
&#13;
WBISD   World Bank Institute Sustainable Development Division&#13;
&#13;
WBIST   World Bank Institute Sector and Thematic Programs&#13;
&#13;
&#13;
&#13;
&#13;
                                    iv&#13;
&amp;#12;&#13;
                           EXECUTIVE SUMMARY&#13;
&#13;
        This review identified recommendations for improving the quality of future&#13;
World Bank Institute (WBI) programs. The recommendations are based on regression&#13;
analyses of data from FY04-05 on 736 activities in WBI's Client Registration System&#13;
(WBICRS) and associated assessments collected from participants at the end of each&#13;
activity. The regressions explored which factors might explain participants' ratings of&#13;
the overall usefulness (and other indicators of quality) of WBI learning events. Interviews&#13;
with 26 task team leaders (TTLs) further clarified ideas and key concerns. WBI is&#13;
moving toward a programmatic approach to capacity development, and learning activities&#13;
remain an integral part of this strategy. Although the data analyzed do not reflect&#13;
activities in FY06 or FY07, the extended effort to clean, merge, and analyze reliable data&#13;
from past learning activities yielded relevant findings for strengthening WBI programs.&#13;
&#13;
                                       PARTICIPANTS&#13;
&#13;
        Data from the WBICRS and participant assessments provided evidence on which&#13;
participant characteristics tended to improve ratings of learning events. Factors that were&#13;
associated with an increase in participants' ratings for overall usefulness included&#13;
&#13;
        · An increase in the share of female participants and&#13;
&#13;
        · A concentration of participants from a region (rather than a broader&#13;
            worldwide representation or a single country representation).&#13;
&#13;
        Factors that decreased ratings for overall usefulness included&#13;
&#13;
        · An increase in the number of participants in an activity and&#13;
&#13;
        · Having a greater proportion of participants from international organizations.&#13;
&#13;
        Interviews with TTLs highlighted participant characteristics associated with&#13;
successful activities, including that they should&#13;
&#13;
        · View their participation in the learning activity as something they want to do&#13;
            to accomplish their goals,&#13;
&#13;
        · Have the authority to make relevant policy decisions following the event,&#13;
&#13;
        · Hold a position in which they can use their acquired knowledge and skills,&#13;
&#13;
&#13;
&#13;
&#13;
                                              v&#13;
&amp;#12;&#13;
        · Be higher level policy makers or researchers who can build capacity for the&#13;
           government, and&#13;
&#13;
        · Be part of a network where they can continue to share experiences.&#13;
&#13;
                             PROGRAM DESIGN AND DELIVERY&#13;
&#13;
        Some factors related to the design and delivery of learning events also influenced&#13;
participants' ratings for overall usefulness and other desired outcomes. Holding the WBI&#13;
learning activity in a low-income country increased the event's overall usefulness rating.&#13;
Events that targeted skills building were rated to be more useful than those focused on&#13;
general knowledge or policy. Electronic or blended learning programs both rated higher&#13;
in overall usefulness compared with face-to-face delivery. Action learning did not&#13;
emerge as a determinant of overall usefulness, but it was also not a clearly defined or&#13;
consistently used variable in the WBICRS.&#13;
&#13;
        TTLs described "the key ingredients of a successful activity," frequently&#13;
emphasizing the use of relevant content and effective materials to match local demand&#13;
and the general quality of design and delivery. As with the regression analysis, the&#13;
interview data revealed a lack of common understanding about what qualifies as action&#13;
learning.&#13;
&#13;
                                       PARTNERSHIPS&#13;
&#13;
        Common contributions by partners in WBI events include funding, content, event&#13;
delivery, and access to knowledge networks or communities of practice. Existing data on&#13;
WBI learning programs for FY04-05 lack sufficient reliable details about partnerships to&#13;
support the systematic analysis of these joint efforts, and the regressions indicated that&#13;
the one partner variable did not influence ratings for overall usefulness or other&#13;
outcomes. This finding underscored the need for WBI to continue to refine the collection&#13;
of data on learning activities.&#13;
&#13;
        TTLs described the roles of partners for WBI programs and reflected on the&#13;
factors needed for a successful partnership. Recurrent themes were that ideal partners&#13;
should (a) make a clearly identified contribution, (b) have a long-term or ongoing&#13;
commitment to collaborate with WBI, and (c) have a long-term plan for how to generate&#13;
the income or other funding necessary to continue their work. TTLs also emphasized the&#13;
importance of working with local partners to ensure that the right participants are selected&#13;
and the logistics are handled smoothly. These reflections during interviews revealed a&#13;
lack of common approach to defining or characterizing partnerships among TTLs.&#13;
&#13;
                  PERFORMANCE WITHIN THE WORLD BANK INSTITUTE&#13;
&#13;
        Participant assessment ratings varied between WBI divisions and over time.&#13;
Learning events had higher average ratings for overall usefulness when delivered by&#13;
WBI's Environment and Natural Resource Management Division (WBIEN), Poverty&#13;
Reduction and Economic Management Division (WBIPR), Human Development&#13;
Division (WBIHD), or other divisions rather than by WBI's Finance and Private Sector&#13;
&#13;
&#13;
                                              vi&#13;
&amp;#12;&#13;
Development Division (WBIFP). In addition, ratings for overall usefulness for WBI&#13;
learning events increased in the second half of FY05 compared with the first six months&#13;
of FY04.&#13;
&#13;
        Interviews with TTLs solicited advice on how to improve WBI programs, and the&#13;
resulting recommendations most frequently focused on (i) improving the coordination&#13;
between WBI and Bank operations, (ii) ending the emphasis on participant training days,&#13;
and (iii) integrating evaluation better into program design and delivery.&#13;
&#13;
                                    RECOMMENDATIONS&#13;
&#13;
        Results of this analysis shed light on the factors that are likely to increase the&#13;
quality of learning or capacity development. Specifically, the factors identified are&#13;
associated with higher participant assessment ratings, but they do not necessarily result in&#13;
better learning outcomes. Considerations for program design and delivery are that events&#13;
are likely to be more useful for attendees if they have&#13;
&#13;
        · Fewer participants,&#13;
&#13;
        · A greater share of female participants,&#13;
&#13;
        · Fewer representatives of international organizations participating,&#13;
&#13;
        · A focus on skills building,&#13;
&#13;
        · Delivery in a low-income country, and&#13;
&#13;
        · A delivery mode of electronic or blended learning, or a level of advance&#13;
            planning and pedagogical structure comparable to those needed for electronic&#13;
            or blended learning.&#13;
&#13;
        Findings also warrant organizational improvements within WBI, some of which&#13;
are already underway. This review highlighted the need for more systematic&#13;
coordination between WBI TTLs and Bank operational staff. Interviews underscored the&#13;
value of decreasing the emphasis on counting the number of participants and considering&#13;
this measure as part of an overall package of performance indicators. TTLs want&#13;
evaluation to be more fully integrated into their programs--by defining the program's&#13;
logic at the outset, collecting baseline data, designing a monitoring and evaluation plan&#13;
that includes participant assessments, and following up with participants over time.&#13;
Finally, WBI managers should have direct experience with WBI programs in order to&#13;
supply the needed guidance and support to TTLs.&#13;
&#13;
        This review identified suggestions for increasing data quality to support WBI's&#13;
programmatic approach. Definitions of variables need to be standardized. Learning&#13;
activity data should be readily accessible to evaluation officers and accompanied by a&#13;
transparent codebook. A detailed systems strategy to increase the coordination among&#13;
WBICRS, Plato, and SAP and to minimize the reporting burden for TTLs will be helpful.&#13;
Activity-specific data and participant perceptions of the relevance and usefulness of&#13;
&#13;
&#13;
                                              vii&#13;
&amp;#12;&#13;
individual events are important building blocks for higher-level indicators linked to&#13;
organizational development. Overall, the findings and recommendations of this review&#13;
support WBIEG's engagement in ongoing efforts to refine data systems and to establish&#13;
comprehensive indicators for assessing WBI's programmatic approach to capacity&#13;
enhancement.&#13;
&#13;
&#13;
&#13;
&#13;
                                           viii&#13;
&amp;#12;&#13;
                                  1.       INTRODUCTION&#13;
&#13;
1.1       The World Bank Institute (WBI) has a wealth of data on learning programs for&#13;
clients from which to derive valuable lessons for task team leaders (TTLs) and managers.&#13;
This review provides guidance for improving the quality of future learning events&#13;
through both the analysis of existing data and interviews with TTLs to highlight ideas and&#13;
key concerns.&#13;
&#13;
1.2       Since FY02, WBI's Client Registration System (WBICRS) has recorded data on&#13;
learning activities and now has information on several thousand discrete learning events.&#13;
Activity-level data on the features of learning events and the characteristics of&#13;
participants are relevant for managerial use in institutional decisionmaking.1 Although&#13;
not all the WBICRS records are complete or reliable, WBI's Monthly Monitoring&#13;
Reports as well as communications from systems developers suggest that there has been&#13;
steady improvement in data quality with increasing compliance among WBI staff in&#13;
entering information. WBI asks participants to complete a standard postactivity&#13;
questionnaire in which participants assess the learning event in which they participated.2&#13;
Response data from these questionnaires provide activity-specific feedback to TTLs and&#13;
populate WBI's Monthly Monitoring Report, periodic Quality Reports, and other reports&#13;
for WBI managers.&#13;
&#13;
1.3       Data from the WBICRS and participant assessments have already proven their&#13;
worth as useful learning and managerial tools. However, participant assessment data&#13;
have rarely been used as outcome variables in regression analysis with WBICRS data or&#13;
triangulated with TTL interviews.3 This review merged WBICRS data and participant&#13;
assessments to explore the following questions:&#13;
&#13;
          · What key participants' characteristics, activity-level variables, and exogenous&#13;
              factors explain participants' ratings of the overall usefulness (and other&#13;
              indicators of quality) of WBI learning events?&#13;
&#13;
          · Are there significant differences in assessment ratings across WBI thematic&#13;
              groups or over time?&#13;
&#13;
&#13;
1There are ongoing efforts to improve the links between WBI's local systems (WBICRS, Plato) and other&#13;
Bankwide data systems--such as SAP and Business Warehouse. These efforts are intended to streamline&#13;
data input and increase the timeliness and quality of information available on specific WBI activities.&#13;
2These questionnaires gauge participants' immediate reactions to learning events and are often referred to&#13;
as Level 1 evaluations.&#13;
3Another study is Liu, Chaoying, Shreyasi Jha, and Tingting Yang, (2006), What Influences the Outcomes&#13;
of WBI's Learning Programs? -- Evidence from WBIEG Evaluations. Report No. EG06-117. World Bank&#13;
Institute. Washington, DC. This study conducted ordinary least squares regressions on a subset of data&#13;
from the WBI CRS and participant assessments to identify which features of client learning programs&#13;
contribute to improved participant assessments.&#13;
&#13;
&#13;
                                                      1&#13;
&amp;#12;&#13;
          · What can WBI TTLs do to improve these assessments of their activities?&#13;
&#13;
          · How might the WBICRS/participant assessment database be improved to&#13;
              provide more relevant and useful information for institutional learning?&#13;
&#13;
1.4       Creating a merged dataset required identifying the current activity-level variables&#13;
in the WBICRS and then mapping variables from participant assessments (i.e., activity&#13;
and participant level) to these WBICRS activities. A list of the variables and their&#13;
definitions for this merged dataset is in appendix A.4 Because data from the WBICRS&#13;
and participant assessments are less complete and reliable for early years (FY02-03), this&#13;
review focused on activities delivered in FY04-05.&#13;
&#13;
1.5       Multiple regression analyses of data on 736 learning activities investigated the&#13;
key factors that might explain participants' assessments of the events' overall usefulness,&#13;
relevance to current work, provision of new information, usefulness of this new&#13;
information, focus on what a participant specifically needed to learn, and extent to which&#13;
the content matched the announced objectives. In addition, this review explored 27&#13;
learning events more extensively by reviewing available data and interviewing the&#13;
TTLs.5 This process was designed to develop a qualitative understanding of how factors&#13;
might explain participant ratings and to explore TTLs' concerns and ideas for improving&#13;
the impact of learning programs. These 27 offerings represented a random sample of the&#13;
highest- and lowest rated FY04-FY05 WBI activities. Additional details on the&#13;
methodology for this review are in appendix B, and the questions used for interviews&#13;
with TTLs are in appendix C.&#13;
&#13;
1.6       Readers will note the limitations of this study--namely that the data analyzed do&#13;
not reflect learning activities in FY06 or FY07, and that the scope focuses on individual&#13;
learning activities in an era when WBI is moving toward a programmatic approach to&#13;
capacity development, meaning that activities are delivered as part of a coordinated series&#13;
to build organizational capacity.6 In fact, activities for individuals remain an integral part&#13;
of WBI's programmatic approach, and the extended effort to clean, merge, and analyze&#13;
reliable data from past learning activities yielded relevant findings about participants,&#13;
program design and delivery features, and partnerships.&#13;
&#13;
1.7       This review represents a learning process for merging participant assessment and&#13;
learning activity data that can guide continued improvement of WBI's data systems. At&#13;
the start of this process, participant assessment data for FY06 and FY07 were not yet&#13;
available, so the analysis focused on data through FY05.7 A major focus of the data&#13;
&#13;
4Included are variables as they exist currently and potential variables whose definitions require&#13;
clarification from their WBI sources. In some cases, coding is not consistent across the WBICRS and&#13;
participant assessment datasets, and the recommendations of this review include guidance on improving&#13;
data quality.&#13;
5One TTL represented two of the sampled activities, so 26 TTLs were interviewed about 27 activities.&#13;
6WBI is formalizing this new approach in the FY08 work program planning process. All learning and&#13;
capacity building activities conducted to achieve a development objective in a country for a subprogram of&#13;
a thematic group are to be defined by a single concept note.&#13;
7Aggregate results on participant assessment data for FY06 and FY07 (based on descriptive statistics rather&#13;
than multiple regression analysis) are available on WBI's Quality Reports intranet site,&#13;
&#13;
&#13;
                                                     2&#13;
&amp;#12;&#13;
management effort for this paper was to address problems with missing values in the&#13;
analysis dataset and to merge data originating from various WBI units to allow for a&#13;
simple time series. The methodology, now tested, could be replicated to clarify further&#13;
what factors contribute to effectiveness and impact--given adequate access to the&#13;
WBICRS and Plato datasets and adequate resources to cover time consuming data&#13;
scrubbing as well as data analysis.&#13;
&#13;
&#13;
&#13;
&#13;
http://intranet.worldbank.org/WBSITE/INTRANET/UNITS/WBIINT/0,,contentMDK:20326329~pagePK:&#13;
135700~piPK:135698~theSitePK:136975,00.html.&#13;
&#13;
&#13;
                                              3&#13;
&amp;#12;&#13;
4&#13;
&amp;#12;&#13;
                                     2.        PARTICIPANTS&#13;
&#13;
2.1      Attracting and selecting appropriate participants is an important part of good&#13;
learning design. Data collected via the WBICRS and from participant assessments&#13;
provided evidence on which participant characteristics tended to increase ratings of&#13;
learning events. These data, combined with the reflections of experienced TTLs,&#13;
underscore the value of reaching the right participants rather than the most participants.&#13;
&#13;
                                           REGRESSION RESULTS&#13;
&#13;
2.2      In designing the regression analysis, we hypothesized that the collective profile of&#13;
participants in a learning event and the characteristics of individual respondents who&#13;
assess the event might serve as explanatory factors for activity ratings. Analyses for this&#13;
review explored such variables as the total number of participants, the share of female&#13;
participants, the share of international representatives, whether World Bank staff were&#13;
present, and the degree to which the mix of participants represented the country, the&#13;
region, or the world. The significance of these factors as explanatory variables is&#13;
presented in table 1.&#13;
&#13;
2.3      Several variables influenced ratings for an event's overall usefulness and other&#13;
related indicators of quality. However, an important caveat accompanying findings&#13;
throughout this report relates to an issue that often arises in evaluations based on&#13;
administrative data: the regression results in this report do find some explanatory factors,&#13;
but they also show that most of the variance in participants' assessments of the overall&#13;
usefulness of WBI learning activities can not be explained (R2=0.17).8 Factors related to&#13;
the mix of participants that do explain some of the variance in assessments are&#13;
highlighted below:&#13;
&#13;
         · Total number of participants: The number of participants in a learning event&#13;
              was negatively correlated with participants' assessments of the event's overall&#13;
              usefulness. In other words, larger numbers of participants in events resulted&#13;
              in lower assessment ratings. If the number of participants in a learning event&#13;
              increased by 100, the event's average usefulness ratings would drop by about&#13;
              2 percent. Thus, any push to raise the number of participants (for example, to&#13;
              increase the number of participant training days or PTDs) comes with a small&#13;
&#13;
&#13;
&#13;
&#13;
8R2, the coefficient of determination, is the proportion of the variation in assessment ratings that can be&#13;
attributed to the variation of a particular independent variable.&#13;
&#13;
&#13;
                                                       5&#13;
&amp;#12;&#13;
              "quality" tradeoff in terms of the participants' ratings of the learning event's&#13;
              usefulness.9&#13;
&#13;
         · Gender: An increase in the share of female participants in an activity raised&#13;
              the activity's overall usefulness ratings. Although female participants&#13;
              typically rated WBI activities higher than their male counterparts, this pattern&#13;
              of higher ratings was only part of the story--the increased presence of female&#13;
              participants also raised males' ratings for overall usefulness of the same event.&#13;
              10 One anecdotal explanation for this finding is that females bring in different&#13;
              perspectives and tend to engage in a more interactive learning style, creating a&#13;
              more highly valued learning experience for all participants. In short, there is a&#13;
              defensible case for including more female participants in WBI learning&#13;
              events, as all participants benefit more than if the event were largely male-&#13;
              dominated.&#13;
&#13;
         · Share of participants from international organizations: An increase in the&#13;
              proportion of participants from international organizations present decreased&#13;
              the average overall usefulness rating of the learning event, as well as the&#13;
              average ratings on four other indicators. A possible explanation for this&#13;
              finding is that WBI events are tailored, in general, to address the practical&#13;
              needs of in-country clients representing their governments and civil societies,&#13;
              rather than for staff of international organizations with more global/regional&#13;
              interests.&#13;
&#13;
         · Regional representation: A concentration of participants from a single region&#13;
              (rather than a broader worldwide representation or a single country&#13;
              representation) added to an activity's average ratings on overall usefulness as&#13;
              well as four other indicators.&#13;
&#13;
&#13;
2.4      These regression results suggest that WBI might improve ratings of overall&#13;
usefulness and related indicators on average, by involving fewer participants per event&#13;
than in FY04-FY05, with relatively more females but fewer representatives from&#13;
international organizations. Interviews with TTLs supplement this quantitative analysis&#13;
to provide a comprehensive understanding of what ingredients contribute to successful&#13;
learning events for clients.&#13;
&#13;
&#13;
&#13;
&#13;
9This analysis was not designed to identify the optimal numbers of participants for different types of&#13;
learning events; however, this issue could be explored further in future analyses.&#13;
10Appendix B presents all regression results in table B.1, first using the ratings of all participants and then&#13;
using the ratings for male participants only.&#13;
&#13;
&#13;
                                                      6&#13;
&amp;#12;&#13;
 Table 1. Participant characteristics as explanatory variables: regressions of mean&#13;
                         ratings by participants (Extract from Appendix B)&#13;
&#13;
       Selected                               Dependent variables (mean ratings by participants)&#13;
     explanatory                                                          Usefulness of      Focus on         Matched&#13;
      variables             Overall      Relevance      Acquired new           new           learning        announced&#13;
    (partial data)        usefulness       to work       information       information         need          objectives&#13;
&#13;
N                          736            736             736               736              736             736&#13;
R2                         0.17           0.18            0.11              0.17             0.13            0.11&#13;
&#13;
Intercept                  0.8051***      0.8393***       0.7410***         0.7854***        0.7534***       0.8129***&#13;
&#13;
Total number of&#13;
participants               -0.0001***     -0.0001***      -0.0001           -0.0002***       -0.0001***      -0.0001***&#13;
&#13;
Share of female&#13;
participants               0.0302**       -0.0127         0.0130            0.0260*          0.0187          0.0320**&#13;
&#13;
Share of international&#13;
representatives            -0.0610***     -0.0022         -0.0697***        -0.0510**        -0.0829***      -0.0556**&#13;
&#13;
Share of other&#13;
representatives            0.0042         0.0064          -0.0009           0.0005           -0.0061         0.0035&#13;
&#13;
WB staff&#13;
participation?&#13;
(Dummy: Yes=1,             0.0014         -0.0004         -0.0131**         -0.0038          -0.0057         0.0043&#13;
&#13;
No=0)&#13;
&#13;
Representation&#13;
(Reference: World&#13;
representation)            -0.0049        -0.0181**       0.0125*           -0.0031          0.0012          0.0&#13;
Country&#13;
representation&#13;
&#13;
Region&#13;
representation             0.0163**       0.0016          0.0222***         0.0201***        0.0160**        0.0122&#13;
&#13;
&#13;
Note: ***, **, * represent levels of significance at 1 percent, 5 percent, and 10 percent respectively. For the complete&#13;
regression results, see table B.1 in appendix B.&#13;
&#13;
&#13;
                                REFLECTIONS FROM TASK TEAM LEADERS&#13;
&#13;
2.5        The 27 learning activities sampled for further investigation through TTL&#13;
interviews represented a broad range of participant characteristics. The majority of&#13;
participants in most activities were male, and two events had no female participants. The&#13;
number of participants ranged from 9 to 180. Based on data entered in WBICRS for the&#13;
sampled activities, participants were most frequently government employees, but five&#13;
events were dominated by academics or educators and three events were mainly&#13;
populated by private sector representatives. In addition, World Bank staff were among&#13;
the audience for five of the 27 events.&#13;
&#13;
2.6        By design, interviews with the TTLs of sampled learning events were structured&#13;
to explore possible factors contributing to higher or lower participant assessment ratings.&#13;
This approach elicited in-depth comments and explanations from TTLs about both the&#13;
individual events in the sample and their broader experiences. Although the sample was&#13;
designed to enable a comparison of high- and low-rated activities, analysis of the&#13;
qualitative data from interviews indicated that responses did not differ measurably&#13;
according to whether they were associated with the highest ratings or the lowest ratings.&#13;
However, analysis of TTLs' nuanced reflections based on their direct experience with&#13;
&#13;
&#13;
                                                            7&#13;
&amp;#12;&#13;
WBI programs enabled this study to provide suggestions on factors that facilitate&#13;
successful learning programs and recommendations to strengthen WBI in the future.&#13;
&#13;
2.7     TTLs' reflections about the sampled learning events provided a unified view that&#13;
participants have an important role in determining the success of learning programs.&#13;
Although no interview question focused specifically on how to select participants or the&#13;
best mix to attract, 20 of the 26 TTLs volunteered their opinions on these topics and&#13;
emphasized the importance of reaching the right audience. Recurrent messages included&#13;
that the ideal participants should...&#13;
&#13;
        · View their participation in the learning activity as something they have sought&#13;
            out to help them accomplish their goals,&#13;
&#13;
        · Have the authority and expertise to make relevant policy decisions following&#13;
            the learning event,&#13;
&#13;
        · Hold a position in which they can use their acquired knowledge and skills to&#13;
            accomplish particular development goals,&#13;
&#13;
        · Be higher level policy makers or researchers who can build capacity for the&#13;
            government, and&#13;
&#13;
        · Be part of a network where they can continue to share experiences.&#13;
&#13;
2.8     Developing clear strategies for identifying and reaching the target audiences for&#13;
specific programs is a critical part of the event planning process, and TTLs' comments&#13;
collectively outlined tips and challenges for doing this most effectively. When possible,&#13;
TTLs should work with local partners who are often best situated to attract, assess, and&#13;
select appropriate participants. However, some TTLs warned that leaving the selection of&#13;
participants to partners can have disadvantages, particularly in cases where partners are&#13;
charging a fee for an activity and are likely to accept anyone who pays the fee. TTLs&#13;
should therefore facilitate an education process, helping partners to consider the&#13;
characteristics listed above in developing their participant selection strategy.&#13;
&#13;
2.9     Interviews also highlighted how participants help determine the relevance of the&#13;
content and the success of the delivery (both discussed in chapter 3), how local partners&#13;
can play a critical role in selecting optimal participants (chapter 4), and how the indicator&#13;
of participant training days is not sufficient if the management goal is to measure (or to&#13;
promote) effective learning practices (chapter 5).&#13;
&#13;
&#13;
&#13;
&#13;
                                               8&#13;
&amp;#12;&#13;
               3.        PROGRAM DESIGN AND DELIVERY&#13;
&#13;
3.1      There are many variations in the design and delivery of WBI's learning events,&#13;
and lessons derived from extant data and TTLs' experiences about the roles of different&#13;
factors can guide program improvements. In addition to having the right audience&#13;
present, participants' ratings can be influenced by the location and objective of the&#13;
program, the means of delivery, and the relevance of the content.&#13;
&#13;
                                         REGRESSION RESULTS&#13;
&#13;
3.2      Together, the WBICRS and participant assessment data describe the format and&#13;
delivery mode of learning events, identify their product lines, and indicate where&#13;
activities were located and how long they lasted. As shown in table 2, an analysis to&#13;
explore which factors could explain participants' ratings indicated the following:&#13;
&#13;
         · Event location in a low-income country: Holding the WBI learning activity in&#13;
             a low-income country is associated with higher ratings for the event's overall&#13;
             usefulness compared with holding the same event in a middle- or high-income&#13;
             country.11&#13;
&#13;
         · Learning objective: Events that target skills building were rated to be more&#13;
             useful than those focused on knowledge exchange or policy service. This&#13;
             focus on practical applications or skills building tailored to address specific&#13;
             concerns is in line with WBI's country focus strategy.&#13;
&#13;
         · Mode of delivery: Compared to face-to-face delivery of learning events,&#13;
             electronic and blended delivery both rated higher in overall usefulness. By&#13;
             necessity, electronic or blended learning programs require advance&#13;
             preparation, so this finding could be due--at least in part--to the increased&#13;
             planning and careful preparation inherent in electronic and blended learning.&#13;
&#13;
         · Duration of the learning event: The length of an activity did not affect the&#13;
             ratings for its overall usefulness. However, participants were more likely to&#13;
             acquire new information in longer events.&#13;
&#13;
3.3      Where appropriate, guidelines for raising participants' ratings for the overall&#13;
usefulness of WBI learning offerings call for more learning events in low-income&#13;
&#13;
&#13;
&#13;
11While this result may be more on account of having the right participants, it is likely that the location of&#13;
the learning activity encourages better participant selection. Unfortunately, we could not test these&#13;
hypotheses with the available data.&#13;
&#13;
&#13;
&#13;
                                                       9&#13;
&amp;#12;&#13;
countries within the same region, additional skills building type of activities, and wider&#13;
use of electronic and blended learning delivery modes.&#13;
&#13;
Table 2. Design and delivery characteristics as explanatory variables: regressions of&#13;
                     mean ratings by participants (Extract from Appendix B)&#13;
&#13;
       Selected                               Dependent variables (mean ratings by participants)&#13;
     explanatory                                           Acquired        Usefulness of     Focus on         Matched&#13;
       variables             Overall      Relevance           new              new            learning       announced&#13;
     (partial data)        usefulness       to work       information       information        need           objectives&#13;
&#13;
N                           736            736             736              736              736             736&#13;
R2                          0.17           0.18            0.11             0.17             0.13            0.11&#13;
&#13;
Intercept                   0.8051***      0.8393***       0.7410***        0.7854***        0.7534***       0.8129***&#13;
&#13;
Duration (in days)          0.0007         -0.0011         0.0022***        0.0013           0.0005          0.0002&#13;
&#13;
Action learning&#13;
(dummy variable:            0.0094         0.0107*         -0.0069          0.0040           0.0096          -0.0005&#13;
yes=1, no=0)&#13;
&#13;
Location of activity&#13;
(Reference: Middle-         0.0236***      0.0071          -0.0060          0.0195***        0.0098          0.0031&#13;
income country) Low-&#13;
income country&#13;
&#13;
High-income country         0.0041         -0.0184**       -0.0072          -0.0078          -0.0047         0.0050&#13;
&#13;
Learning product&#13;
line (Reference:&#13;
Knowledge                   0.0101         -0.0049         0.0035           -0.0004          0.0024          0.0009&#13;
Exchange) Policy&#13;
Service&#13;
&#13;
Skills Building             0.0133**       0.0015          -0.0025          0.0125**         0.0089          0.0037&#13;
&#13;
Mode of delivery&#13;
(Reference: Face to&#13;
face) Distance              -0.0128        -0.0262**       -0.0052          -0.0078          -0.0226**       -0.0153&#13;
&#13;
learning&#13;
&#13;
Electronic learning         0.0312**       -0.0067         0.0292**         0.0403***        0.0319***       0.0318***&#13;
&#13;
Blended offering            0.0152*        -0.0023         0.0085           0.0115           -0.0014         0.0111&#13;
&#13;
Note: ***, **, * represent levels of significance at 1 percent, 5 percent, and 10 percent respectively. For the complete&#13;
regression results, see table B.1 in appendix B.&#13;
&#13;
3.4        One interesting finding was that the use of action learning did not emerge from&#13;
the regression analysis as a determinant of overall usefulness even though there is&#13;
sufficient a priori reason and other evidence to think otherwise.12 This is because the&#13;
WBICRS question from which this action learning variable was derived was not&#13;
associated with a specific definition, so a common understanding of the term is not&#13;
possible.13 The manner in which data on action learning were recorded in the WBICRS&#13;
&#13;
&#13;
&#13;
12Earlier evaluations have identified this variable as a significant factor that explains participants' use of&#13;
knowledge and skills acquired from the WBI learning event.&#13;
13In FY05, WBIEG conducted face-to-face interviews with 34 WBI TTLs on their use of data&#13;
systems. The interviews revealed that WBI TTLs had different notions of what constituted action&#13;
learning. This is not surprising because the definition of action learning was complex and had not been&#13;
finalized. Also, TTLs did not have convenient access to this definition. Furthermore, TTLs--who were in&#13;
the best position to describe their activity--often delegated to assistants the task of entering activity&#13;
information into administrative systems. These people were not always sufficiently informed to indicate&#13;
&#13;
&#13;
                                                           10&#13;
&amp;#12;&#13;
was too imprecise to be useful for analysis or planning purposes; however, WBI's&#13;
development of an electronic activity planning tool (Plato) represents a positive step, and&#13;
hopefully will allow for clarification of definitions such as "action learning."&#13;
&#13;
                            REFLECTIONS FROM TASK TEAM LEADERS&#13;
&#13;
3.5      TTLs were asked to identify "the key ingredients of a successful activity" and&#13;
most emphasized similar factors. Aside from the importance of having the right&#13;
participants (discussed previously), the most dominant themes included using relevant&#13;
content and effective materials to match local demand (17 of 26 TTLs), and the general&#13;
quality of design and delivery features--often including an action learning component&#13;
and the use of recognized experts as presenters (14 of 26 TTLs). Examples of these&#13;
comments are in box 1.&#13;
&#13;
  Box 1. Illustrative comments from TTLs on what factors contribute to successful&#13;
                                             learning events&#13;
&#13;
               "We try to do action learning, which is matching the knowledge with something&#13;
               that will produce a result for the client. That doesn't always work: it's a&#13;
               function of the nature of the course. In some cases, it's a dialogue, so action&#13;
               learning doesn't make sense. In other cases, it's skills building, in which action&#13;
               learning makes a lot of sense. So we try to match the pedagogy to the program's&#13;
               objective."&#13;
&#13;
               "If you don't have content that is relevant, that is of high quality according to&#13;
               international standards, that adds value, that is trusted, then you won't have a&#13;
               successful activity."&#13;
&#13;
               "To have a successful activity, you must have something topical and relevant&#13;
               with interaction--not just people listening to lectures ... presentations [by&#13;
               participants], panels, case studies are different ways of learning."&#13;
&#13;
&#13;
3.6      As with the regression results, the analysis of interview data revealed a lack of&#13;
common understanding about what qualified as action learning. When asked directly&#13;
about whether their specific activities in the sample had included an action learning&#13;
component, 16 TTLs claimed that they did. However, the accompanying descriptions&#13;
encompassed a range of definitions. For example, one task manager explained that the&#13;
action learning component was having participants do homework individually in the&#13;
evening whereas another TTL had participants conduct economic modeling and computer&#13;
simulations during the learning session but claimed that no action learning had been&#13;
included.&#13;
&#13;
&#13;
&#13;
&#13;
whether or not an activity used action learning. All these circumstances made the information related to&#13;
action learning unreliable.&#13;
&#13;
&#13;
                                                      11&#13;
&amp;#12;&#13;
                                   4.       PARTNERSHIPS&#13;
&#13;
4.1     Learning providers in WBI have many definitions for "partnership." In&#13;
interviews, TTLs used this term broadly to refer to collaborations with Bank operations,&#13;
joint efforts with other international donors, agreements with local institutions, and even&#13;
interactions with clients. Common contributions by partners include providing funding&#13;
(including in-kind contributions), developing content, participating in event delivery&#13;
(which could include providing training and/or logistical support), and offering access&#13;
into knowledge networks or communities of practice. Despite the widespread reliance on&#13;
and substantial contribution by partners, existing data on WBI learning programs for&#13;
FY04-05 lack sufficient reliable details about partnerships to support the systematic&#13;
analysis of these joint efforts. The newer Plato, at least as of June 2007, requests data&#13;
about partners that may help in future analyses if the Plato data can be merged with other&#13;
relevant datasets.&#13;
&#13;
                                         REGRESSION RESULTS&#13;
&#13;
4.2     Limited information on partner involvement was recorded in the WBICRS or&#13;
collected via participant assessment evaluations for learning events in FY04-05. In fact,&#13;
the only clear variable related to partnerships came from a field about whether or not a&#13;
partner was involved "to a large extent" in delivering the offering.14 Given that the basic&#13;
types of partner involvement were not captured, it is not surprising that the regressions&#13;
conducted for this study did not find this variable to have any influence on participants'&#13;
ratings for an event's overall usefulness or other desired outcomes. Rather than&#13;
supporting any conclusions regarding the importance of partnerships, this finding&#13;
underscored the need for WBI to continue to refine the collection of data on learning&#13;
activities to improve their overall reliability and usefulness. WBI has achieved important&#13;
progress in this area: starting in FY07, Plato prompts providers to list whether partners&#13;
are involved, to indicate the role or roles the partner organization(s) fill, and to list the&#13;
partner(s) by name.15&#13;
&#13;
                             REFLECTIONS FROM TASK TEAM LEADERS&#13;
&#13;
4.3     TTLs described the roles of partners for the sampled activities and noted that they&#13;
were often shaped by political context. In some countries, a task team must collaborate&#13;
closely with government officials to design and deliver any program. Client governments&#13;
or local partners frequently played an instrumental or even autonomous role in selecting&#13;
participants. The variety of ways that collaboration happened among WBI task teams,&#13;
Bank operations, clients, local partners, and other donors therefore reflected a range of&#13;
factors that affected partner involvement. Some of these factors stemmed from funding,&#13;
design, and logistical considerations; others occurred through political necessity.&#13;
&#13;
14See appendix A for descriptions of specific variables in the merged dataset.&#13;
15The roles listed do not link directly back to specific partners, so the precise contribution of individual&#13;
organizations is still unclear when multiple partners are listed.&#13;
&#13;
&#13;
                                                      12&#13;
&amp;#12;&#13;
4.4      The learning events sampled for TTL interviews reflected various types and&#13;
intensities of partnerships. Some of the events were delivered entirely by partners,&#13;
without any Bank staff present. In 19 of the 26 cases, partners had the main responsibility&#13;
for selecting and screening participants. Eight of the 26 events involved the efforts of&#13;
multiple partners.&#13;
&#13;
4.5      Despite the varying experiences with collaboration, TTLs expressed similar views&#13;
on factors needed for a successful partnership. Recurrent themes were that, in a&#13;
successful partnership, all partners should...&#13;
&#13;
         · Make a clearly identified contribution (that is, they "add value") to the event,&#13;
         · Have a long-term or ongoing commitment to collaborate with WBI, and&#13;
&#13;
         · Have a long-term view of their work and a plan for how to generate the&#13;
             income or other funding necessary to continue their work.&#13;
&#13;
4.6      In addition to the characteristics for successful partnerships in general, nine of the&#13;
26 TTLs emphasized that working with a local partner to ensure that the right participants&#13;
were selected and that logistics were handled smoothly was critical to the success of a&#13;
learning event. Comments from TTLs to illustrate these common themes are in box 2.&#13;
&#13;
                  Box 2. Illustrative comments from TTLs about partners&#13;
&#13;
   Characteristics of a successful partnership&#13;
&#13;
     "A successful partnership is where one begins to develop or take on the full responsibility and&#13;
      actually continue on one's own--even after we have left."&#13;
&#13;
     "We depend on the partner for delivering or developing content with passion and commitment.&#13;
      We help develop operational sustainability. Our partner has had a relationship with us for about&#13;
      four years and we have seen them grow successfully. The credit should be shared mutually and&#13;
      not be single sided."&#13;
&#13;
     "Complementarity with the partner is key... one has to make strategic choice[s] and differentiate&#13;
      between content partners, logistic partners, technical partners. One should make sure that a mix&#13;
      of these important factors are met in the actual partnership as everybody should ... bring a&#13;
      particular contribution to the table."&#13;
&#13;
     "You have to find a reliable partner, a partner that is not only after the money but also contributes&#13;
      towards the objective and that is not one sided and shares risks."&#13;
&#13;
   Importance of a local partner&#13;
&#13;
     "If you get the local institutions involved in the activity then you have a higher likelihood of&#13;
      succeeding. For training, the local institutions should be involved to develop part of the content&#13;
      as they know the participants, know the problems, the culture. They can easily get the right&#13;
      participants. In terms of preparation, this is the key."&#13;
&#13;
     "You need a local partner with appropriate capacity to organize the event...facilities [are] the key&#13;
      in developing countries and contribute 25-30 percent for a successful activity... if the&#13;
      participants are not comfortable, they may lose interest. I am a believer in relying on many local&#13;
      partners as competent as possible to ensure the delivery."&#13;
&#13;
&#13;
&#13;
&#13;
                                                      13&#13;
&amp;#12;&#13;
4.7    Overall, the interviews highlighted differences in how WBI partnerships are&#13;
defined or characterized. Some TTLs characterized their work with counterparts in Bank&#13;
operations as partnerships while others specifically noted that they had not collaborated&#13;
with partners and had teamed with staff in operations instead. One TTL wondered if&#13;
"partner" was really just another term for their client. Some TTLs identified local or&#13;
international organizations that played a major role in the activity design and delivery&#13;
whereas others referred to only peripheral involvement. In at least one case, a partner&#13;
described as having a "minor role" contributed content, identified local experts and&#13;
presenters, selected the participants, and handled logistics.&#13;
&#13;
&#13;
&#13;
&#13;
                                             14&#13;
&amp;#12;&#13;
      5.      PERFORMANCE WITHIN THE WORLD BANK&#13;
                                          INSTITUTE&#13;
&#13;
5.1     Although some activity-level data needed improvement (particularly for variables&#13;
on partnerships and action learning), merging the data from the WBICRS and participant&#13;
assessments for the 736 FY04-05 activities in the dataset provided a useful vehicle for&#13;
exploring how well WBI was performing across units and over time. These findings,&#13;
supplemented with insights from TTLs, inform ideas for increasing the quality and&#13;
impact of WBI programs, including both external training for individuals and broader&#13;
capacity development initiatives.&#13;
&#13;
                                       REGRESSION RESULTS&#13;
&#13;
5.2     As shown in table 3 and detailed below, participant assessment ratings varied&#13;
between WBI divisions and over time:&#13;
&#13;
        · WBI division: Participants' average ratings for overall usefulness were&#13;
             explained at least partly by the unit that managed and delivered the learning&#13;
             event. Learning events had higher average ratings when managed and&#13;
             delivered by WBI's Environment and and Natural Resource Management&#13;
             Division (WBIEN), Poverty Reduction and Economic Management Division&#13;
             (WBIPR), Human Development Division (WBIHD), or other divisions&#13;
             (WBIOTHER) rather than by WBI's Finance and Private Sector Development&#13;
             Division (WBIFP).16 Of these units, WBIPR had the largest positive effect on&#13;
             overall usefulness, followed by WBIOTHER, WBIEN, and WBIHD. This&#13;
             ordering changed, albeit moderately, when considering alternative success&#13;
             indicators such as the relevance of the activity to participants' current work,&#13;
             the extent to which the activity provided new information, the usefulness of&#13;
             the acquired information, the focus of the activity on the learning needed by&#13;
             the participant, and the degree to which the activity matched the announced&#13;
             objectives.&#13;
&#13;
        · Fiscal year: Overall usefulness ratings for WBI learning events rose in the&#13;
             second half of FY05 compared with the first six months of FY04, the base&#13;
             period. This is a gain of 13 percent in this indicator from what was possible at&#13;
             the base period.17 Similar gains are shown for other success indicators. These&#13;
&#13;
&#13;
&#13;
16WBIOTHER includes the following WBI unit codes: WBIST, WBISM, WBIKL, WBIKD, WBIES, WBIEG,&#13;
WBIMO, and WBIRC.&#13;
17The FY04 (first half) mean for overall usefulness was 4.28, based on a 5-point scale. The possible gain&#13;
over time from this base is 0.72.&#13;
&#13;
&#13;
&#13;
                                                    15&#13;
&amp;#12;&#13;
               results attest to notable improvements, from the viewpoint of participants, in&#13;
               the conduct and delivery of WBI learning events over the FY04-05 period.&#13;
&#13;
   Table 3. WBI division and timing as explanatory variables: regressions of mean&#13;
                                ratings by participants (Extract from Appendix B)&#13;
&#13;
   Selected                                Dependent variables (mean ratings by participants)&#13;
  explanatory                                                          Usefulness of                          Matched&#13;
   variables           Overall        Relevance      Acquired new           new            Focus on          announced&#13;
 (partial data)      usefulness        to work        information       information      learning need       objectives&#13;
&#13;
N                     736              736            736               736                736              736&#13;
R2                    0.17             0.18           0.11              0.17               0.13             0.11&#13;
&#13;
Intercept             0.8051***        0.8393***      0.7410***         0.7854***          0.7534***        0.8129***&#13;
&#13;
Division&#13;
(Reference:           0.0239***        0.0352***      0.0289***         0.0349***          0.0267***        0.0130&#13;
WBIFP)&#13;
WBIEN&#13;
&#13;
WBIPR                 0.0343***        0.0410***      0.0245***         0.0369***          0.0309***        0.0282***&#13;
&#13;
WBIHD                 0.0210**         0.0528***      0.0255**          0.0377***          0.0282***        0.0266***&#13;
&#13;
WBIOTHER              0.0302**         0.0365**       0.0058            0.0308**           0.0133           0.0231&#13;
&#13;
Fiscal year&#13;
(Reference:&#13;
First half of&#13;
FY04)                 -0.0037          0.0075         0.0009            0.0009             -0.0037          -0.0066&#13;
&#13;
Second half of&#13;
FY04&#13;
&#13;
First half of&#13;
FY05                  0.0103           0.0128         0.0104            0.0104             0.0126           0.0068&#13;
&#13;
Second half of&#13;
FY05                  0.0193***        0.0094         0.0167**          0.0167**           0.0168**         0.0130*&#13;
&#13;
&#13;
Note: ***, **, * represent levels of significance at 1 percent, 5 percent, and 10 percent respectively. For the complete&#13;
regression results, see table B.1 in appendix B.&#13;
&#13;
&#13;
                                REFLECTIONS FROM TASK TEAM LEADERS&#13;
&#13;
5.3        Interview sessions with TTLs ended with questions on how to improve learning&#13;
programs and capacity development activities carried out by WBI.18 Recommendations&#13;
focused on:&#13;
&#13;
           · Improving the coordination between WBI and Bank operations (13 of 26&#13;
               TTLs),&#13;
&#13;
           · Ending the emphasis on participant training days (12 of 26 TTLs), and&#13;
&#13;
           · Integrating evaluation better into program design and delivery (8 of 26 TTLs),&#13;
               including&#13;
&#13;
&#13;
&#13;
18As noted in appendix C, TTLs were asked how they would (a) improve the quality and impact of WBI&#13;
activities and (b) change the ways WBI carries out its capacity development mission. They were also asked&#13;
what they would change if they were a Bank leader. Answers to these three questions were interchangeable&#13;
and are discussed collectively in this chapter.&#13;
&#13;
&#13;
                                                           16&#13;
&amp;#12;&#13;
            o Developing methods or tools to collect feedback and adjust delivery&#13;
                 during longer events (rather than just through a questionnaire at the end),&#13;
&#13;
            o Having WBIEG rather than the unit delivering the activity develop&#13;
                 customized questions for participant assessments and analyze the results,&#13;
                 and&#13;
            o Establishing a system for following up with participants six months or&#13;
                 more after an event to ask about the use of what they learned or other&#13;
                 ways in which their participation in the WBI activity affected their work.&#13;
&#13;
5.4      Quotes illustrating frequent recommendations by TTLs are in box 3. Other less&#13;
frequent suggestions by those interviewed included using a multiyear cycle for&#13;
programming and budgeting (7 of 26 TTLs) and strengthening WBI management (6 of 26&#13;
TTLs) by eliminating at least one layer of management and by requiring that all managers&#13;
serve as task manager for at least one learning event per year and as team member for at&#13;
least one learning event per year. Finally, four of 26 TTLs highlighted the need to&#13;
emphasize quality content and delivery to compete better with universities and the&#13;
importance of tailoring offerings to local demand based on needs assessments.&#13;
&#13;
Box 3. Illustrative recommendations from TTLs on how to improve the quality and&#13;
        impact of WBI learning programs and capacity development initiatives&#13;
&#13;
   End the emphasis on PTDs&#13;
     "Look at the incentive structure of TTLs. The incentive structure is designed to increase the number to&#13;
      have a better PTD. Instead of a large group of participants, I would rather train a small group of&#13;
      policy makers who actually change policy in a country."&#13;
&#13;
     "If WBI ever gets its act together and eliminates the whole concept of PTDs and focuses instead on&#13;
      selection and quality--on what content are we teaching, who are we teaching it to, does it have any&#13;
      impact--it would eliminate half my stupid load. It would allow me to actually follow up. The&#13;
      biggest problem is we have no follow-up capacity. We are obsessed with pushing stuff through the&#13;
      system, training as many people as you can train in any way you can."&#13;
&#13;
   Coordinate better with Bank operations&#13;
     "In operations, people do not know that WBI has the capacity to respond to situations that could be&#13;
      addressed well and they keep going around searching web sites to select training institutes in&#13;
      countries to do the training."&#13;
&#13;
     "We need RCET [WBIRC] help to establish and operationalize the link with operations on capacity&#13;
      building. Operations should keep us [WBI] in their radar not just to be informed of the training but&#13;
      to help design the capacity development components of the loan itself, brought in at the very&#13;
      beginning along with loan documents."&#13;
&#13;
   Integrate evaluation more fully into programming&#13;
     "There should be a feedback process to establish a link with the policy makers in order to ensure an&#13;
      impact of the training activity. In simple terms, the training activity should directly produce the&#13;
      desired results, with diagnostic tools provided to be applied to the local data and be used by policy&#13;
      makers in finance, planning, and so on. Otherwise there will be no value added in this type of&#13;
      training activities."&#13;
&#13;
     "We do level 1s as required, but we do [daily assessments] in our programs as feedback, and we&#13;
      publish the results the following day...we make necessary adjustments immediately which is more&#13;
      important that the level 1 results which come later. My clients are there for one week to be dealt with&#13;
      on the spot!"&#13;
&#13;
&#13;
&#13;
                                                    17&#13;
&amp;#12;&#13;
                         6.       RECOMMENDATIONS&#13;
&#13;
6.1    The emphasis of WBI programs has evolved since the scope of this review was&#13;
established, with efforts increasingly focusing on multiyear programmatic initiatives to&#13;
develop organizational capacity rather than just on PTDs. Although this review is based&#13;
on earlier data, results of this analysis shed light on the factors that are likely to increase&#13;
the quality of learning or capacity development. Specifically, the factors identified are&#13;
associated with higher participant assessment ratings, but they do not necessarily result in&#13;
better outcomes. WBI managers and TTLs should consider and apply the findings of this&#13;
review when appropriate. The following recommendations outline advice for programs,&#13;
suggest organizational improvements within WBI, and identify steps needed to improve&#13;
the quality of data on learning activities and participant characteristics.&#13;
&#13;
       · Considerations for program design and delivery. TTLs consider a range of&#13;
           factors in delivering WBI's programs--from available resources and cost&#13;
           effectiveness to feasibility and potential impact. As task teams plan events&#13;
           and encounter trade-offs, findings from this review can inform&#13;
           decisionmaking to maximize programs' usefulness. Specifically, participants&#13;
           perceive programs to be more useful if events have:&#13;
&#13;
           o Fewer participants overall,&#13;
           o A greater share of female participants,&#13;
           o A smaller share of international representatives participating, as opposed&#13;
                to government representatives&#13;
&#13;
           o A focus on skills building,&#13;
           o A delivery in a low-income country, and&#13;
           o A delivery mode of electronic or blended learning, or a level of advance&#13;
                planning and pedagogical structure comparable to those needed for&#13;
                electronic or blended learning.&#13;
&#13;
       Furthermore, working with local partners is advised to optimize the selection of&#13;
       participants, the adaptation of content, and the logistical details of an event's&#13;
       delivery.&#13;
&#13;
       · Organizational improvements within WBI. Several of the changes suggested&#13;
           by TTLs in interviews are already underway in WBI: most notably, the&#13;
           program emphasis is shifting to a multiyear focus on initiatives at the&#13;
           organizational level rather than on learning events for individuals, and&#13;
           management is actively exploring alternative indicators to supplement the use&#13;
&#13;
&#13;
&#13;
                                               18&#13;
&amp;#12;&#13;
  of PTDs. Findings from this review provide further guidance within this&#13;
  context:&#13;
&#13;
  o Links between WBI programs and Bank operations. WBI TTLs have&#13;
      varying degrees of interaction with operational staff, and many reported&#13;
      that this this coordination happens only on an ad hoc basis. Increased&#13;
      guidance and support from WBIRC is needed to establish more systematic&#13;
      coordination. Suggestions include involving WBI counterparts early on in&#13;
      the Bank's lending process or bringing WBI staff into the Bank's matrix&#13;
      whereby they report also to operational managers.&#13;
&#13;
  o Performance indicators: TTLs expressed a frustration with being assessed&#13;
      through PTDs, but they also demonstrated an understanding that some&#13;
      such indicators are needed to gauge performance. This study underscored&#13;
      the current opportunity to continue decreasing the emphasis on counting&#13;
      the number of participants and considering this measure as part of an&#13;
      overall package. Assessments of and incentives for TTLs should focus on&#13;
      reaching the right participants, delivering quality programming, and&#13;
      following up as necessary or appropriate to ensure intended impact.&#13;
&#13;
  o Evaluation services and tools. TTLs want evaluation to be more fully&#13;
      integrated into their programs, and this perspective is aligned with WBI's&#13;
      growing focus on coherent programs rather than individual events, as well&#13;
      as on a results framework for capacity development programs. Ideally,&#13;
      evaluation practices should support and guide the programmatic approach&#13;
      by defining the program's logic at the outset, collecting baseline data,&#13;
      designing a monitoring and evaluation plan that includes participants'&#13;
      assessments, and following up with participants over time. This holistic&#13;
      approach will provide more meaningful direction to programs rather than&#13;
      just collecting participant assessments at the conclusion of individual&#13;
      activities. At minimum, TTLs want customized questions to ask their&#13;
      participants and guidance on how best to follow up with participants later.&#13;
      Ideally, WBIEG should be engaged at the start of the program and have&#13;
      the capacity to help TTLs shape appropriate evaluation questions,&#13;
      strategies, and analyses.&#13;
&#13;
  o Strengthening management. To ensure that WBI managers can supply the&#13;
      needed guidance and support to TTLs, they should be directly familiar&#13;
      with both the overall strategy and the practical details of the relevant WBI&#13;
      learning programs. Such familiarity could enable managers to identify&#13;
      and overcome barriers to optimal performance. A systematic approach of&#13;
      requiring managers to lead or serve on at least one task team may be&#13;
      warranted given the dominance of this theme in TTL interviews.&#13;
&#13;
· Increasing data quality to support WBI's programmatic approach. Although&#13;
  the data for this review were from FY04-05, the preparation and analysis of&#13;
  the dataset highlighted lessons to improve systems and practices in FY08 and&#13;
 beyond:&#13;
&#13;
&#13;
&#13;
                                    19&#13;
&amp;#12;&#13;
           o Defining variables. The process of merging data from the WBICRS and&#13;
               participant assessment evaluations revealed several cases where variables&#13;
               with similar coding had different meanings in different datasets (see&#13;
               appendix A). Efforts to standardize the definitions of all variables should&#13;
               continue. Of particular concern are the variables for action learning and&#13;
               partnerships, two important factors in learning programs whose&#13;
               contribution can not be understood without better data.&#13;
&#13;
           o Supporting monitoring and evaluation. The growing repository of data&#13;
               available on WBI activities should be mined and analyzed regularly as&#13;
               part of a more integrated approach to program evaluation. To support&#13;
               such a process and to ensure that analyses such at this one are accurate and&#13;
               up-to-date, learning activity data should be readily accessible to evaluation&#13;
               officers, for example, through a full database query available at any time&#13;
               without the intervention of programmers. In addition, a transparent&#13;
               codebook is needed to promote the common understanding of all variables&#13;
               therein.&#13;
&#13;
           o Aligning systems thinking to WBI programming. The WBICRS, Plato,&#13;
               and SAP all contain valuable data on learning activities; however, it is not&#13;
               yet clear how all of this information will be harvested and used. A&#13;
               detailed systems strategy is needed to increase the coordination among&#13;
               data systems and to minimize the reporting burden for TTLs. As part of&#13;
               this strategy, data entry protocols are needed to promote consistency. The&#13;
               changes in the SAP system format for accounting records for external&#13;
               training (TE) activities represent a positive step in this direction. New&#13;
               changes in Plato are also expected to be helpful, and management should&#13;
               emphasize collection and analysis of data from SAP, Plato, and the&#13;
               WBICRS, as well as from participant assessments, to continue learning&#13;
               how to improve WBI's programs.&#13;
&#13;
6.2    Activity-specific data and participant perceptions of the relevance and usefulness&#13;
of individual events are important building blocks for higher-level indicators linked to&#13;
organizational development. Continuing to improve the reliability of these data and&#13;
using them to inform decisions on program design and delivery can contribute to the&#13;
success of WBI's programmatic approach.&#13;
&#13;
&#13;
&#13;
&#13;
                                             20&#13;
&amp;#12;&#13;
APPENDIX A: WBICRS AND LEVEL 1 EVALUATION VARIABLES&#13;
&#13;
CRS  L1           Variable                                   Additional explanation&#13;
&#13;
        Division                    Five-letter abbreviation for the WBI division. These are not&#13;
                                    necessarily the same across fiscal years.&#13;
&#13;
        Thematic Program            One of 18 or so WBI thematic programs&#13;
&#13;
        WPA Number                  Work program agreement number -- corresponds to a thematic&#13;
                                    program for a given fiscal year&#13;
&#13;
        WBS Element                 P0 number&#13;
&#13;
        Schedule Code               Number that comes from the Learning Catalog - one schedule code&#13;
                                    per site&#13;
&#13;
        Name of Offering            Activity title&#13;
&#13;
        TM                          Name of task manager&#13;
&#13;
        Location                    City and country (or sometimes only country) where the activity&#13;
                                    actually took place; venue&#13;
&#13;
        Start                       Start date of the activity&#13;
&#13;
        End                         End date of the activity&#13;
&#13;
        N Participants              Number of participants registered in the activity&#13;
&#13;
        N Observers                 Number of observers registered in the activity&#13;
&#13;
        N Resource People           Number of resource people registered in the activity&#13;
&#13;
        1.1 Participants            Response "Participant" to "Which of the following best describes your&#13;
                                    main role in this activity?"&#13;
&#13;
        1.2 Observers               Response "Observer" to "Which of the following best describes your&#13;
                                    main role in this activity?"&#13;
&#13;
        1.3 Resource Persons        Response "Resource person" to "Which of the following best&#13;
                                    describes your main role in this activity?"&#13;
&#13;
        1.4 Other                   Response "Other" to "Which of the following best describes your main&#13;
                                    role in this activity?"&#13;
&#13;
        2.1 Attended all            Response "All of it" to "How much of the activity were you able to&#13;
                                    attend?"&#13;
&#13;
        2.2 Attended most           Response "Most of it" to "How much of the activity were you able to&#13;
                                    attend?"&#13;
&#13;
        2.3 Attended half or less   Response "Half or less of it" to "How much of the activity were you&#13;
                                    able to attend?"&#13;
&#13;
        3.1 WB Employee             Response "Yes" to "Are you a World Bank employee?"&#13;
&#13;
        3.2 Not WB Employee         Response "No" to "Are you a World Bank employee?"&#13;
&#13;
        4.1 Male                    Response "Male" to "Are you"&#13;
&#13;
        4.2 Female                  Response "Female" to "Are you"&#13;
&#13;
        5. Relevance                Response to "Relevance of this activity to your current work or&#13;
                                    functions," rating on a 1-5 scale (1=minimum; 5=maximum)&#13;
&#13;
        6. New info                 Response to "Extent to which you have acquired information that is&#13;
                                    new to you," rating on a 1-5 scale (1=minimum; 5=maximum)&#13;
&#13;
        7. Useful info              Response to "Usefulness for you of the information that you have&#13;
                                    acquired." rating on a 1-5 scale (1=minimum; 5=maximum)&#13;
&#13;
        8. Learning                 Response to "Focus of this activity on what you specifically needed to&#13;
                                    learn," rating on a 1-5 scale (1=minimum; 5=maximum)&#13;
&#13;
        9. Objectives               Response to "Extent to which the content of this activity matched the&#13;
                                    announced objectives," rating on a 1-5 scale (1=minimum;&#13;
                                    5=maximum)&#13;
&#13;
        10. Overall useful          Response to "Overall usefulness of this activity," rating on a 1-5 scale&#13;
                                    (1=minimum; 5=maximum)&#13;
&#13;
        Action Learning             Whether the activity was designated as action learning or not; values&#13;
                                    can be "Yes" or "No"&#13;
&#13;
                                                                            (Table continues on next page.)&#13;
&#13;
&#13;
&#13;
&#13;
                                          21&#13;
&amp;#12;&#13;
(Table continued.)&#13;
&#13;
 CRS       L1              Variable                                      Additional explanation&#13;
&#13;
                 Mode of delivery               Mode of delivery of the activity; could be face-to-face; distance&#13;
                                                learning; electronic learning; blended learning; others?&#13;
&#13;
                 Partner involvement from       "Was a Partner involved to a large extent in delivering this offering?"&#13;
                 CRS                            Can be Y or N: Y= partner-led; N = WBI-led&#13;
&#13;
                 Activity Type                  Type of activity -- values can be course, seminar, clinic/workshop,&#13;
                                                conference, global dialogue, study tour, e-discussion, others&#13;
&#13;
                 Scheduled Duration             Number of days for which this activity is scheduled&#13;
&#13;
                 Participant Training Days      Number of participant training recorded for this activity&#13;
&#13;
                 Actual Duration                Number of days the activity lasted.&#13;
&#13;
                 Duration                       There may be several variables of "actual duration" because there&#13;
                                                may be a different duration under each activity&#13;
&#13;
                 GDLN                           Whether the activity was a GDLN activity - probably a Yes/No&#13;
                                                variable. Note that some WBI distance learning courses did not make&#13;
                                                use of GDLN facilities.&#13;
&#13;
                 AMS Send                       Whether the activity was sent to AMS -- probably a Yes/No variable&#13;
&#13;
                 Due Level 1                    Whether an evaluation was required for this activity or not, in other&#13;
                                                words, whether this activity would appear on the Due Level 1 report.&#13;
                                                (Activities lasting 1 day or less or conferences are exempt)&#13;
&#13;
                 Product Line                   Values can be -- T=skills building; P=policy service; K=knowledge&#13;
                                                exchange; others&#13;
&#13;
                 Requested by                   Also known as source of demand: EC=external client; OP=operations;&#13;
                                                OT-others; other&#13;
&#13;
                 Pillar                         Pillar -- sector &amp; thematic; knowledge; regional; global programs;&#13;
                                                other&#13;
&#13;
                 Used 10 questions?             Whether the evaluation used the old six-question format or the current&#13;
                                                ten-question format&#13;
&#13;
                 Participant contact info?      How much contact information was in the CRS for the participants in&#13;
                                                this activity -- values can be: All have contact info, Some have&#13;
                                                contact info, Participants entered but none have contact info,&#13;
                                                Summary only (individual participants did not enter)&#13;
&#13;
                 Country - location of the      Country in which the activity took place. DL activities with more than&#13;
                 activity                       one location or activities with an unspecified location. EL activities are&#13;
                                                coded "Worldwide"&#13;
&#13;
                 Country - where participants   There could be as many countries listed here as there are participants&#13;
                 live and work&#13;
&#13;
                  Number of participants from   If there is more than one participant from a country, the CRS should&#13;
                 country                        indicate how many participants are from that country&#13;
&#13;
                 Region - location of the       Region corresponding to the country in which the activity took place.&#13;
                 activity                       There may be activities with more than one location or with an&#13;
                                                unspecified location&#13;
&#13;
                 Region - where the&#13;
                 participants in this activity&#13;
                 come from&#13;
&#13;
                                                                                         (Table continues on next page.)&#13;
&#13;
&#13;
&#13;
&#13;
                                                       22&#13;
&amp;#12;&#13;
(Table continued.)&#13;
&#13;
 CRS       L1              Variable                                   Additional explanation&#13;
&#13;
                 Participant roles            Roles the participants were registered as having, and how many in&#13;
                                              each role -- values could be&#13;
                                              Resource: Donor&#13;
                                              Resource: Observer&#13;
                                              Resource: Organizer&#13;
                                              Resource: Lecturer&#13;
                                              Resource: Other&#13;
                                              Participant: Client country&#13;
                                              Participant: IMF&#13;
                                              Participant: World Bank&#13;
                                              Participant: Other international organization&#13;
                                              Participant: Other&#13;
&#13;
                 Participant representations  To what type of organization did the participant belong, and how many&#13;
                                              participants were from each type of organization&#13;
                                              M: Minister&#13;
                                              P: Parliamentarian&#13;
                                              G: Government official&#13;
                                              A: Academics/education&#13;
                                              J: Media/journalist&#13;
                                              H: NGO/research institute&#13;
                                              V: Private sector&#13;
                                              B: Bilateral aid donor&#13;
                                              I: IMF&#13;
                                              O: International organization&#13;
                                              Z: Other&#13;
                                              W: WB&#13;
&#13;
                 Participant education level  Education level of participants, and how many participants with each&#13;
                                              education level&#13;
&#13;
                 Priority country             Calculated by the results database based on a table of priority&#13;
                                              countries&#13;
&#13;
                 Focus country                Calculated by the results database based on a table of focus&#13;
                                              countries&#13;
&#13;
                 Low-income focus country     Whether this was one of the six low-income focus countries Probably&#13;
                                              calculated on the basis of other variables&#13;
&#13;
                 Economy                      Classification of the economy, from the World Development Report --&#13;
                                              LIC=low-income; LMC=lower-middle-income; UMC=upper-middle-&#13;
                                              income; OECD=high-income OECD countries; OHI=high-income&#13;
                                              countries other than OECD -- probably calculated by the results&#13;
                                              database based on a table of countries and economies&#13;
&#13;
Note: =Included; = Not included&#13;
&#13;
&#13;
&#13;
&#13;
                                                    23&#13;
&amp;#12;&#13;
                             APPENDIX B: DATA AND METHODS&#13;
                       SELECTION OF WBI LEARNING ACTIVITIES FOR EVALUATION&#13;
&#13;
               For both our quantitative and qualitative analysis, we focused on FY04 and FY05&#13;
    WBI learning activities only. Although we merged and cleaned WBICRS and participant&#13;
    assessment (Level 1) data from FY02-FY05, we excluded activities before FY04 because&#13;
    we found some key variables were not available or were not reliable. For FY04-05, the&#13;
    total number of WBI learning activities delivered was 815. From this total, we dropped&#13;
    76 activities of one day or less in duration and included 739 activities for analysis19.&#13;
&#13;
                                             REGRESSION ANALYSIS&#13;
&#13;
               We used multiple regression analysis to investigate the key factors that might&#13;
    explain the participants' ratings of an activity's overall usefulness and other desired&#13;
    features and outcomes of the learning event (relevance, provision of new information,&#13;
    and focus of the particular activity on what the respondent specifically needed to learn).20&#13;
    We use OLS estimation procedures to test the following model:&#13;
&#13;
&#13;
                             n                         n                                 n&#13;
Y (Overall Usefulness) =   +   (activity features)+   (respondent characteristics)+          (exogenousvariables) + &#13;
                         0        ij                       ij                                ij                     ij&#13;
                            j =1                      j =1                              j =1&#13;
&#13;
&#13;
&#13;
&#13;
               We constructed some important activity-level variables such as total number of&#13;
    participants; share of government, international or other representatives; and share of&#13;
    female participants. For example, to capture the significance of country representation or&#13;
    regional representation in a particular activity, we created two dummy variables:&#13;
    RCOUNTRY and RREGION. The former is =1 when 80 percent or more participants in&#13;
    an activity come from the same country, zero otherwise. The latter variable is =1 if 80&#13;
    percent or more participants come from the same region. Detailed procedures used&#13;
    creating all the new variables used in the regression analysis are given in the appendix D.&#13;
&#13;
               In all, the regressions are intended to answer the question: what key participants'&#13;
    characteristics, activity-level variables, and exogenous factors can explain participants'&#13;
    ratings of WBI learning events?21&#13;
&#13;
&#13;
&#13;
&#13;
    19However, due to missing values, we used only 736, out of 739 available, observations in our regression&#13;
    analysis.&#13;
    20We standardized these dependent variables by converting their values to between [0, 1].&#13;
    21We also investigated other possible explanatory variables that are not reported here, i.e., language of&#13;
    instruction, number of sessions, and whether or not the average activity participant attended all, attended&#13;
    half, or attended most of the learning event. We dropped these variables from the final regressions because&#13;
    they either (a) contained a lot of missing values; (b) had very unclear definitions; or (c) could be defined by&#13;
    a more precisely defined variable used in the regressions (to avoid multicollinearity).&#13;
&#13;
&#13;
&#13;
                                                        24&#13;
&amp;#12;&#13;
  Table B.1. Regressions of mean ratings by all participants and by male participants&#13;
&#13;
                                          Dependent variables (mean ratings by all participants)&#13;
&#13;
  Explanatory variables                                 Acquired     Usefulness of     Focus on    Matched&#13;
                                Overall   Relevance      new             new            learning  announced&#13;
                              usefulness    to work   information     information        need     objectives&#13;
&#13;
N                            736         736         736            736              736         736&#13;
R2                           0.17        0.18        0.11           0.17             0.13        0.11&#13;
&#13;
Intercept                    0.8051***   0.8393***   0.7410***      0.7854***        0.7534***   0.8129***&#13;
&#13;
Total number of participants -0.0001***  -0.0001***  -0.0001        -0.0002***       -0.0001***  -0.0001***&#13;
&#13;
Duration (in days)           0.0007      -0.0011     0.0022***      0.0013           0.0005      0.0002&#13;
&#13;
Share of female participants 0.0302**    -0.0127     0.0130         0.0260*          0.0187      0.0320**&#13;
&#13;
Share of international&#13;
representatives              -0.0610***  -0.0022     -0.0697***     -0.0510**        -0.0829***  -0.0556**&#13;
&#13;
Share of other&#13;
representatives              0.0042      0.0064      -0.0009        0.0005           -0.0061     0.0035&#13;
&#13;
Dummy variables&#13;
(Yes=1, No=0)&#13;
&#13;
WB staff participation       0.0014      -0.0004     -0.0131**      -0.0038          -0.0057     0.0043&#13;
&#13;
Action learning              0.0094      0.0107*     -0.0069        0.0040           0.0096      -0.0005&#13;
&#13;
Partner led                  0.0061      0.0035      0.0083         0.0086*          0.0016      0.00570&#13;
&#13;
Division&#13;
(Reference: WBIFP)&#13;
WBIEN                        0.0239***   0.0352***   0.0289***      0.0349***        0.0267***   0.0130&#13;
&#13;
WBIPR                        0.0343***   0.0410***   0.0245***      0.0369***        0.0309***   0.0282***&#13;
&#13;
WBIHD                        0.0210**    0.0528***   0.0255**       0.0377***        0.0282***   0.0266***&#13;
&#13;
WBIOTHER                     0.0302**    0.0365**    0.0058         0.0308**         0.0133      0.0231&#13;
&#13;
Location of activity&#13;
(Reference: Middle- income&#13;
country)&#13;
Low-income country           0.0236***   0.0071      -0.0060        0.0195***        0.0098      0.0031&#13;
&#13;
High-income country          0.0041      -0.0184**   -0.0072        -0.0078          -0.0047     0.0050&#13;
&#13;
Learning product line&#13;
(Reference: Knowledge&#13;
exchange)&#13;
Policy service               0.0101      -0.0049     0.0035         -0.0004          0.0024      0.0009&#13;
&#13;
Skills building              0.0133**    0.0015      -0.0025        0.0125**         0.0089      0.0037&#13;
&#13;
Mode of delivery&#13;
(Reference: Face to face)&#13;
Distance learning            -0.0128     -0.0262**   -0.0052        -0.0078          -0.0226**   -0.0153&#13;
&#13;
Electronic learning          0.0312**    -0.0067     0.0292**       0.0403***        0.0319***   0.0318***&#13;
&#13;
Blended offering             0.0152*     -0.0023     0.0085         0.0115           -0.0014     0.0111&#13;
&#13;
Representation&#13;
(Reference: World&#13;
representation)&#13;
Country representation       -0.0049     -0.0181**   0.0125*        -0.0031          0.0012      0&#13;
&#13;
Region representation        0.0163**    0.0016      0.0222***      0.0201***        0.0160**    0.0122&#13;
&#13;
Fiscal year (Reference:&#13;
First half of FY04)&#13;
Second half of FY04          -0.0037     0.0075      0.0009         0.0009           -0.0037     -0.0066&#13;
&#13;
First half of FY05           0.0103      0.0128      0.0104         0.0104           0.0126      0.0068&#13;
&#13;
Second half of FY05          0.0193***   0.0094      0.0167**       0.0167**         0.0168**    0.0130*&#13;
&#13;
&#13;
&#13;
&#13;
                                                   25&#13;
&amp;#12;&#13;
                                              Dependent variables (mean ratings by male participants)&#13;
&#13;
                                                                 Acquired       Usefulness of    Focus on    Matched&#13;
                                 Overall       Relevance           new              new           learning  announced&#13;
                               usefulness        to work        information      information       need     objectives&#13;
&#13;
N                             736             736             736              736              736        736&#13;
R2                            0.17            0.18            0.10             0.18             0.13       0.10&#13;
&#13;
Intercept                     4.0202***       4.2092***       3.6681***        3.9009***        3.7721***  4.1088***&#13;
&#13;
Total number of participants  -.0007***       -0.0006***      -0.0003          -0.0007***       -0.0007*** -0.0009***&#13;
&#13;
Duration (in days)            0.0046          -0.0058         0.0106***        0.0104           0.0041     0.0004&#13;
&#13;
Share of female participants  0.1385**        -0.0512         0.0529           0.0482           0.0269     0.1246*&#13;
&#13;
Share of international&#13;
representatives               -0.2772**       -0.0522         -0.2201*         -0.2143*         -0.2559*   -0.2798**&#13;
&#13;
Share of other&#13;
representatives               0.0194          0.0607          0.0152           -0.0209          -0.0384    0.0124&#13;
&#13;
Dummy variables Yes=1,&#13;
No=0&#13;
&#13;
WB staff participation        0.0005          -0.0451         -0.0804**        -0.01027         -0.0457    0.0207&#13;
&#13;
Action learning               0.0527*         0.0609*         -0.0459          0.0188           0.0614     -0.0063&#13;
&#13;
Partner led                   0.0336          0.0182          0.0733**         0.0431           -0.0049    0.0182&#13;
&#13;
Division (Reference:&#13;
WBIFP)&#13;
WBIEN                         0.1196***       0.8152***       0.0523***        0.1743***        0.1342***  0.0617&#13;
&#13;
WBIPR                         0.1686***       0.2177***       0.1372***        0.2046***        0.1764***  0.1398***&#13;
&#13;
WBIHD                         0.0943*         0.2949          0.1372***        0.1751***        0.1250**   0.1231**&#13;
&#13;
WBIOTHER                      0.1731**        0.2405          0.0961           0.1145           0.0982     0.1170&#13;
&#13;
Location of activity&#13;
(Reference: Middle-income&#13;
country)&#13;
Low-income country            0.1265***       0.0422          -0.0062          0.1097***        0.0502     0.0226&#13;
&#13;
High-income country           0.0061          -0.0717*        -0.0151          -0.0515          -0.0166    0.0182&#13;
&#13;
Learning product line&#13;
(Reference: Knowledge&#13;
exchange)&#13;
Policy service                0.0591          -0.0124         0.0063           0.0072           0.0162     0.0239&#13;
&#13;
Skills building               0.0840***       0.0090          -0.0137          0.0841***        0.0659**   0.0399&#13;
&#13;
Mode of delivery&#13;
(Reference: Face to face)&#13;
Distance learning             -0.0473         -0.1526***      -0.0603          -0.0127          -0.1000*   -0.0547&#13;
&#13;
Electronic learning           0.1824***       -0.1103*        0.1483**         0.1954**         0.1426**   0.1612**&#13;
&#13;
Blended offering              0.0801*         -0.0418         0.0195           0.0812*          0.0035     0.0806*&#13;
&#13;
Representation&#13;
(Reference: World&#13;
representation)&#13;
Country representation        -0.0493         -0.1370***      0.0554           -0.0141          -0.0106    -0.0199&#13;
&#13;
Region representation         0.0669*         -0.0170         0.1126***        0.1062***        0.0895**   0.0376&#13;
&#13;
Fiscal year (Reference:&#13;
First half of FY04)&#13;
Second half of FY04           -0.0179         0.0469          -0.0132          0.0117           -0.0328    -0.0482&#13;
&#13;
First half of FY05            0.0459          0.0582          0.0573           0.0530           0.0515     0.0154&#13;
&#13;
Second half of FY05           0.0958**        0.0574          0.1013**         0.0923**         0.0768*    0.0413&#13;
&#13;
 Note: ***, **, * represent levels of significance at 1 percent, 5 percent, and 10 percent respectively.&#13;
&#13;
&#13;
&#13;
                                                          26&#13;
&amp;#12;&#13;
                             SELECTION OF WBI TTLS FOR INTERVIEWS&#13;
&#13;
         A typical WBI Level 1 evaluation asks participants immediately after the event to&#13;
rate, on a five-point scale, a learning activity's: (a) relevance, (b) quality of instruction,&#13;
(c) usefulness and job applicability, (d) achievement of stated objectives, and (e) overall&#13;
usefulness. We drew 10 percent of the highest-rated and lowest-rated FY04-05 WBI&#13;
activities in each of these five criteria and we report on the key features of these activities&#13;
that relate to their having extreme ratings.&#13;
&#13;
Table B.2: Proposed vs. actual number of sampled activities for TTL interviews&#13;
&#13;
             Participant Assessment (Level 1) Evaluation   Number of sampled activities from:&#13;
&#13;
                                  criteria:                 highest 10%        lowest 10%&#13;
&#13;
         (a) relevance                                           3                   3&#13;
&#13;
         (b) quality of instruction                              3                   3&#13;
&#13;
         (c) usefulness and job applicability                    3                   3&#13;
&#13;
         (d) achievement of stated objectives                    3                   3&#13;
&#13;
         (e) overall usefulness                                  3                   3&#13;
&#13;
                                           TOTAL                15                   15&#13;
&#13;
&#13;
        We did not know a priori how an activity's ratings, based on the above criteria,&#13;
are correlated. Neither did we know whether these criteria really measure different&#13;
attributes of learning events, as intended. Also, it is possible that certain activities, or&#13;
WBI programs, were consistently among the best (or worst) according to specific criteria&#13;
ratings, thereby indicating their particular strengths (or weaknesses).&#13;
&#13;
        We interviewed the WBI TTLs of these sampled learning activities to understand&#13;
more clearly the features of these events that contributed to their highest (and lowest)&#13;
rankings. We investigated whether TTLs have the same understandings of key questions&#13;
(or variables) that are used to describe their activities in the WBICRS, such as whether&#13;
the WBI activity they managed involved "action learning" or "working with partners."&#13;
This inquiry was intended to clarify, refine, and standardize the definitions used in the&#13;
WBICRS, thereby making this entire dataset more useful. Appendix C lists the guideline&#13;
questions used in the TTL interviews.&#13;
&#13;
&#13;
&#13;
&#13;
                                                  27&#13;
&amp;#12;&#13;
        APPENDIX C: TOPIC GUIDE AND QUESTIONS FOR TTL&#13;
                                            INTERVIEWS&#13;
&#13;
&#13;
Factors for a successful learning program&#13;
&#13;
What, in your opinion, are the key ingredients for a successful activity?&#13;
&#13;
&#13;
The nature of WBI's partners:&#13;
&#13;
What role do they play in the partnership?&#13;
&#13;
What types and levels of involvement?&#13;
&#13;
What is a successful partnership?&#13;
&#13;
What happened with this partnership since the activity (outcome)?&#13;
&#13;
&#13;
Client/Staff composition of participants&#13;
&#13;
Were there World Bank staff? How many?&#13;
&#13;
Do you think it makes a difference when staff attend activities? Why or why not?&#13;
&#13;
What is their level of engagement?&#13;
&#13;
&#13;
Single versus multicountry offerings&#13;
&#13;
&#13;
If single:&#13;
&#13;
Why was this offered in country X?&#13;
&#13;
According to the CRS summary sheet (provide copy), this activity was / was not broadcast regionally /&#13;
globally. Is that correct?&#13;
&#13;
Why did you decide to broadcast regionally / globally?&#13;
&#13;
&#13;
If multicountry,&#13;
&#13;
Why was this offered in countries X Y and Z?&#13;
&#13;
Does the number of countries participating influence the success of the activity?&#13;
&#13;
&#13;
Presenter and facilitator selection&#13;
&#13;
How did you select the presenter(s)? Facilitator(s)? Why?&#13;
&#13;
&#13;
Participant selection:&#13;
&#13;
How were participants selected?&#13;
&#13;
-open or invitation?&#13;
&#13;
-advertised? where?&#13;
&#13;
-screening? how? by whom?&#13;
&#13;
-did participants pay? how much?&#13;
&#13;
-how were partners involved in participant selection?&#13;
&#13;
&#13;
&#13;
&#13;
                                                 28&#13;
&amp;#12;&#13;
Action learning&#13;
&#13;
Did you use any action learning in this activity?&#13;
&#13;
Why? What kind?&#13;
&#13;
Examples?&#13;
&#13;
&#13;
Follow up&#13;
&#13;
What has happened since the activity? Why?&#13;
&#13;
&#13;
Recommendations&#13;
&#13;
What do you think could be done to improve the quality and impact of WBI activities?&#13;
&#13;
If you could change how WBI carries out its capacity development mission, what would you change and&#13;
how?&#13;
&#13;
(If you were the president of the Bank, what would you change?)&#13;
&#13;
What advice would you have for management (for your peers) on how to change the ways WBI carries out&#13;
capacity development?&#13;
&#13;
&#13;
&#13;
&#13;
                                                 29&#13;
&amp;#12;&#13;
    APPENDIX D: LIST OF VARIABLES USED FOR REGRESSION&#13;
                                                ANALYSIS&#13;
&#13;
Dependent Variables: (We consider activity wise mean ratings by `only male participants' as well as&#13;
`mean of male female together' standardized to [0, 1].)&#13;
&#13;
Overalluseful              : Overall usefulness of this activity.&#13;
Relevance                  : Relevance of this activity to your current work or function.&#13;
Newinfo                    : Extent to which you have acquired information that is new to you.&#13;
Usefulinfo                 : Usefulness for you of the information that you have acquired.&#13;
Learning                   : Focus of this activity on what you specifically needed to learn.&#13;
&#13;
Independent Variables&#13;
------------------&#13;
TPARTICIPANT = Number of participants&#13;
                     = INTERNAL_TOTAL+EXTERNAL_TOTAL+&#13;
                       DONORS_OBSERVER_TOTAL+RESOURCE_TOTAL&#13;
&#13;
PFEMALE            = share of female participants = (External + Internal female)/TPARTICIPANT&#13;
&#13;
TREP               = REP_MIN + REP_PARLIAMENTARIANS + REP_GOV_OF +&#13;
REP_ACADEMICS +REP_JOURNALISTS + REP_NGO +&#13;
PRIVATE_SECTOR_REPRESENTATIVES +&#13;
INTERNATIONAL_REPRESENTATIVES + IMF_REPRESENTATIVES +&#13;
             AID_DONORS_REPRESENTATIVES+OTHER__REPRESENTATIVES);&#13;
&#13;
PINTREP              = share of international representatives&#13;
                     = INTERNATIONAL_REPRESENTATIVES+IMF_REPRESENTATIVES)/TREP.&#13;
&#13;
PGOVREP            = ( REP_MIN+REP_PARLIAMENTARIANS+REP_GOV_OF)/TREP;&#13;
&#13;
&#13;
POTHREP              = share of the other representatives.&#13;
                     = (1-(PGOVREP+PINTREP)).&#13;
&#13;
**(Proportion of Government representatives (PGOVREP) is used as reference).&#13;
-------------------&#13;
RCOUNTRY                    =1 if 80% or more participants are from single country; =0 otherwise.&#13;
RREGION                     =1 if 80% or more representatives are from single region; =0 otherwise.&#13;
                               (this is done only for those cases where RCOUNTRY=0).&#13;
&#13;
Dummy variables&#13;
&#13;
DSTAFF               = 1 if WB staff attended the activity as a participant rather than as a resource person;&#13;
                     =0 otherwise.&#13;
DACTION              = 1 if the activity used action learning; =0 otherwise.&#13;
DPARTNER             = 1 if the WBICRS indicates that the activity involved a partner to a large extent;&#13;
                     =0 otherwise.&#13;
&#13;
Mode of Delivery&#13;
&#13;
DDL                        = 1 if distance learning; =0 otherwise.&#13;
DEL                        = 1 if electronic learning; =0 otherwise.&#13;
DBL                        = 1 if blended mode of delivery; =0 otherwise.&#13;
**DMF2F                    = is used as reference&#13;
&#13;
&#13;
&#13;
                                                    30&#13;
&amp;#12;&#13;
Division (Cost Centers)&#13;
&#13;
CCWBIEN                 = 1 if activity was sponsored by EN division: =0 otherwise.&#13;
CCWBIFP**               = 1 if activity was sponsored by FP division: =0 otherwise&#13;
CCWBIHD                 = 1 if activity was sponsored by HD division: =0 otherwise&#13;
CCWBIOTHER                        = 1if activity was sponsored by other division: =0 otherwise&#13;
CCWBIPR                 = 1 if activity was sponsored by PR division: =0 otherwise&#13;
&#13;
** WBIFP is the reference WBI division.&#13;
Note: WBIOTHER includes WBIST, WBISM, WBIKL, WBIKD, WBIES, WBIEG, WBIMO, and&#13;
WBIRC.&#13;
&#13;
Income dummies based on the income status of the representative countries (Directly taken from&#13;
Level 1 evaluation data)&#13;
&#13;
DLIC                    = 1 if low- income country; 0 otherwise&#13;
DMIC**                  = 1 if upper and lower middle-income countries (UMC+LMC); 0 otherwise&#13;
DHIC                    = 1 if high-income countries; 0 otherwise&#13;
&#13;
** DMIC is used as reference&#13;
&#13;
Learning Product line&#13;
DLPLK**                 = 1 if for knowledge exchange; 0 otherwise&#13;
DLPLP                   = 1 if for policy service; 0 otherwise&#13;
DLPLT                   = 1 if for skill building; 0 otherwise&#13;
&#13;
** DLPLK is used as reference&#13;
&#13;
Half-Year Dummies&#13;
&#13;
HALF 41**      =1 if FY=2004 and quarter=1 and 2; 0 otherwise&#13;
HALF 42         =1 if FY=2004 and quarter=3 and 4; 0 otherwise&#13;
HALF 51         =1 if FY=2005 and quarter=1 and 2; 0 otherwise&#13;
HALF 52        =1 if FY=2005 and quarter=3 and 4; 0 otherwise&#13;
&#13;
** HALF41 or the first half of fiscal year 2004 is used as reference&#13;
&#13;
&#13;
&#13;
&#13;
                                                 31&#13;
&amp;#12;&#13;
</ml:original-txt><ml:search-metadata><doc id="9321446">
        <url>
            http://documents.worldbank.org/curated/en/2008/01/9321446/can-wbi-learn-participants-task-team-leaders-system-records-learning-activities-review-client-learning
        </url>
        <availablein>English</availablein>
        <url_friendly_title>http://documents.worldbank.org/curated/en/2008/01/9321446/can-wbi-learn-participants-task-team-leaders-system-records-learning-activities-review-client-learning</url_friendly_title>
        <new_url>2008/01/9321446/can-wbi-learn-participants-task-team-leaders-system-records-learning-activities-review-client-learning</new_url>
        <disclosure_date>2010-07-01T00:00:00Z</disclosure_date>
        <disclosure_type>NA</disclosure_type>
        <ext_pub_date>2010-07-01T00:00:00Z</ext_pub_date>
        <disclstat>Disclosed</disclstat>
        <txturl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2008/04/02/000333038_20080402004725/Rendered/INDEX/431550WBWP0P0910review0pf0client0le.txt</txturl>
        <pdfurl>http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2008/04/02/000333038_20080402004725/Rendered/PDF/431550WBWP0P0910review0pf0client0le.pdf</pdfurl>
        <docdt>2008-01-01T00:00:00Z</docdt>
        <datestored>2008-04-02T00:00:00Z</datestored>
        <totvolnb>1</totvolnb>
        <versiontyp>Final</versiontyp>
        <versiontyp_key>1309935</versiontyp_key>
        <volnb>1</volnb>
        <repnme>
            What can WBI learn from the participants,
            task team leaders, and system records of its learning
            activities? A review of client learning
        </repnme>
        <abstracts>
            This review identified recommendations
            for improving the quality of future World Bank Institute
            (WBI) programs. This review identified suggestions for
            increasing data quality to support WBI's programmatic
            approach. Definitions of variables need to be standardized.
            Learning activity data should be readily accessible to
            evaluation officers and accompanied by a transparent
            codebook. A detailed systems strategy to increase the
            coordination among World Bank Institute Client Registration
            System (WBICRS), Plato, and SAP (the Bank's cost
            accounting system) and to minimize the reporting burden for
            Task team leaders (TTLs) will be helpful. Individual events
            are important building blocks for higher level indicators
            linked to organizational development. Overall, the findings
            and recommendations of this review support World Bank
            Institute Evaluation Groups (WBIEG's) engagement in
            ongoing efforts to refine data systems and to establish
            comprehensive indicators for assessing WBI's
            programmatic approach to capacity enhancement. This review
            merged WBICRS data and participant assessments to explore
            the following questions: what key participants'
            characteristics, activity-level variables, and exogenous
            factors explain participants' ratings of the overall
            usefulness (and other indicators of quality) of WBI learning
            events? Are there significant differences in assessment
            ratings across WBI thematic groups or over time? What can
            WBI TTLs do to improve these assessments of their activities?
        </abstracts>
        <docna>
            What can WBI learn from the participants,
            task team leaders, and system records of its learning
            activities? A review of client learning
        </docna>
        <display_title>What can WBI learn from the
            participants, task team leaders, and system records of its
            learning activities? A review of client learning</display_title>
        <listing_relative_url>/research/2008/01/9321446/can-wbi-learn-participants-task-team-leaders-system-records-learning-activities-review-client-learning</listing_relative_url>
        <projn>1W-Analysis Of Wbi Evaluation Data -- P097980</projn>
        <docty>WBI Working Paper</docty>
        <subtopic>Teaching and Learning,Poverty Monitoring &amp; Analysis,Educational Sciences,Education for Development (superceded),Education For All</subtopic>
        <teratopic>Poverty Reduction,Education</teratopic>
        <count>World</count>
        <authors>
            <author>Quizon, Jaime</author>
            <author>Behrens, Joy</author>
            <author>Dasgupta, Basab</author>
            <author>Ling, Cristina</author>
            <author>Rajakaruna, Oliver</author>
            <author>Roberts, Dawn</author>
        </authors>
        <entityids>
            <entityid>000333038_20080402004725</entityid>
        </entityids>
        <admreg>The World Region,The World Region</admreg>
        <colti>WBI Evaluation Studies; no. EG08-138</colti>
        <lang>English</lang>
        <historic_topic>Poverty Reduction,Education</historic_topic>
        <prdln>Evaluation of Training</prdln>
        <majdocty>Publications &amp; Research</majdocty>
        <keywd>
            access to knowledge, achievement, Action
            learning, adaptation, call, capacity building,
            collaboration, collaborations, collection of data,
            communities, communities of practice, computer simulations,
            descriptive statistics, discussion, Distance learning,
            documents, Education level, educators, effective learning,
            exogenous factors, Gender, homework, human development,
            ideas, income, individual learning, insights, instruction,
            interactive learning, intervention, knowledge for
            development, knowledge networks, language of instruction,
            Learning, Learning Activities, learning design, learning
            outcomes, learning practices, learning process, learning
            programs, lectures, logic, modeling, NGO, organizational
            development, organizational level, pedagogy, performance
            indicators, poverty reduction, program evaluation, programs,
            qualitative analysis, quality of information, quality of
            instruction, quality of learning, Readers, regression
            analyses, regression analysis, SAP, Scholarships, success
            indicators, sustainable development, systems thinking,
            teaching, training activities, universities, use of
            knowledge, variety
        </keywd>
        <owner>Evaluation Group (WBIEG)</owner>
        <repnb>43155</repnb>
    </doc></ml:search-metadata><ml:annotations><ml:concepts><ml:concept>ICT</ml:concept><ml:concept>ICT for Development</ml:concept><ml:concept>Information Technology</ml:concept><ml:concept>Information and Communication Technologies (ICT)</ml:concept><ml:concept>Finance and Development</ml:concept><ml:concept>Finance and Financial Sector Development</ml:concept><ml:concept>Poverty Reduction</ml:concept><ml:concept>Poverty Reduction and Distributional Analysis</ml:concept><ml:concept>Poverty Reduction and Equity</ml:concept><ml:concept>Poverty and Inequality</ml:concept><ml:concept>General Public Administration Sector</ml:concept><ml:concept>Governance and Public Sector Management</ml:concept><ml:concept>Government</ml:concept><ml:concept>Institutions</ml:concept><ml:concept>Public Administration</ml:concept><ml:concept>Public Sector Development</ml:concept><ml:concept>Public Sector Management and Reform</ml:concept><ml:concept>Public Sector and Governance</ml:concept><ml:concept>Social Protections and Labor</ml:concept><ml:concept>Information and Communication Technologies</ml:concept><ml:concept>Financial Sector Development</ml:concept><ml:concept>Private Sector Development</ml:concept><ml:concept>Agriculture and Food Security</ml:concept><ml:concept>Health, Nutrition and Population</ml:concept><ml:concept>Poverty</ml:concept><ml:concept>Public Sector Management</ml:concept><ml:concept>Social Protection and Labor</ml:concept><ml:concept>Alternative Sentencing Options</ml:concept><ml:concept>Community Policing</ml:concept><ml:concept>Community based Policing</ml:concept><ml:concept>Correctional Services and Facilities</ml:concept><ml:concept>Corrections</ml:concept><ml:concept>Crime Policies</ml:concept><ml:concept>Crime Prevention</ml:concept><ml:concept>Crime and Society</ml:concept><ml:concept>Defense Services</ml:concept><ml:concept>Detention</ml:concept><ml:concept>Enforcement Policies and Oversight Mechanism</ml:concept><ml:concept>Forensic</ml:concept><ml:concept>Forensic Services</ml:concept><ml:concept>Investigation</ml:concept><ml:concept>Investigative Task Force Police</ml:concept><ml:concept>Juvenile Justice</ml:concept><ml:concept>Law Enforcement</ml:concept><ml:concept>Offender Reintegration</ml:concept><ml:concept>Police Administration and Management</ml:concept><ml:concept>Police Reform</ml:concept><ml:concept>Problem solving Policing</ml:concept><ml:concept>Prosecution</ml:concept><ml:concept>Restorative Justice</ml:concept><ml:concept>Therapeutic Justice</ml:concept><ml:concept>Victim Assistance</ml:concept><ml:concept>Victim Services</ml:concept><ml:concept>Victim-Offender Mediation</ml:concept><ml:concept>Nutritional supplements</ml:concept><ml:concept>Vitamins</ml:concept><ml:concept>Natural Resource Management and Biodiversity</ml:concept><ml:concept>Natural Resources Management and Rural Issues</ml:concept><ml:concept>Asset Recovery</ml:concept><ml:concept>PeopleSoft</ml:concept><ml:concept>SAP</ml:concept><ml:concept>Analysis &amp; Monitoring</ml:concept><ml:concept>Delivery Units</ml:concept><ml:concept>Grievance Redress</ml:concept><ml:concept>Indicators</ml:concept><ml:concept>M&amp;E</ml:concept><ml:concept>Performance Measurement</ml:concept><ml:concept>Performance Reviews</ml:concept><ml:concept>Rapid Results Approaches</ml:concept><ml:concept>Governance and Public Accountability (GPA)</ml:concept><ml:concept>Incentives for Good Government</ml:concept><ml:concept>National Governance</ml:concept><ml:concept>Knowledge for Development</ml:concept><ml:concept>Civil Society</ml:concept><ml:concept>Income</ml:concept><ml:concept>Banking</ml:concept><ml:concept>Criminal Justice</ml:concept><ml:concept>Supplements</ml:concept><ml:concept>Scholarships</ml:concept><ml:concept>Adaptation</ml:concept><ml:concept>Natural Resource Management</ml:concept><ml:concept>Natural Resource Management </ml:concept><ml:concept>ERP Systems</ml:concept><ml:concept>Monitoring and Evaluation</ml:concept><ml:concept>Governance</ml:concept></ml:concepts><ml:geo-regions/></ml:annotations></ml:doc-envelope>